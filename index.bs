<pre class='metadata'>
Group: AOM
Status: WGD
Title: Immersive Audio Model and Formats
Editor: SungHee Hwang, Samsung, hshee@samsung.com
Editor: Felicia Lim, Google, flim@google.com
Repository: AOMediaCodec/iamf
Shortname: iamf
URL: https://aomediacodec.github.io/iamf/
Date: 2023-05-08
Abstract: This document specifies an immersive audio (IA) architecture and model, a standalone IA sequence format and an [[!ISOBMFF]]-based IA container format.
</pre>

<pre class="anchors">
url: https://www.iso.org/standard/68960.html#; spec: ISOBMFF; type: dfn;
	text: AudioSampleEntry
	text: boxtype
	text: grouping_type
	text: SampleGroupDescriptionEntry
	text: channelcount
	text: samplerate
	text: AudioRollRecoveryEntry
	text: media_time
	text: edit_duration
	
url: https://www.iso.org/standard/68960.html#; spec: ISOBMFF; type: property;
	text: iso6
	text: sgpd
	text: stsd
	text: sbgp
	text: edts
	text: stts
	text: roll
	text: mvhd
	text: elst
	text: trun

url: https://aomedia.org/av1/specification/conventions/; spec: AV1-Convention; type: dfn;
	text: leb128()
	text: Clip3

url: https://www.iso.org/standard/43345.html#; spec: AAC; type: dfn;
	text: raw_data_block()
	text: ADTS
	text: Low Complexity Profile

url: https://opus-codec.org/docs/opus_in_isobmff.html#; spec: OPUS-IN-ISOBMFF; type: dfn;
	text: OpusSpecificBox
	text: OutputChannelCount
	text: OutputGain
	text: ChannelMappingFamily
	text: PreSkip
	text: InputSampleRate


url: https://opus-codec.org/docs/opus_in_isobmff.html#; spec: OPUS-IN-ISOBMFF; type: property;
	text: Opus
	text: dOps

url: https://www.iso.org/standard/55688.html#; spec: MP4-Systems; type: dfn;
	text: objectTypeIndication
	text: streamType
	text: upstream
	text: decSpecificInfo()
	text: DecoderConfigDescriptor()
	text: Syntactic Description Language

url: https://www.iso.org/standard/76383.html#; spec: MP4-Audio; type: dfn;
	text: AudioSpecificConfig()
	text: audioObjectType
	text: channelConfiguration
	text: GASpecificConfig()
	text: frameLengthFlag
	text: dependsOnCoreCoder
	text: extensionFlag

url: https://www.iso.org/standard/79110.html#; spec: MP4; type: dfn;
	text: ESDBox

url: https://www.iso.org/standard/79110.html#; spec: MP4; type: property;
	text: mp4a
	text: esds

url: https://tools.ietf.org/html/rfc6381#; spec: RFC6381; type: property;
	text: codecs

url: https://tools.ietf.org/html/rfc8486#; spec: RFC8486; type: dfn;
	text: channel count

url: https://tools.ietf.org/html/rfc7845#; spec: RFC7845; type: dfn;
	text: ID Header
	text: Magic Signature
	text: Output Channel Count
	text: Output Gain
	text: Pre-skip

url: https://tools.ietf.org/html/rfc6716#; spec: RFC6716; type: dfn;
	text: opus packet

url: https://www.itu.int/dms_pubrec/itu-r/rec/bs/R-REC-BS.1770-4-201510-I!!PDF-E.pdf#; spec: ITU1770-4; type: dfn;
	text: LKFS

url: https://www.itu.int/dms_pubrec/itu-r/rec/bs/R-REC-BS.2051-3-202205-I!!PDF-E.pdf#; spec: ITU2051-3; type: dfn;
	text: Loudspeaker configuration for Sound System A (0+2+0)
	text: Loudspeaker configuration for Sound System B (0+5+0)
	text: Loudspeaker configuration for Sound System C (2+5+0)
	text: Loudspeaker configuration for Sound System D (4+5+0)
	text: Loudspeaker configuration for Sound System E (4+5+1)
	text: Loudspeaker configuration for Sound System F (3+7+0)
	text: Loudspeaker configuration for Sound System G (4+9+0)
	text: Loudspeaker configuration for Sound System H (9+10+3)
	text: Loudspeaker configuration for Sound System I (0+7+0)
	text: Loudspeaker configuration for Sound System J (4+7+0)
	text: SP Label

url: https://www.itu.int/dms_pubrec/itu-r/rec/bs/R-REC-BS.2127-0-201906-I!!PDF-E.pdf#; spec: ITU2127-0; type: dfn;
	text:

url: https://www.itu.int/dms_pubrec/itu-r/rec/bs/R-REC-BS.2076-2-201910-I!!PDF-E.pdf#; spec: ITU2076-2; type: dfn;
	text:

url: https://en.wikipedia.org/wiki/Q_(number_format); spec: Q-Format; type: dfn;
	text:

url: https://xiph.org/flac/format.html; spec: FLAC; type: dfn;
	text: METADATA_BLOCK
	text: FRAME
	text: FRAME_HEADER
	text: SUBFRAME
	text: FRAME_FOOTER

url: https://xiph.org/flac/format.html; spec: FLAC; type: property;
	text: fLaC

url: https://www.iso.org/standard/77752.html#; spec: MP4-PCM; type: dfn;
	text: format_flags
	text: PCM_sample_size
	
url: https://www.iso.org/standard/77752.html#; spec: MP4-PCM; type: property;
	text: ipcm

</pre>

<pre class='biblio'>
{
	"AI-CAD-Mixing": {
		"title": "AI 3D immersive audio codec based on content-adaptive dynamic down-mixing and up-mixing framework",
		"status": "Paper",
		"publisher": "AES",
		"href": "https://www.aes.org/e-lib/browse.cfm?elib=21489"
	},
	"AAC": {
		"title": "Information technology — Generic coding of moving pictures and associated audio information — Part 7: Advanced Audio Coding (AAC)",
		"status": "Standard",
		"publisher": "ISO/IEC",
		"href": "https://www.iso.org/standard/43345.html"
	},
	"MP4-Audio": {
		"title": "Information technology — Coding of audio-visual objects — Part 3: Audio",
		"status": "Standard",
		"publisher": "ISO/IEC",
		"href": "https://www.iso.org/standard/76383.html"
	},
	"MP4-Systems": {
		"title": "Information technology — Coding of audio-visual objects — Part 1: Systems",
		"status": "Standard",
		"publisher": "ISO/IEC",
		"href": "https://www.iso.org/standard/55688.html"
	},
	"OPUS-IN-ISOBMFF": {
		"title": "Encapsulation of Opus in ISO Base Media File Format",
		"status": "Best Practice",
		"publisher": "IETF",
		"href": "https://opus-codec.org/docs/opus_in_isobmff.html"
	},
	"ISOIEC-23091-3-2018": {
	  "title": "Information Technology - Coding-Independent Code Points - Part 3: Audio",
	  "status" : "Standard",
	  "publisher" : "ISO/IEC",
	  "href" : "https://www.iso.org/standard/73413.html"
	},
	"ITU1770-4": {
		"title": "Algorithms to measure audio programme loudness and true-peak audio level",
		"status": "Standard",
		"publisher": "ITU",
		"href": "https://www.itu.int/dms_pubrec/itu-r/rec/bs/R-REC-BS.1770-4-201510-I!!PDF-E.pdf"
	},
	"ITU2051-3": {
		"title": "Advance sound system for programme production",
		"status": "Standard",
		"publisher": "ITU",
		"href": "https://www.itu.int/dms_pubrec/itu-r/rec/bs/R-REC-BS.2051-3-202205-I!!PDF-E.pdf"
	},
	"Q-Format": {
		"title": "Q (number format)",
		"status": "Best Practice",
		"publisher": "Wikipedia",
		"href": "https://en.wikipedia.org/wiki/Q_(number_format)"
	},
	"BCP47": {
		"title": "BCP 47",
		"status": "Best Practice",
		"publisher": "IETF",
		"href": "https://www.rfc-editor.org/info/bcp47"
	},
	"FLAC": {
		"title": "Free Lossless Audio Codec",
		"status": "Best Practice",
		"publisher": "xiph.org",
		"href": "https://xiph.org/flac/format.html"
	},
	"AV1-Convention": {
		"title": "Conventions",
		"status": "Spec",
		"publisher": "aomedia.org",
		"href": "https://aomedia.org/av1/specification/conventions/"
	},
	"ITU2076-2": {
		"title": "Audio Definition Model",
		"status": "Standard",
		"publisher": "ITU",
		"href": "https://www.itu.int/dms_pubrec/itu-r/rec/bs/R-REC-BS.2076-2-201910-I!!PDF-E.pdf"
	},
	"ITU2127-0": {
		"title": "Audio Definition Model renderer for advanced sound systems",
		"status": "Standard",
		"publisher": "ITU",
		"href": "https://www.itu.int/dms_pubrec/itu-r/rec/bs/R-REC-BS.2127-0-201906-I!!PDF-E.pdf"
	},
	"BEAR": {
		"title": "Developing a Binaural Renderer for Audio Definition Model Content",
		"status": "Paper",
		"publisher": "AES",
		"href": "https://www.aes.org/e-lib/browse.cfm?elib=21729"
	},
	"Resonance-Audio": {
		"title": "Efficient Encoding and Decoding of Binaural Sound with Resonance Audio",
		"status": "Paper",
		"publisher": "AES",
		"href": "https://www.aes.org/e-lib/browse.cfm?elib=20446"
	},
	"AmbiX": {
		"title": "AMBIX - A SUGGESTED AMBISONICS FORMAT",
		"status": "Paper",
		"publisher": "Ambisonics Symposium, June 2011",
		"href": "https://iem.kug.ac.at/fileadmin/media/iem/projects/2011/ambisonics11_nachbar_zotter_sontacchi_deleflie.pdf"
	},
	"MP4-PCM": {
		"title": "Information technology — MPEG audio technologies — Part 5: Uncompressed audio in MPEG-4 file format",
		"status": "Standard",
		"publisher": "ISO/IEC",
		"href": "https://www.iso.org/standard/77752.html"
	}

}
</pre>

# Convention # {#convention}

## Syntax Description ## {#convention-syntaxstructure}

All of syntax elements conform to [=Syntactic Description Language=] specified in [[!MP4-Systems]] unless it is explicitly described in the specification.

### Data types ### {#convention-data-types}

 <b>leb128()</b> <b>syntaxName</b>
 
 <b>leb128()</b> indicates the type of an unsigned integer. It indicates the following unsigned integer <b>syntaxName</b> is encoded by [=leb128()=] specified in [[!AV1-Convention]].
 
 <b>syntaxName</b> is an unsigned integer which is encoded by [=leb128()=] specified in [[!AV1-Convention]].
 
 <b>sleb128()</b> <b>syntaxName</b>

 <b>sleb128()</b> indicates the type of an signed integer. It indicates the following signed integer <b>syntaxName</b> is encoded by [=leb128()=] specified in [[!AV1-Convention]].
 
 <b>syntaxName</b> is an signed integer which is encoded by [=leb128()=] specified in [[!AV1-Convention]].
 
 <b>string</b> <b>syntaxName</b>

 <b>string</b> indicates the type of a string which is terminated by null of one byte (i.e. 0x00).
 
 <b>syntaxName</b> is a human readable label whose byte representation consists of <b>two-letter primary language subtags</b> and <b>two-letter region subtags</b> which are connected by hyphen("-"), and followed by bytes representation of [=UTF-8_Enc(label)=]. Its length in bytes is limited to 128.
 
 Where, <b>two-letter primary language subtags</b> and <b>two-letter region subtags</b> conform to [[!BCP47]].

## Arithmetic Operators ## {#convention-arithmetic-operators}

<table class="def">
<tr>
  <td>+</td><td>Addition.</td>
</tr>
<tr>
  <td>-</td><td>Subtraction.</td>
</tr>
<tr>
  <td>*</td><td>Multiplication.</td>
</tr>
<tr>
  <td>÷</td><td>Floating point (arithmetic) division.</td>
</tr>
<tr>
  <td>/</td><td>Integer division with truncation of the result toward zero.</td>
</tr>
<tr>
  <td>floor(x)</td><td>The largest integer that is smaller than or equal to x.</td>
</tr>
<tr>
  <td>sqrt(x)</td><td>The square root of x.</td>
</tr>
</table>

## Function ## {#convention-function}

### Function templates ### {#convention-function-templates}

When the <b>template</b> keyword is used to decorate the <b>class</b> declaration, it indicates that the code is a template with a placeholder type that can be reused by other classes. Only classes that use the template present in the bitstream; the template itself does not present in the bitstream. Classes that use a function template pass a data type that is specified in either [[!MP4-Systems]] or [[#convention-data-types]].

<b>Example</b>

```
template <class T>
class Foo {
  T t;
}

class Bar {
  Foo<int> f;
}
```

### Mathematical functions ### {#convention-function-mathematical}
 
<b>Clip3(x, y, z)</b>
 
It conforms to [=Clip3=] specified in [[!AV1-Convention]].

<b>round(x)</b>

The round() function returns the integer value closest to <code>x</code> and may be implemented as

```
round(x) = floor(x + 0.5).
```

<b>MOD(Number, Divisor)</b>

The MOD() function returns the remainder after <b>Number</b> is divided by <b>Divisor</b>.
 
### Function UTF-8 Encoding ### {#convention-function-utf8}

 <b>UTF-8_Enc(label)</b>
 
 <dfn values noexport>UTF-8_Enc(label)</dfn> byte representation of the encoded <b>label</b>, which is UTF-8 string as defined in [[!RFC3629]], null terminated.

# Introduction # {#introduction}

The <dfn noexport>immersive audio</dfn> means the combination of 3D audio signals recreating a sound experience close to that of a natural environment.

This specification defines a model for representing [=immersive audio=] contents based on coded audio substreams contributing to audio elements meant to be rendered and mixed to form one or more immersive presentations as depicted in the figure below.

<center><img src="images/decoding_flow_cropped.png" style="width:100%; height:auto;"></center>
<center><figcaption>Processing flow to decode, reconstruct, render and mix the audio signals for immersive audio playback.</figcaption></center>

Based on the model, this specification defines a hypothetical immersive audio model and format (<dfn noexport>IAMF</dfn>) architecture as depicted in the figure below.

<center><img src="images/Hypothetical IAMF Architecture.png" style="width:100%; height:auto;"></center>
<center><figcaption>Hypothetical IAMF Architecture</figcaption></center>

For a given input 3D audio,
- Pre-Processor generates Pre-Processed Audio and Codec Agnostic Metadata for [=immersive audio=] (IA).
	- Pre-Processed Audio is composed of one or more substreams.
	- Metadata is determined to drive the rendering and mixing
- Audio Codec Enc generates Codec-Dependent Bitstream, which consists of the coded substreams.
- Bitstream Packager generates IA sequence from Codec-Dependent Bitstream and Codec Agnostic Metadata.
- File Packager generates IAMF File by encapsulating IA sequence into [[!ISOBMFF]] tracks.
- File Parser reconstructs IA sequence by decapsulating IAMF File.
- Bitstream Parser outputs Codec-Dependent Bitstream and Codec Agnostic Metadata.
- Audio Codec Dec outputs a decoded Pre-Processed Audio after decoding of Codec-Dependent Bitstream.
- Post-Processor outputs Immersive 3D Audio by using the decoded Pre-Processed Audio and Codec Agnostic Metadata.

## IA sequence Components ## {#iasequence-components}

The <dfn noexport>IA sequence</dfn> is a bitstream to represent [=immersive audio=] for presentation on a wide range of devices in both dynamic streaming and offline applications. These applications include internet audio streaming, multicasting/broadcasting services, file download, gaming, communication, virtual and augmented reality, and others. In these applications, audio may be played back on a wide range of devices, e.g. headsets, mobile phones, tablets, TVs, sound bars, home theater systems and big screens.

The bitstream comprises a number of coded audio substreams and the metadata that describes how to decode, render and mix the substreams to generate an audio signal for playback. The bitstream format itself is codec-agnostic; any supported audio codec may be used to code the audio substreams.

The IA sequence includes one or more audio elements, each of which consists of one or more audio substreams. The IA sequence further includes mix presentations and parameters.

- <dfn noexport>Audio substream</dfn> is the actual audio signal, which may be encoded with any compatible audio codec.
- <dfn noexport>Audio element</dfn> is the 3D representation of the audio signals, and are constructed from one or more audio substreams and the metadata describing them. The audio substreams associated with one audio element use the same audio codec.
- <dfn noexport>Mix presentations</dfn> contain metadata that describe how the audio elements are rendered and mixed together for playback through physical loudspeakers or headphones. Multiple mix presentations can be defined as alternatives to each other within the same IA sequence. Furthermore, the choice of which mix presentation to use at playback is left to the user. For example, multi-language support is implemented by defining different mix presentations, where the first mix describes the use of the audio element with English dialogue, and the second mix describes the use of the audio element with French dialogue.
- <dfn noexport>Parameters</dfn> are the values that are associated with the algorithms used for decoding, reconstructing, rendering and mixing. Parameters may change their values over time and may further be animated; for example, any changes in values may be smoothed over some time duration. Their rate of change is specific to its respective algorithm, and is independent of other algorithms and the frame rates associated with the audio substreams. As such, they may be viewed as a 1D signal that have different metadata specified for different time durations.

## Use of OBU Syntax ## {#use-of-obu}

### Descriptors ### {#descriptors}

The descriptor OBUs contains all the information that is required to setup and configure the decoders, reconstruction algorithms, renderers and mixers.

- <dfn noexport>Magic Code OBU</dfn> indicates the start of a full IA sequence description, version and profile version.
- <dfn noexport>Codec Config OBU</dfn> describes information to set up a decoder for an audio substream.
- <dfn noexport>Audio Element OBU</dfn> describes information to combine one or more audio substreams to reconstruct an audio element.
- <dfn noexport>Mix Presentation OBU</dfn> describes information to render and mix one or more audio elements to generate the final audio output.

### Data ### {#data}

The data OBUs contain the actual time-varying data that is required in the generation of the final audio output.

The IA sequence supports the description of multiple audio substreams and algorithms, which may have different metadata update rates to each other. The update rate for the audio substreams and audio elements is governed by the frame rates of the audio codec used. Since a single bitstream may support multiple codecs, this may lead to multiple different frame rates. The algorithms for rendering and mixing may have parameters that update at different rates to each other and to the audio frame rates. Therefore, the IA sequence contains information to facilitate the synchronization of the different audio frames and parameters.

- <dfn noexport>Audio Frame OBU</dfn> provides the raw coded audio frame for an audio substream.
- <dfn noexport>Parameter Block OBU</dfn> provides the time-varying parameter values for an algorithm used in any of the decoding, reconstruction, rendering or mixing steps.
- <dfn noexport>Sync OBU</dfn> provides relative timestamp offsets to synchronize audio frames and parameter blocks.
- <dfn noexport>Temporal Delimiter OBU</dfn> identifies the temporal units.

# Open Bitstream Unit (OBU) Syntax and Semantics # {#obu-syntax}

The IA sequence uses the OBU syntax.

This section specifies the OBU syntax elements and their semantics.

## Audio OBU Syntax and Semantics ## {#audio-obu}

<b>Syntax</b>

```
class audio_open_bitstream_unit() {
  obu_header();

  if (obu_type == OBU_IA_Magic_Code)
    magic_code_obu();
  else if (obu_type == OBU_IA_Codec_Config)
    codec_config_obu();
  else if (obu_type == OBU_IA_Audio_Element)
    audio_element_obu();
  else if (obu_type == OBU_IA_Mix_Presentation)
    mix_presentation_obu();
  else if (obu_type == OBU_IA_Parameter_Block)
    parameter_block_obu();
  else if (obu_type == OBU_IA_Temporal_Delimiter)
    temporal_delimiter_obu();
  else if (obu_type == OBU_IA_Sync)
    sync_obu();
  else if (obu_type == OBU_IA_Audio_Frame)
    audio_frame_obu_with_no_id();
  else if (obu_type >= 9 and <= 30)
    audio_frame_obu(obu_type - 9);
  else if (obu_type == 6 or 7)
    reserved_obu();

  byte_alignment():
}
```

<b>Semantics</b>

If the syntax element obu_type is equal to OBU_IA_Magic_Code, an ordered series of OBUs is presented to the decoding process as a string of bytes.


## OBU Header Syntax and Semantics ## {#obu-header}

<b>Syntax</b>

```
class obu_header() {
  unsigned int (5) obu_type;
  unsigned int (1) obu_redundant_copy;
  unsigned int (1) obu_trimming_status_flag;
  unsigned int (1) obu_extension_flag;
  leb128() obu_size;

  if (obu_trimming_status_flag) {
    leb128() num_samples_to_trim_at_end;
    leb128() num_samples_to_trim_at_start;
  }
  if (obu_extension_flag == 1)
    leb128() extension_header_size;
}
```

<b>Semantics</b>

OBUs are structured with a header and a payload.

<dfn noexport>obu_type</dfn> specifies the type of data structure contained in the OBU payload.

<pre class = "def">
obu_type: Name of obu_type
   0    : OBU_IA_Codec_Config
   1    : OBU_IA_Audio_Element
   2    : OBU_IA_Mix_Presentation
   3    : OBU_IA_Parameter_Block
   4    : OBU_IA_Temporal_Delimiter
   5    : OBU_IA_Sync
  6~7   : Reserved
   8    : OBU_IA_Audio_Frame
  9~30  : OBU_IA_Audio_Frame_ID0 to OBU_IA_Audio_Frame_ID21
   31   : OBU_IA_Magic_Code
</pre>

<dfn noexport>obu_redundant_copy</dfn> indicates whether this OBU is a redundant copy of the previous OBU in the IA sequence with the same obu_type. A value of 1 indicates that it is a redundant copy, while a value of 0 indicates that it is not.

It shall always be set to 0 for the following obu_type values:

- OBU_IA_Temporal_Delimiter
- OBU_IA_Sync
- OBU_IA_Audio_Frame
- OBU_IA_Audio_Frame_ID0 to OBU_IA_Audio_Frame_ID21

<dfn noexport>obu_trimming_status_flag</dfn> indicates whether this OBU has audio samples to be trimmed or not. If it is set to 0, the [=num_samples_to_trim_at_start=] and [=num_samples_to_trim_at_end=] fields shall not be present. Otherwise, the [=num_samples_to_trim_at_start=] and [=num_samples_to_trim_at_end=] fields shall be present.

For a given substream, 
- If the substream contains audio samples to be trimmed, then they shall only be at the start and/or end of the substream. Thus, [=obu_trimming_status_flag=] shall be set to 1 only for one or more consecutive Audio Frame OBUs at the start of the substream and/or only for one or more consecutive Audio Frame OBUs at the end of the substream.
- Otherwise, then [=obu_trimming_status_flag=] shall be set to 0 for every Audio Frame OBU of the substream. 

<dfn noexport>obu_extension_flag</dfn> indicates whether the [=extension_header_size=] field presents or not. If it set to 0, the [=extension_header_size=] field shall not be present. Otherwise, the [=extension_header_size=] field shall be present.

This flag shall be set to 0 for the current version of the specification (i.e. [=version=] = 0). An IAMF-OBU parser which is conformant with the current version of the specification shall be able to parse this flag and [=extension_header_size=].

NOTE: A future version of specification may use this flag to specify an extension header field by setting [=obu_extension_flag=] = 1 and setting the size of extended header to [=extension_header_size=].

<dfn noexport>obu_size</dfn> indicates the size in bytes of the OBU immediately following the obu_size field of the OBU.
	
<dfn noexport>num_samples_to_trim_at_start</dfn> indicates the number of samples that needs to be trimmed from the start of the samples in this Audio Frame OBU. 

<dfn noexport>num_samples_to_trim_at_end</dfn> indicates the number of samples that needs to be trimmed from the end of the samples in this Audio Frame OBU.

<dfn noexport>extension_header_size</dfn> indicates the size in bytes of the extension header including this field.


## Byte Alignment Syntax and Semantics ## {#obu-bytealignment}

<b>Syntax</b>

```
class byte_alignment() {
  while (get_position() & 7)
    unsigned int (1) zero_bit;
}
```

<b>Semantics</b>

<dfn noexport>zero_bit</dfn> shall be equal to 0 and is inserted into the bitstream to align the bit position to a multiple of 8 bits.


## Reserved OBU Syntax and Semantics ## {#obu-reserved}

The reserved OBU allows the extension of this specification with additional OBU types in a way that allows IAMF-OBU parsers compliant to this version of specification to ignore them.


## Magic Code OBU Syntax and Semantics ## {#obu-magiccode}

This section specifies obu payload of OBU_IA_Magic_Code.

<b>Syntax</b>

```
class magic_code_obu() {
  unsigned int (32) ia_code;
  unsigned int (8) version;
  unsigned int (8) profile_version
}
```

<b>Semantics</b>

<dfn noexport>ia_code</dfn> indicates a ‘four-character code’ (4CC) to identify the start of the IA sequence. It shall be ‘iamf’.

<dfn noexport>version</dfn> indicates the version of an IA sequence. It shall be set to 0 for this version of the specification. Implementations should treat IA sequences where the MSB four bits of the version number match that of a recognized specification as backwards compatible with that specification. That is, the version number can be split into "major" and "minor" version sub-fields, with changes to the minor sub-field (in the LSB four bits) signaling compatible changes. For example, an implementation of this specification should accept any stream with a version number of ’15’ or less, and should assume any stream with a version number ’16’ or
greater is incompatible.

<dfn noexport>profile_version</dfn> indicates the profile of an IA sequence. The MSB four bits indicates the profile of an IA sequence. Implementations should treat IA sequences where the MSB four bits of the version number match that of a recognized profile as backwards compatible with that specification. That is, the version number can be split into "profile major" and "profile minor" version sub-fields, with changes to the minor sub-field (in the LSB four bits) signaling compatible changes with the profile major version. The semantic of this field is only valid when the MSB four bits of [=version=] = 0.

## Codec Config OBU Syntax and Semantics ## {#obu-codecconfig}

This section specifies the OBU payload of OBU_IA_Codec_Config.

<b>Syntax</b>

```
class codec_config_obu() {
  leb128() codec_config_id;  
  codec_config();
}

class codec_config() {
  unsigned int (32) codec_id;
  leb128() num_samples_per_frame;
  signed int (16) roll_distance;
  decoder_config(codec_id);
}
```

<b>Semantics</b>

<dfn noexport>codec_config_id</dfn> defines an identifier for a codec configuration. Within an IA Sequence, there shall be exactly one non-redundant Codec Config OBU with a given identifier. Audio Elements that need a decoder configuration based on this codec configuration refer to this identifier.

<dfn noexport>codec_id</dfn> indicates a ‘four-character code’ (4CC) to identify the codec used to generate the audio substreams. It shall be 'Opus' for IAMF-OPUS, 'mp4a' for IAMF-AAC-LC, 'fLaC' for IAMF-FLAC and 'ipcm' for IAMF-LPCM.

<dfn noexport>num_samples_per_frame</dfn> indicates the frame length, in samples, of the raw coded audio provided in by audio_frame_obu(). It shall not be set to zero.

<dfn noexport>roll_distance</dfn> is a signed integer that gives the number of frames that need to be decoded in order for a frame to be decoded correctly. A negative value indicates the number of frames before the frame to be decoded corrently.
- It shall be set to -1 for IAMF-AAC-LC and -R (R = 4 when the frame size = 960) for IAMF-OPUS. IAMF-FLAC may ignore this field. Where, R is the smallest integer greater than or equal to 3840 divided by the frame size. 

<dfn noexport>decoder_config()</dfn> specifies the set of codec parameters required to decode an audio substream for the given codec_id. It is byte aligned.
- The codec_id and decoder_config() for IAMF-OPUS shall conform to [=Codec_Specific_Info=] of [[#iamf-opus-specific]]
- The codec_id and decoder_config() for IAMF-AAC-LC shall conform to [=Codec_Specific_Info=] of [[#iamf-aac-lc-specific]].
- The codec_id and decoder_config() for IAMF-FLAC shall conform to [=Codec_Specific_Info=] of [[#iamf-flac-specific]]
- The codec_id and decoder_config() for IAMF-LPCM shall conform to [=Codec_Specific_Info=] of [[#iamf-lpcm-specific]].

## Audio Element OBU Syntax and Semantics ## {#obu-audioelement}

This section specifies the OBU payload of OBU_IA_Audio_Element.

<b>Syntax</b>

```
class audio_element_obu() {
  leb128() audio_element_id;
  unsigned int (3) audio_element_type;
  unsigned int (5) reserved;
  
  leb128() codec_config_id;  

  leb128() num_substreams;
  for (i = 0; i < num_substreams; i++) {
    leb128() audio_substream_id;
  }
  
  leb128() num_parameters;
  for (i = 0; i < num_parameters; i++) {
    leb128() param_definition_type;
    if (param_definition_type == PARAMETER_DEFINITION_DEMIXING) {
        DemixingParamDefinition demixing_info;
    }
    if (param_definition_type == PARAMETER_DEFINITION_RECON_GAIN) {
        ReconGainParamDefinition recon_gain_info;
    }
  }

  if (audio_element_type == CHANNEL_BASED) {
    scalable_channel_layout_config();
  } else if (audio_element_type == SCENE_BASED) {
    ambisonics_config();
  }  
}
```

```
class DemixingParamDefinition() extends ParamDefinition() {
}
```

```
class ReconGainParamDefinition() extends ParamDefinition() {
}

```

<b>Semantics</b>

<dfn noexport>audio_element_id</dfn> defines an identifier for an Audio Element. Within an IA Sequence, there shall be exactly one non-redundant Audio Element OBU with a given identifier. Mix Presentations that use an Audio Element refer to this identifier.

<dfn noexport>audio_element_type</dfn> specifies the audio representation of this audio element which is constructed from one or more audio substreams.

<pre class = "def">
audio_element_type: The type of audio representation.
   0    : CHANNEL_BASED
   1    : SCENE_BASED
  2~7   : Reserved
</pre>

<dfn value noexport for="audio_element_obu()">codec_config_id</dfn> indicates the identifier for the codec configuration which this Audio Element refers to.

<dfn noexport>num_substreams</dfn> specifies the number of audio substreams that are used to reconstruct this audio element.

<dfn value noexport for="audio_element_obu()">audio_substream_id</dfn> indicates the identifier for a Substream which this Audio Element refers to.

Let a particular ChannelGroup's substream be indexed as [<dfn noexport>c</dfn>, <dfn noexport>n_c</dfn>], where
- [=c=] = [1, ..., C] is the ChannelGroup index and C is the number of ChannelGroups.
- [=n_c=] = [1, ..., N_c] is the substream index in the c-th ChannelGroup and N_c is the number of substreams in the c-th ChannelGroup.
- The i-th audio_substream_id maps to a ChannelGroup's substream as follows, where i is the index of the array:

```
[[1, 1], [1, 2], ..., [1, N_1], [2, 1], [2, 2], ..., [2, N_2], ..., [C, 1], [C, 2], ..., [C, N_c]]
```

A ChannelGroup is defined in [[#iamfgeneration]]. The order of the substreams in each ChannelGroup., i.e. the semantics of n_c, is specified in [[#syntax-scalable-channel-layout-config]].


<dfn noexport>num_parameters</dfn> specifies the number of parameters that are used by the algorithms specified in this audio element.

<dfn noexport>param_definition_type</dfn> specifies the type of the parameter definition. All parameter definition types described in this version of the specification are listed in the table below, along with their associated parameter definitions.

<table class = "def">
<tr>
  <th>param_definition_type</th><th>Parameter definition type</th><th>Parameter definition</th>
</tr>
<tr>
  <td>0</td><td>PARAMETER_DEFINITION_MIX_GAIN</td><td>MixGainParamDefinition</td>
</tr>
<tr>
  <td>1</td><td>PARAMETER_DEFINITION_DEMIXING</td><td>DemixingParamDefinition</td>
</tr>
<tr>
  <td>2</td><td>PARAMETER_DEFINITION_RECON_GAIN</td><td>ReconGainParamDefinition</td>
</tr>
</table>

<dfn noexport>demixing_info</dfn> provides the parameter definition for the demixing information to reconstruct channel audios according to [=loudspeaker_layout=] from scalable channel audio. The parameter definition is provided by DemixingParamDefinition() and the corresponding parameter data to be provided in parameter blocks is specified in demixing_info_parameter_data().

<dfn noexport>recon_gain_info</dfn> provides the parameter definition for the gain value to reconstruct channel audios according to [=loudspeaker_layout=] from scalable channel audio. The parameter definition is provided by ReconGainParamDefinition() and the corresponding parameter data to be provided in parameter blocks is specified in recon_gain_info_parameter_data().

<dfn noexport>scalable_channel_layout_config()</dfn> is a class that provides the metadata required for combining the substreams identified here in order to reconstruct a scalable channel layout.

<dfn noexport>ambisonics_config()</dfn> is a class that provides the metadata required for combining the substreams identified here in order to reconstruct an Ambisonics layout.

### Parameter Definition Syntax and Semantics ### {#parameter-definition}

Parameter definition classes inherits from the abstract <dfn noexport>ParamDefinition()</dfn> class.

<b>Syntax</b>

```
abstract class ParamDefinition() {
  leb128() parameter_id;
  leb128() parameter_rate;
  unsigned int (1) param_definition_mode;
  unsigned int (7) reserved;
  if (param_definition_mode == 0) {
    leb128() duration;
    leb128() num_subblocks;
    leb128() constant_subblock_duration;
    if (constant_subblock_duration == 0) {
      for (i=0; i< num_subblocks; i++) {
        leb128() subblock_duration;
      }
    }
    
  }
}
```

<b>Semantics</b>

<dfn value noexport for="ParamDefinition()">parameter_id</dfn> indicates the identifier for the Parameter which this parameter definition refers to.

<dfn noexport>parameter_rate</dfn> specifies the rate used by this parameter, expressed as ticks per second. Time-related fields associated with this parameter, such as durations, shall be expressed in the number of ticks.

<dfn noexport>param_definition_mode</dfn> indicates if this parameter definition specifies duration, num_subblocks, constant_subblock_duration and subblock_duration fields for the parameter blocks associated to the [=parameter_id=].
- When this field is set to 0, all of duration, num_subblocks, constant_subblock_duration and subblock_duration fields shall be specified in this parameter definition mapped to the [=parameter_id=]. In that case, none of parameter blocks associated to this parameter definition shall specify duration, num_subblocks, constant_subblock_duration and subblock_duration fields. 
- When this field is set to 1, none of duration, num_subblocks, constant_subblock_duration and subblock_duration fields shall be specificed in this parameter definition. In that case, each of parameter blocks associated to this parameter definition shall specify its own duration, num_subblocks, constant_subblock_duration and subblock_duration fields.

<dfn noexport>duration</dfn> specifies the duration for which all of parameter blocks associated to this parameter definition are valid and applicable. 

<dfn noexport>num_subblocks</dfn> specifies the number of different sets of parameter values specified in all of parameter blocks associated to this parameter definition, where each set describes a different subblock of the timeline, contiguously.

<dfn noexport>constant_subblock_duration</dfn> specifies the duration of each subblock, in the case where all subblocks except the last subblock have equal durations. If all subblocks except the last subblock do not have equal durations, the value of constant_subblock_duration shall be set to 0. 

When it defines <dfn noexport>D</dfn> = the value of [=duration=], <dfn noexport>NS</dfn> = the value of [=num_subblocks=], <dfn noexport>CSI</dfn> = the value of [=constant_subblock_duration=] and <dfn noexport>SI</dfn> = the value of [=subblock_duration=].
- When [=CSI=] != 0, [=NS=] x [=CSI=] shall be equal to or greater than [=D=].
	- If [=NS=] x [=CSI=] > [=D=], the actual duration of the last subblock shall be [=D=] - ([=NS=] - 1) x [=CSI=].
- When [=CSI=] = 0, the summation of all [=SI=]s in this parameter block shall be equal to [=D=].

<dfn noexport>subblock_duration</dfn> specifies the duration for the given subblock.

Each value of [=duration=], [=constant_subblock_duration=] and [=subblock_duration=] shall be expressed as the number of ticks at the [=parameter_rate=] specified in the corresponding parameter definition.

### Scalable Channel Layout Config Syntax and Semantics ### {#syntax-scalable-channel-layout-config}

[=scalable_channel_layout_config()=] contains information regarding the configuration of scalable channel audio.

<b>Syntax</b>

```
class scalable_channel_layout_config() {
  unsigned int (3) num_layers;
  unsigned int (5) reserved;
  for (i = 1; i <= num_layers; i++) {
    channel_audio_layer_config(i);
  }
}

class channel_audio_layer_config(i) {
  unsigned int (4) loudspeaker_layout(i);
  unsigned int (1) output_gain_is_present_flag(i);
  unsigned int (1) recon_gain_is_present_flag(i);
  unsigned int (2) reserved;
  unsigned int (8) substream_count(i);
  unsigned int (8) coupled_substream_count(i);
  if (output_gain_is_present_flag(i) == 1) {
    unsigned int (6) output_gain_flag(i);
    unsigned int (2) reserved;
    signed int (16) output_gain(i);
  }
}
```

When an audio element is composed of G(r) number of substreams, scalable channel audio for the audio element is layered into [=num_layers=] = r number of ChannelGroups.
- The order of ChannelGroups in each temporal unit shall be same as the order of channel_audio_layer_config()s in scalable_channel_layout_config().
- <dfn noexport>ChannelGroup</dfn> is a set of substreams which is able to provide a spatial resolution of audio contents by itself or which is able to provide an enhanced spatial resolution of audio contents by combining with the preceding ChannelGroups within the audio frames.
- ChannelGroup #q consists of G(q)-G(q-1) number of substreams. Where, q = 1, 2, ..., r and G(0) = 0.
- IA frame is a set of audio_frame_obus with the same sync offsets of the single audio element for scalable channel audio. Each of them comes from each substream.
- Every IA frame shall have the same number of audio_frame_obus.
- When r > 1, parameter_block_obu() may present with IA frame. 

<center><img src="images/Immersive Audio Bitstream with scalable channel audio (before OBU packing).png" style="width:100%; height:auto;"></center>
<center><figcaption>Immersive Audio Sequence with scalable channel audio (before OBU packing)</figcaption></center>

The IA decoder shall select one of one or more channel audios provided by scalable channel audio. The IA decoder should select the appropriate channel audio according to the following rules, in order:
- The IA decoder should first attempt to select the channel audio whose loudspeaker layout matches the physical playback layout.
- If there is no match, the IA decoder should select the channel audio with the closest specified loudspeaker layout to the physical layout and then apply up or down-mixing appropriately, after decoding and reconstruction of the channel audio. [[#iamfgeneration-scalablechannelaudio-downmixmechanism]] and [[#processing-downmixmatrix]] provide examples of dynamic and static down-mixing matrices for some common layouts that may be used.

<b>Semantics</b>

<dfn noexport>num_layers</dfn> indicates the number of ChannelGroups for scalable channel audio. It shall not be set to zero and its maximum number shall be limited to 6.
- For Binaural, this field shall be set to 1.

<dfn noexport>channel_audio_layer_config()</dfn> is a class that provides the information regarding the configuration of ChannelGroup for scalable channel audio. channel_audio_layer_config(i) provides information regarding the configuration of ChannelGroup #i.

<dfn noexport>loudspeaker_layout</dfn> indicates the channel layout for the channels to be reconstructed from the precedent ChannelGroups and the current ChannelGroup among ChannelGroups for scalable channel audio.

In the current version of the specification, [=loudspeaker_layout=] indicates one of 10 channel layouts including Mono, Stereo, 5.1ch, 5.1.2ch, 5.1.4ch, 7.1ch, 7.1.2ch, 7.1.4ch, 3.1.2ch and Binaural. Where,
- <dfn noexport>Stereo</dfn> is the loudspeaker configuration as depicted in [=Loudspeaker configuration for Sound System A (0+2+0)=] of [[!ITU2051-3]].
- <dfn noexport>5.1ch</dfn> is the loudspeaker configuration as depicted in [=Loudspeaker configuration for Sound System B (0+5+0)=] of [[!ITU2051-3]].
- <dfn noexport>5.1.2ch</dfn> is the loudspeaker configuration as depicted in [=Loudspeaker configuration for Sound System C (2+5+0)=] of [[!ITU2051-3]].
- <dfn noexport>5.1.4ch</dfn> is the loudspeaker configuration as depicted in [=Loudspeaker configuration for Sound System D (4+5+0)=] of [[!ITU2051-3]].
- <dfn noexport>7.1ch</dfn> is the loudspeaker configuration as depicted in [=Loudspeaker configuration for Sound System I (0+7+0)=] of [[!ITU2051-3]].
- <dfn noexport>7.1.2ch</dfn> is the combination of the loudspeaker configuration as depicted in [=Loudspeaker configuration for Sound System I (0+7+0)=] of [[!ITU2051-3]] and the left and right top front pair of the loudspeaker configuration as depicted in [=Loudspeaker configuration for Sound System J (4+7+0)=] of [[!ITU2051-3]].
- <dfn noexport>7.1.4ch</dfn> is the loudspeaker configuration as depicted in [=Loudspeaker configuration for Sound System J (4+7+0)=] of [[!ITU2051-3]].
- <dfn noexport>3.1.2ch</dfn> is the front subset (L/C/R/Ltf/Rtf/LFE) of [=7.1.4ch=].

<pre class = "def">
Loudspeaker Layout (4 bits) :  Channel Layout  : Loudspeaker Location Ordering
             0000           :       Mono       : C
             0001           :      Stereo      : L/R
             0010           :      5.1ch       : L/C/R/Ls/Rs/LFE
             0011           :     5.1.2ch      : L/C/R/Ls/Rs/Ltf/Rtf/LFE
             0100           :     5.1.4ch      : L/C/R/Ls/Rs/Ltf/Rtf/Ltr/Rtr/LFE
             0101           :      7.1ch       : L/C/R/Lss/Rss/Lrs/Rrs/LFE
             0110           :     7.1.2ch      : L/C/R/Lss/Rss/Lrs/Rrs/Ltf/Rtf/LFE
             0111           :     7.1.4ch      : L/C/R/Lss/Rss/Lrs/Rrs/Ltf/Rtf/Ltb/Rtb/LFE
             1000           :     3.1.2ch      : L/C/R//Ltf/Rtf/LFE
             1001           :     Binaural     : L/R
            others          :     reserved     :
</pre>

```
Where, C: Center, L: Left, R: Right, Ls: Left Surround, Lss: Left Side Surround, 
Rs: Right Surround, Rss: Right Side Surround, 
Ltf: Left Top Front, Rtf: Right Top Front, Ltr: Left Top Rear, Rtr: Right Top Rear, 
Ltb: Left Top Back, Rtb: Right Top Back, LFE: Low-Frequency Effects
```

<dfn noexport>output_gain_is_present_flag</dfn> indicates if output_gain information fields for the ChannelGroup presents .
- 0: No output_gain information fields for the ChannelGroup shall be present.
- 1: output_gain information fields for the ChannelGroup present. In this case, output_gain_flags and output_gain fields shall be present.

<dfn noexport>recon_gain_is_present_flag</dfn> indicates if recon_gain information fields for the ChannelGroup presents in recon_gain_info_parameter_data().
- 0: No recon_gain information fields for the ChannelGroup shall be present in recon_gain_info_parameter_data().
- 1: recon_gain information fields for the ChannelGroup present in recon_gain_info_parameter_data(). In this case, recon_gain_flags and recon_gain fields shall be present.

<dfn noexport>substream_count</dfn> specifies the number of audio substreams. It must be the same as [=num_substreams=] in its corresponding audio_element().

<dfn noexport>coupled_substream_count</dfn> specifies the number of referenced substreams that are coded as coupled stereo channels.

Mono or stereo coding shall be only allowed for the version of this specification.
- Each pair of coupled stereo channels in the same ChannelGroup shall be coded as stereo mode to generate one single substream and each of non-coupled channels in the same ChannelGroup shall be coded as mono mode to generate one single substream.
	- <dfn noexport>Coupled stereo channels</dfn>: L/R, Ls/Rs, Lss/Rss, Lrs/Rrs, Ltf/Rtf, Ltb/Rtb
	- <dnf noexport>Non-coupled channels</dfn>: C, LFE, L

The order of substreams in each ChannelGroup shall be as follows:
- Coupled Substreams comes first and followed by non-coupled Substreams.
- Coupled Substreams for surround channels comes first and followed by one(s) for top channels.
- Coupled Substreams for front channels comes first and followed by one(s) for side, rear and back channels.
- Coupled Substreams for side channels comes first and followed by one(s) for rear channels.
- Center channel comes first and followed by LFE and followed by the other one.
- Where, <dfn noexport>non-coupled substream</dfn> is a coded substream from one of non-coupled channels.

<dfn noexport>output_gain_flags</dfn> indicates the channels which output_gain is applied to. If a bit set to 1, output_gain shall be applied to the channel. Otherwise, output_gain shall not be applied to the channel.


<pre class = "def">
Bit position : Channel Name
    b5(MSB)  : Left channel (L1, L2, L3)
      b4     : Right channel (R2, R3)
      b3     : Left Surround channel (Ls5)
      b2     : Right Surround channel (Rs5)
      b1     : Left Top Front channel (Ltf)
      b0     : Right Top Front channel (Rtf)

</pre>

<dfn noexport>output_gain</dfn> indicates the gain value to be applied to the mixed channels which are indicated by output_gain_flags. It is 20*log10 of the factor by which to scale the mixed channels. It is stored in a 16-bit, signed, two’s complement fixed-point value with 8 fractional bits (i.e. Q7.8 in [[!Q-Format]]). Where, each mixed channel is generated by downmixing two or more input channels.


### Ambisonics Config Syntax and Semantics ### {#syntax-ambisonics-config}

[=ambisonics_config()=] contains information regarding the configuration of Ambisonics. In this specification, the [[!AmbiX]] format is adopted, which uses Ambisonics Channel Number (ACN) channel ordering and normalizes the channels with Schmidt Semi-Normalization (SN3D).

<b>Syntax</b>

```
class ambisonics_config() {
  leb128() ambisonics_mode;
  if (ambisonics_mode == MONO) {
    ambisonics_mono_config();
  } else if (ambisonics_mode == PROJECTION) {
    ambisonics_projection_config();
  }
}

class ambisonics_mono_config() {
  unsigned int (8) output_channel_count (C);
  unsigned int (8) substream_count (N);
  unsigned int (8 * C) channel_mapping;
}

class ambisonics_projection_config() {
  unsigned int (8) output_channel_count (C);
  unsigned int (8) substream_count (N);
  unsigned int (8) coupled_substream_count (M);
  unsigned int (16 * (N + M) * C) demixing_matrix;
}
```

<b>Semantics</b>

<dfn noexport>ambisonics_mode</dfn> specifies the method of coding Ambisonics.

<pre class = "def">
ambisonics_mode: Method of coding Ambisonics.
   0    : MONO
   1    : PROJECTION
</pre>

If ambisonics_mode is equal to MONO, this indicates that the Ambisonics channels are coded as individual mono substreams. For IAMF-LPCM, [=ambisonics_mode=] shall be equal to MONO. 

If ambisonics_mode is equal to PROJECTION, this indicates that the Ambisonics channels are first linearly projected onto another subspace before coding as a mix of coupled stereo and mono substreams.

<dfn noexport>output_channel_count</dfn> complies with [=channel count=] in [[!RFC8486]] with following restrictions:
- The allowed numbers of [=output_channel_count=] are (1+n)^2, where n = 0, 1, 2, ..., 14. 
- In other words, the scene-based audio element shall not include non-diegetic channels.

[=substream_count=] specifies the number of audio substreams. It must be the same as [=num_substreams=] in its corresponding audio_element().

<dfn noexport>channel_mapping</dfn> complies with the one for [=ChannelMappingFamily=] = 2 in [[!RFC8486]].

[=coupled_substream_count=] specifies the number of referenced substreams that are coded as coupled stereo channels, where M <= N.

<dfn noexport>demixing_matrix</dfn> complies with the one for [=ChannelMappingFamily=] = 3 in [[!RFC8486]] except the byte order of each of matrix coefficients is converted to big endian.

The order of substreams in ChannelGroup shall conform to [[RFC8486]].


## Mix Presentation OBU Syntax and Semantics ## {#obu-mixpresentation}

This section specifies the OBU payload of OBU_IA_Mix_Presentation.

The metadata in mix_presentation() specifies how to render, process and mix one or more audio elements, with details provided in [[#processing-mixpresentation]].

An IA sequence may have one or more mix presentations specified. The IA parser shall select the appropriate mix presentation to process according to the rules specified in [[#processing-mixpresentation-selection]].

A mix presentation may contain one or more sub-mixes. Common use-cases may specify only one sub-mix, which includes all rendered and processed audio elements used in the mix presentation. The use-case for specifying more than one sub-mix arises if an IA multiplexer is merging two or more IA sequences. In this case, it may choose to capture the loudness information from the original IA sequences in multiple sub-mixes, instead of recomputing the loudness information for the final mix.

<b>Syntax</b>
```
class mix_presentation_obu() {
  leb128() mix_presentation_id;
  mix_presentation_annotations();

  leb128() num_sub_mixes;
  for (i = 0; i < num_sub_mixes; i++) {	  
    leb128() num_audio_elements;
    for (j = 0; j < num_audio_elements; j++) {
      leb128() audio_element_id;
      mix_presentation_element_annotations();
      rendering_config();
      element_mix_config();
    }
    output_mix_config();
    
    leb128() num_layouts;
    for (j = 0; j < num_layouts; j++) {
      layout loudness_layout;
      loudness_info loudness; 
    }
  }
}  
```

<b>Semantics</b>

<dfn noexport>mix_presentation_id</dfn> defines an identifier for a Mix Presentation. Within an IA Sequence, there shall be exactly one non-redundant Mix Presentation OBU with a given identifier. This identifier may be used by the application to select which Mix Presentation(s) to offer.

<dfn noexport>mix_presentation_annotations()</dfn> is a class that provides informational metadata that an IA parser should refer to when selecting the mix presentation to use. The metadata may also be used by the playback system to display information to the user, but is not used in the rendering or mixing process to generate the final output audio signal.

<dfn noexport>num_sub_mixes</dfn> specifies the number of sub-mixes.

<dfn noexport>num_audio_elements</dfn> specifies the number of audio elements that are used in this mix presentation to generate the final output audio signal for playback.

<dfn value noexport for ="mix_presentation_obu()">audio_element_id</dfn> indicates the identifier for an Audio Element which this Mix Presentation refers to.

<dfn noexport>rendering_config()</dfn> is a class that provides the metadata required for rendering the referenced audio element. 

<dfn noexport>element_mix_config()</dfn> is a class that provides the metadata required for applying any processing to the referenced and rendered audio element before being summed with other processed audio elements.

<dfn noexport>output_mix_config()</dfn> is a class that provides the metadata required for post-processing the mixed audio signal to generate the audio signal for playback.

<dfn noexport>num_layouts</dfn> specifies the number of layouts for this sub-mix which the loudness informations were measured on.

<dfn noexport>loudness_layout</dfn> identifies the layout that was used to measure the loudness information provided in this sub-mix.

<dfn noexport>loudness</dfn> provides the loudness information which was measured on [=loudness_layout=] for the mixed audio elements by this sub-mix.

The layout specified in [=loudness_layout=] should not be higher than the highest layout among layouts provided by the audio elements. In other words, rendering from an audio element with the highest layout to the [=loudness_layout=] should not require an upmix.

If one sub-mix of Mix Presentation OBU includes only one single scalable channel audio, then it complies with as follows:
- [=num_layouts=] shall be greater than or equal to [=num_layers=] specified in [=scalable_channel_layout_config()=] of Audio Element OBU for the [=audio_element_id=].
- The set of [=loudness_layout=]s shall include all of [=loudspeaker_layout=]s specified in the [=channel_audio_layer_config()=]s of Audio Element OBU for the [=audio_element_id=]. 

The highest [=loudness_layout=] specified in one sub-mix is the layout which was used for authoring the sub-mix.

Each sub-mix shall include [=loudness_layout=] to identify [=Loudspeaker configuration for Sound System A (0+2+0)=] (i.e. Stereo). In other words, each sub-mix shall include loudness_info() for Stereo. 

### Mix Presentation Annotations Syntax and Semantics ### {#obu-mixpresentation-annotation}

<b>Syntax</b>
```
class mix_presentation_annotations() {
  string mix_presentation_friendly_label;
}
```

<b>Semantics</b>

<dfn noexport>mix_presentation_friendly_label</dfn> specifies a human-friendly label to describe this mix presentation.


### Mix Presentation Element Annotations Syntax and Semantics ### {#obu-mixpresentation-elementannotation}

<b>Syntax</b>
```
class mix_presentation_element_annotations() {
  string audio_element_friendly_label;
}
```

<b>Semantics</b>

<dfn noexport>audio_element_friendly_label</dfn> specifies a human-friendly label to describe the referenced audio element.

### Rendering Config Syntax and Semantics ### {#syntax-rendering-config}

During playback, an audio element should be rendered using a pre-defined renderer according to [[#processing-mixpresentation-rendering]]. In this version of the specification, no additional metadata is required to configure the renderers, and as such, <code>rendering_config()</code> has an empty payload.

<b>Syntax</b>

```
class rendering_config() {
}
```

<b>Semantics</b>

### Element Mix Config Syntax and Semantics ### {#syntax-element-mix-config}

[=element_mix_config()=] provides a gain value to be applied to the rendered audio element signal.

<b>Syntax</b>

```
class element_mix_config() {
  MixGainParamDefinition mix_gain;
}
```

```
class MixGainParamDefinition() extends ParamDefinition() {
  signed int (16) default_mix_gain;
}
```

<b>Semantics</b>

<dfn noexport>mix_gain</dfn> provides the parameter definition for the gain value that is applied to all channels of the rendered audio element signal. The parameter definition is provided by MixGainParamDefinition() and the corresponding parameter data to be provided in parameter blocks is specified in mix_gain_parameter_data().

<dfn noexport>default_mix_gain</dfn> specifies the default mix gain value to apply when there are no mix gain parameter blocks provided. This value is expressed in dB and shall be applied to all channels in the rendered audio element. It is stored as a 16-bit, signed, two's complement fixed-point value with 8 fractional bits (i.e. Q7.8 in [[!Q-Format]]).


### Output Mix Config Syntax and Semantics ### {#obu-mixpresentation-outputmix}

output_mix_config() provides a gain value to be applied to the mixed audio signal.

<b>Syntax</b>

```
class output_mix_config() {
  MixGainParamDefinition output_mix_gain;
}
```

<b>Semantics</b>

<dfn noexport>output_mix_gain</dfn> provides the parameter definition for the gain value that is applied to all channels of the mixed audio signal. The parameter definition is provided by MixGainParamDefinition() and the corresponding parameter data to be provided in parameter blocks is specified in mix_gain_parameter_data().


### Layout Syntax and Semantics ### {#syntax-layout}

The layout class specifies either a binaural system or the list of physical loudspeaker positions according to [[!ITU2051-3]].

<b>Syntax</b>

```
class layout() {
  unsigned int (2) layout_type;
  
  if (layout_type == LOUDSPEAKERS_SP_LABEL) {
    unsigned int (6) num_loudspeakers;
    for (i = 0; i < num_loudspeakers; i++) {
      unsigned int (8) sp_label;
    }
  } 
  else if (layout_type == LOUDSPEAKERS_SS_CONVENTION) {
    unsigned int (4) sound_system;
    unsigned int (2) reserved;
  }
  else if (layout_type == BINAURAL or NOT_DEFINED) {
    unsigned int (6) reserved;
  }
}
```

<b>Semantics</b>

<dfn noexport>layout_type</dfn> specifies the layout type. 

<pre class = "def">
layout_type : Layout type
     0      : NOT_DEFINED
     1      : LOUDSPEAKERS_SP_LABEL
     2      : LOUDSPEAKERS_SS_CONVENTION
     3      : BINAURAL
</pre>

- A value of 0 indicates no specific layout.
- A value of 1 indicates that the layout is defined using the [=SP Label=] of [[!ITU2051-3]].
- A value of 2 indicates that the layout is defined using the sound system convention of [[!ITU2051-3]].
- A value of 3 indicates that the layout is binaural.

<dfn noexport>num_loudspeakers</dfn> specifies the number of loudspeakers.

<dfn noexport>sp_label</dfn> defines the [=SP Label=] as specified in [[!ITU2051-3]].


<style>
.col_border {
  border-left: 1px solid var(--def-border);
}
</style>

<table class="def">
<tr>
  <th>sp_label</th><th>SP label</th><th class="col_border">sp_label</th><th>SP label</th><th class="col_border">sp_label</th><th>SP label</th>
</tr>
<tr>
  <td>0</td><td>M+000</td><td class="col_border">18</td><td>U+000</td><td class="col_border">36</td><td>B+000</td>
</tr>
<tr>
  <td>1</td><td>M+022</td><td class="col_border">19</td><td>U+022</td><td class="col_border">37</td><td>B+022</td>
</tr>
<tr>
  <td>2</td><td>M-022</td><td class="col_border">20</td><td>U-022</td><td class="col_border">38</td><td>B-022</td>
</tr>
<tr>
  <td>3</td><td>M+SC</td><td class="col_border">21</td><td>U+030</td><td class="col_border">39</td><td>B+030</td>
</tr>
<tr>
  <td>4</td><td>M-SC</td><td class="col_border">22</td><td>U-030</td><td class="col_border">40</td><td>B-030</td>
</tr>
<tr>
  <td>5</td><td>M+030</td><td class="col_border">23</td><td>U+045</td><td class="col_border">41</td><td>B+045</td>
</tr>
<tr>
  <td>6</td><td>M-030</td><td class="col_border">24</td><td>U-045</td><td class="col_border">42</td><td>B-045</td>
</tr>
<tr>
  <td>7</td><td>M+045</td><td class="col_border">25</td><td>U+060</td><td class="col_border">43</td><td>B+060</td>
</tr>
<tr>
  <td>8</td><td>M-045</td><td class="col_border">26</td><td>U-060</td><td class="col_border">44</td><td>B-060</td>
</tr>
<tr>
  <td>9</td><td>M+060</td><td class="col_border">27</td><td>U+090</td><td class="col_border">45</td><td>B+090</td>
</tr>
<tr>
  <td>10</td><td>M-060</td><td class="col_border">28</td><td>U-090</td><td class="col_border">46</td><td>B-090</td>
</tr>
<tr>
  <td>11</td><td>M+090</td><td class="col_border">29</td><td>U+110</td><td class="col_border">47</td><td>B+110</td>
</tr>
<tr>
  <td>12</td><td>M-090</td><td class="col_border">30</td><td>U-110</td><td class="col_border">48</td><td>B-110</td>
</tr>
<tr>
  <td>13</td><td>M+110</td><td class="col_border">31</td><td>U+135</td><td class="col_border">49</td><td>B+135</td>
</tr>
<tr>
  <td>14</td><td>M-110</td><td class="col_border">32</td><td>U-135</td><td class="col_border">50</td><td>B-135</td>
</tr>
<tr>
  <td>15</td><td>M+135</td><td class="col_border">33</td><td>U+180</td><td class="col_border">51</td><td>B+180</td>
</tr>
<tr>
  <td>16</td><td>M-135</td><td class="col_border">34</td><td>UH+180</td><td class="col_border">52</td><td>LFE1</td>
</tr>
<tr>
  <td>17</td><td>M+180</td><td class="col_border">35</td><td>T+000</td><td class="col_border">53</td><td>LFE2</td>
</tr>
<tr>
  <td></td><td></td><td class="col_border"></td><td></td><td class="col_border">54 ~ 256</td><td>Reserved</td>
</tr>
</table>


<dfn noexport>sound_system</dfn> specifies the sound system A to J as specified in [[!ITU2051-3]], 7.1.2ch and 3.1.2ch of [=loudspeaker_layout=] as follows:
 - 0: It indicates [=Loudspeaker configuration for Sound System A (0+2+0)=]
 - 1: It indicates [=Loudspeaker configuration for Sound System B (0+5+0)=]
 - 2: It indicates [=Loudspeaker configuration for Sound System C (2+5+0)=]
 - 3: It indicates [=Loudspeaker configuration for Sound System D (4+5+0)=]
 - 4: It indicates [=Loudspeaker configuration for Sound System E (4+5+1)=]
 - 5: It indicates [=Loudspeaker configuration for Sound System F (3+7+0)=]
 - 6: It indicates [=Loudspeaker configuration for Sound System G (4+9+0)=]
 - 7: It indicates [=Loudspeaker configuration for Sound System H (9+10+3)=]
 - 8: It indicates [=Loudspeaker configuration for Sound System I (0+7+0)=]
 - 9: It indicates [=Loudspeaker configuration for Sound System J (4+7+0)=]
 - 10: It indicates the same loudspeaker configuration as [=loudspeaker_layout=] = 0110 (i.e. 7.1.2ch)
 - 11: It indicates the same loudspeaker configuration as [=loudspeaker_layout=] = 1000 (i.e. 3.1.2ch)
 - 12 ~ 15: Reserved

### Loudness Info Syntax and Semantics ### {#obu-mixpresentation-loudness}

loudness_info() provides loudness information for a given audio signal.

All signed values are stored as signed Q7.8 fixed-point values (in [[!Q-Format]]).

<b>Syntax</b>

```
class loudness_info() {
  unsigned int (8) info_type;
  signed int (16) integrated_loudness;
  signed int (16) digital_peak;

  if (info_type & 1) {
    signed int (16) true_peak;
  }

  if (info_type & 2) {
    unsigned int (8) num_anchored_loudness;
    for (i = 0; i < num_anchored_loudness; i++) {
      unsigned int (8) anchor_element;
      signed int (16) anchored_loudness;
    }
  }
}
```

<b>Semantics</b>

<dfn noexport>info_type</dfn> is a bitmask that specifies the type of optional loudness information provided. The bits are set as follows, where the first bit is the LSB:

<pre class = "def">
 Bit : Type of information provided
  0  : True peak
  1  : Anchored Loudness (one or more)
 2~7 : Reserved
</pre>

<dfn noexport>integrated_loudness</dfn> provides the program integrated loudness information, specified in [=LKFS=] as defined in [[!ITU1770-4]], and measured according to [[!ITU1770-4]].

<dfn noexport>digital_peak</dfn> specifies the digital (sampled) peak value of the audio signal, specified in dBFS.

<dfn noexport>true_peak</dfn> specifies the true peak of the audio signal, specified in dBFS and measured according to [[!ITU1770-4]].

<dfn noexport>anchor_element</dfn> specifies the anchor element used in computation of the anchored_loudness which follows, as defined in [[!ISOIEC-23091-3-2018]], as follows:

<pre class = "def">
   0   : Unknown
   1   : Dialogue
   2   : Album
 3~255 : Reserved
</pre>

There shall be no duplicate values of [=anchor_element=] within one loudness_info().

<dfn noexport>anchored_loudness</dfn> specifies the loudness information according to the anchor element, specified in [=LKFS=] as defined in [[!ITU1770-4]].



NOTE: [[!ITU1770-4]] adopts the convention of using the dBov unit for dBFS, where the RMS value of a full-scale square wave is 0 dBov. The same convention is adopted here.

## Parameter Block OBU Syntax and Semantics ## {#obu-parameterblock}

This section specifies the OBU payload of OBU_IA_Parameter_Block.

The metadata specified in this OBU defines the parameter values for an algorithm for an indicated duration, including any animation of the parameter values over this duration. The metadata are used in conjunction with a corresponding parameter definition and parameter data specification. The parameter definition is specified based on [=ParamDefinition()=]. The parameter data provides the values to apply in each parameter block. These are specified using the [=AnimatedParameterData()=] function template if parameter animation is supported.

<b>Syntax</b>

```
class parameter_block_obu() {
  leb128() parameter_id;
  
  (param_definition_type, param_definition_mode, duration, num_subblocks, constant_subblock_duration, subblock_duration) = get_param_definition(parameter_id);
  
  if (param_definition_mode) {
    leb128() duration;
    leb128() num_subblocks;
    leb128() constant_subblock_duration;
  }

  for (i = 0; i < num_subblocks; i++) {
    if (param_definition_mode) {
      if (constant_subblock_duration == 0) {
        leb128() subblock_duration;
      }
    }

    if (param_definition_type == PARAMETER_DEFINITION_MIX_GAIN) {
      mix_gain_parameter_data();
    }
    if (param_definition_type == PARAMETER_DEFINITION_DEMIXING) {
      demixing_info_parameter_data();
    }
    if (param_definition_type == PARAMETER_DEFINITION_RECON_GAIN) {
      recon_gain_info_parameter_data();
    }
  }
}
```

<b>Semantics</b>

<dfn noexport>parameter_id</dfn> defines an identifier for a Parameter. Within an IA Sequence, there shall be exactly one non-redundant Audio Element OBU with this identifier. Parameter Block OBU refer to the Parameter through this identifier.

<dfn noexport>get_param_definition()</dfn> is a run-time function to get the parameter definition type, the parameter definition mode, duration, num_subblocks, constant_subblock_duration and subblock_duration mapped to the parameter_id. 

<dfn value noexport for="parameter_block_obu()">duration</dfn> specifies the duration for which this parameter block is valid and applicable. 

<dfn value noexport for="parameter_block_obu()">num_subblocks</dfn> specifies the number of different sets of parameter values specified in this parameter block, where each set describes a different subblock of the timeline, contiguously.

<dfn value noexport for="parameter_block_obu()">constant_subblock_duration</dfn> specifies the duration of each subblock, in the case where all subblocks except the last subblock have equal durations. If all subblocks except the last subblock do not have equal durations, the value of constant_subblock_duration shall be set to 0. 

Audio Element OBU and/or Mix Presentation OBU is mapping a parameter_id to the parameter definition type. So, IA decoders can know the definition type mapped to the parameter_id.

<dfn value noexport for="parameter_block_obu()">subblock_duration</dfn> specifies the duration for the given subblock.

Each value of duration, constant_subblock_duration and subblock_duration shall be expressed as the number of ticks at the [=parameter_rate=] specified in the corresponding parameter definition.

### Mix Gain Parameter Data Syntax and Semantics ### {#syntax-mix-gain-param}

<b>Syntax</b>

```
class mix_gain_parameter_data() {
  leb128() animation_type;
  AnimatedParameterData<signed int (16)> param_data;
}
```

<b>Semantics</b>

<dfn noexport>animation_type</dfn> specifies the type of animation applied to the parameter values.

<dfn noexport>param_data</dfn> uses the AnimatedParameterData function template. Each of the values defined within this instance (start_point_value, end_point_value and control_point_value) is expressed in dB and shall be applied to all channels in the rendered audio element. They are stored as 16-bit, signed, two's complement fixed-point values with 8 fractional bits (i.e. Q7.8 in [[!Q-Format]]).

<pre class = "def">
animation_type : Animation Type
       0       : STEP
       1       : LINEAR
       2       : BEZIER
</pre>

Classes that take [=animation_type=] as an input argument use the <dfn noexport>AnimatedParameterData()</dfn> function template. The method of applying the animation is described in [[#processing-animated-params]].

```
template <class T>
class AnimatedParameterData(animation_type) {
  if (animation_type == STEP) {
    T start_point_value;
  }
  if (animation_type == LINEAR) {
    T start_point_value;
    T end_point_value;
  }
  if (animation_type == BEZIER) {
    T start_point_value;
    T end_point_value;
    T control_point_value;
    unsigned int (8) control_point_relative_time;
  }
}
```

<dfn noexport>start_point_value</dfn> specifies the parameter value that is applied at the start of the subblock.

<dfn noexport>end_point_value</dfn> specifies the parameter value that is applied at the end of the subblock.

<dfn noexport>control_point_value</dfn> specifies the parameter value of the middle control point of a quadratic Bezier curve, i.e. its y-axis value.

<dfn noexport>control_point_relative_time</dfn> specifies the time of the middle control point of a quadratic Bezier curve, i.e. its x-axis value. This value is expressed as a fraction of the parameter subblock duration with valid values in the range of 0 and 1, inclusively. A value equal to 0 or 1 indicates that this animation implements a linear Bezier curve, in which case control_point_value shall be ignored by the IA parser. It is stored as an 8-bit, unsigned, fixed-point value with 8 fractional bits (i.e. Q0.8 in [[!Q-Format]]).

### Demixing Info Parameter Data Syntax and Semantics ### {#syntax-demixing-info}

<dfn noexport>demixing_info_parameter_data()</dfn> specifies demixing parameter mode to be used to reconstruct output channel audio according to its [=loudspeaker_layout=].

<b>Syntax</b>

```
class demixing_info_parameter_data() {
  unsigned int (3) dmixp_mode;
  unsigned int (5) reserved;
}
```

<b>Semantics</b>

<dfn noexport>dmixp_mode</dfn> indicates a mode of pre-defined combinations of five demix parameters.
- 0: mode1, (alpha, beta, gamma, delta, w_idx_offset) = (1, 1, 0.707, 0.707, -1)
- 1: mode2, (alpha, beta, gamma, delta, w_idx_offset) = (0.707, 0.707, 0.707, 0.707, -1)
- 2: mode3, (alpha, beta, gamma, delta, w_idx_offset) = (1, 0.866, 0.866, 0.866, -1)
- 3: reserved
- 4: mode1, (alpha, beta, gamma, delta, w_idx_offset) = (1, 1, 0.707, 0.707, 1)
- 5: mode2, (alpha, beta, gamma, delta, w_idx_offset) = (0.707, 0.707, 0.707, 0.707, 1)
- 6: mode3, (alpha, beta, gamma, delta, w_idx_offset) = (1, 0.866, 0.866, 0.866, 1)
- 7: reserved

<dfn noexport>alpha</dfn> and <dfn noexport>beta</dfn> are gain values used for S7to5 down-mixer, <dfn noexport>gamma</dfn> for T4to2 down-mixer, <dfn noexport>delta</dfn> for S5to3 down-mixer and <dfn noexport>w_idx_offset</dfn> is the offset to generate a gain value <dfn noexport>w</dfn> used for T2toTF2 down-mixer.

<center><img src="images/Down-mix Mechanism.png" style="width:100%; height:auto;"></center>
<center><figcaption></b>IA Down-mix Mechanism</figcaption></center>

### Recon Gain Info Parameter Data Syntax and Semantics ### {#syntax-recon-gain-info}

<dfn noexport>recon_gain_info_parameter_data()</dfn> contains recon gain values for demixed channels.

NOTE: [=recon_gain_info_parameter_data()=] is required to compensate the propagated errors by De-mixer and Gain modules specified in [[#processing-scalablechannelaudio-demixer]] and [[#processing-scalablechannelaudio-gain]] due to the error caused by lossy codecs such as IAMF-OPUS and IAMF-AAC-LC. However, it is not required for lossless codecs such as IAMF-FLAC and IAMF-LPCM because the propagated errors are negligible.

<b>Syntax</b>

```
class recon_gain_info_parameter_data() {
  for (i=0; i< num_layers; i++) {
    if (recon_gain_is_present_flag(i) == 1) {
      leb128() recon_gain_flags(i);
      for (j=0; j< n(i); j++) {
        if (recon_gain_flag(i)(j) == 1)
          unsigned int (8) recon_gain;
      }
    }
  }
}
```

<b>Semantics</b>

<dfn noexport>recon_gain_flags</dfn> indicates the channels which recon_gain is applied to.

<left><img src="images/Recon_Gain_Flags.png" style="width:100%; height:auto;"></left>
<center><figcaption>Table for Recon Gain Flags</figcaption></center>

The each bit of [=recon_gain_flags=] indicates the presence of [=recon_gain=] applied to the channel as depicted in the above figure.
 - 0: It indicates that no [=recon_gain=] presents for the channel.
 - 1: It indicates that [=recon_gain=] presents for the channel.

<dfn noexport>n(i)</dfn> indicates the number of bits for recon_gain_flag(i). It shall be 7 or 12 as depicted in the above figure. Where, i = 0, 1, ..., [=num_layers=] - 1.

<dfn noexport>recon_gain</dfn> indicates the gain value to be applied to the channel, which is indicated by [=recon_gain_flags=], after decoding of the associated frames and demixing operation. Where, the channel is indicated by recon_gain_flags. Detailed operation by using this value is specified in [[#processing-scalablechannelaudio-recongain]].


## Audio Frame OBU Syntax and Semantics ## {#obu-audioframe}

This section specifies OBU payloads of OBU_IA_Audio_Frame and OBU_IA_Audio_Frame_ID0 to OBU_IA_Audio_Frame_ID21. 

The first 22 audio substreams in an IA sequence may use the OBU types OBU_IA_Audio_Frame_ID0 to OBU_IA_Audio_Frame_ID21, which have predefined audio substream identifiers associated with them. This avoids the need to manually specify an [=audio_substream_id=].

[=audio_substream_id=] = 0 to [=audio_substream_id=] = 21 shall be assigned to Audio Frame OBUs with [=obu_type=] = 9 to 30, respectively. 

<b>Syntax</b>

```
class audio_frame_obu_with_no_id() {
  leb128() audio_substream_id;
  audio_frame_obu(audio_substream_id);
}
```

```
class audio_frame_obu() {
  unsigned int (8*coded_frame_size) audio_frame();
}
```

<b>Semantics</b>

<dfn noexport>audio_substream_id</dfn> defines an identifier for a Substream. In this class (i.e. when [=obu_type=] = 8), the value shall be greater than 21. Within an IA Sequence, there shall be exactly one non-redundant Audio Element OBU with this identifier. Audio Frame OBUs that provide coded data for this Substream use this identifier.

<dfn noexport>coded_frame_size</dfn> is the size of [=audio_frame()=] in bytes.

<dfn noexport>audio_frame()</dfn> is the raw coded audio data for the frame. It shall be [=opus packet=] of [[!RFC6716]] for IAMF-OPUS, [=raw_data_block()=] of [[!AAC]] for IAMF-AAC-LC and [=FRAME=] of [[!FLAC]] for IAMF-FLAC.

For IAMF-LPCM, [=audio_frame()=] shall be LPCM samples. When more than one byte is used to represent a LPCM sample, the byte order is indicated in [=sample_format_flags=]. 

## Temporal Delimiter OBU Syntax and Semantics ## {#obu-temporaldelimiter}

This section specifies the OBU payload of OBU_IA_Temporal_Delimiter.

<b>Syntax</b>

```
class temporal_delimiter_obu() {
}
```

NOTE: The Temporal Delimiter OBU has an empty payload.

## Sync OBU Syntax and Semantics ## {#obu-sync}

This section specifies the OBU payload of OBU_IA_Sync.

<b>Syntax</b>

```
class sync_obu() {
  leb128() global_offset;
  leb128() num_obu_ids;
  for (i = 0; i < num_obu_ids; i++) {
    leb128() obu_id;
    unsigned int (1) obu_data_type;
    unsigned int (1) reinitialize_decoder;
    unsigned int (6) reserved;
    sleb128() relative_offset;
  }
}
```

<b>Semantics</b>

<dfn noexport>global_offset</dfn> specifies the offset that is applied to all substreams and parameters specified in this Sync OBU, in addition to their individual relative offsets.

For this version of the specification, the value of global_offset shall be set to 0.

<dfn noexport>num_obu_ids</dfn> specifies the number of substream and parameter IDs that this Sync OBU specifies the offset for.

<dfn noexport>obu_id</dfn> specifies the unique ID associated with the substream or parameter that is being referred to.

<dfn noexport>obu_data_type</dfn> specifies the type of data that is being referred to.

<pre class = "def">
obu_data_type : Type of OBU data
      0       : SUBSTREAM
      1       : PARAMETER
</pre>

<dfn noexport>reinitialize_decoder</dfn> is used to specify the behaviour of a decoder when encountering gaps in the audio substream, where the gap is identified as described in [[#standalone-synchronizing-data-obus]]. If obu_data_type does not equal SUBSTREAM, an IAMF-OBU parser shall ignore this field.

If reinitialize_decoder = 0, the decoder shall not be reinitialized before decoding the audio frames after the gap. This may be used in the case where it is preferable for the decoder to fill the gap with silence instead.

If reinitialize_decoder = 1, the decoder shall be reinitialized before decoding the audio frames after the gap. If a pre-skip is specified in the relevant Codec Config OBU, it is applicable after reinitializing the decoder.

For this version of the specification, the value of reinitialize_decoder shall be set to 0. If a value of 1 is seen, the IA sequence shall be rejected as invalid.

<dfn value noexport for="sync_obu()">reserved</dfn> shall be set to 0. Reserved units are for future use and shall be ignored by an IAMF-OBU parser.

<dfn noexport>relative_offset</dfn> is the offset to position the first audio frame (before trimming) or parameter block with the referenced obu_id that comes after this Sync OBU with respect to the timeline generated before this Sync OBU. If this Sync OBU is the first one, it is the offset from 0. Otherwise, it is the offset from the end of the timeline of Substreams generated from the previous Sync OBU.

The difference, [=relative_offset=](P) - [=relative_offset=](A), shall be the offset to position the first audio sample where the first parameter value of the first parameter block that comes after this Sync OBU is applied to.
- Where, [=relative_offset=](P) is [=relative_offset=] of [=obu_id=] for the parameter and [=relative_offset=](A) is [=relative_offset=] of [=obu_id=] for the substream which the parameter is applied to. 

The offset shall be indicated in the number of ticks at the sample rate specified in the corresponding substream or Codec Config OBU. For IAMF-OPUS, the sample rate is 48000Hz.

IA encoder and decoder operations related to this field are specified in [[#standalone-synchronizing-data-obus]].


## Codec Specific ## {#codec-specific}

This section defines codec specific information for Codec_Specific_Info and Substream.

- <dfn noexport>Codec_Specific_Info</dfn> is composed of [=Codec_ID=] and [=Decoder_Config()=]. Codec_ID indicates the codec which has been used to generate a given substream within IA sequence and Decoder_Config() indicates the decoding parameters which are applied to the substream within IA sequence.

For legacy codecs, Decoder_Config() shall be exactly the same information as the conventional file parser feeds to the codec decoders for decoding of the substream. For future codecs, Decoder_Config() shall include all of decoding parameters which are required to decode Substreams.

- Substream is a raw coded stream for one or more channels. Substream format is exactly the same as the sample format (before packing OBU and except parameter blocks) for the audio file which consists of only one single coded stream by the Codec_ID.


### IAMF-OPUS Specific ### {#iamf-opus-specific}

[=Codec_ID=] shall be 'Opus'.

[=Decoder_Config()=] for IAMF-OPUS conforms to [=ID Header=] with [=ChannelMappingFamily=] = 0 of [[!RFC7845]] with following constraints:
- [=Magic Signature=] shall not be present.
- [=Output Channel Count=] must be set to 2. [=Output Channel Count=] can be ignored because the real value can be determined from the Audio Element OBU and from the opus packet header.
- [=Pre-skip=] shall be same as the number of audio samples to be trimmed at the start of substreams.
- [=Output Gain=] shall not be used. In other words, it shall be set to 0dB.
- The byte order of each field in [=ID Header=] is converted to big endian.

Substream format is [=opus packet=] of [[!RFC6716]] which contains only one single frame of mono or stereo channels and which has non-delimiting frame structure.


### IAMF-AAC-LC Specific ### {#iamf-aac-lc-specific}

[=Codec_ID=] shall be 'mp4a'.

[=Decoder_Config()=] for IAMF-AAC-LC is [=DecoderConfigDescriptor()=] of [[!MP4-Systems]], which is a subset of [=ESDBox=] for [[!MP4-Audio]], with following constraints:
- [=objectTypeIndication=] = 0x40
- [=streamType=] = 0x05 (Audio Stream)
- [=upstream=] = 0
- [=decSpecificInfo()=]: The syntax and values conforms to [=AudioSpecificConfig()=] of [[!MP4-Audio]] with following constraints:
	- [=audioObjectType=] = 2
	- [=channelConfiguration=] must be set to 2. The real value can be implied from the Audio Element OBU.
	- [=GASpecificConfig()=]: The syntax and values conform to [=GASpecificConfig()=] of [[!MP4-Audio]] with following constraints:
		- [=frameLengthFlag=] = 0 (1024 lines IMDCT)
		- [=dependsOnCoreCoder=] = 0
		- [=extensionFlag=] = 0

Substream format is one single [=raw_data_block()=] of [[!AAC]] which contains only one single frame of mono or stereo channels.

### IAMF-FLAC Specific ### {#iamf-flac-specific}

[=Codec_ID=] shall be 'fLaC', the FLAC stream marker in ASCII, meaning byte 0 of the stream is 0x66, followed by 0x4C 0x61 0x43.

[=Decoder_Config()=] for IAMF-FLAC is [=METADATA_BLOCK=] of [[!FLAC]].

Substream format is [=FRAME=] of [[!FLAC]], which is composed of [=FRAME_HEADER=], followed by [=SUBFRAME=](s) (one [=SUBFRAME=] per channel) and followed by [=FRAME_FOOTER=].

### IAMF-LPCM Specific ### {#iamf-lpcm-specific}

[=Codec_ID=] shall be 'ipcm'.

[=Decoder_Config()=] for IAMF-LPCM is as follows:

```
class decoder_config(ipcm) {
  unsigned int (8) sample_format_flags;
  unsigned int (8) sample_size;
  unsigned int (32) sample_rate;
}
```
<dfn noexport>sample_format_flags</dfn> complies with [=format_flags=] specified in [[!MP4-PCM]]. In other words, 0x01 indicates little-endian PCM sample format and 0x00 indicates big-endian PCM sample format.

<dfn noexport>sample_size</dfn> complies with [=PCM_sample_size=] specified in [[!MP4-PCM]]. In other words, it shall take a value from the set 16, 24 and 32. 

<dfn noexport>sample_rate</dfn> indicates the sample rate of the input audio in Hz. It shall take a value from the set 44.1k, 16k, 32k, 48k and 96k.

Substream format is one [=audio_frame()=] of Audio_Frame_OBU which contains only one single PCM audio frame of mono or stereo channels.
	- In case of that [=audio_frame()=] contains one single PCM audio frame of stereo channels, the ith audio sample of the left channel is followed by the ith audio sample of the right channel, and then the (i+1)th audio sample of the left channel is followed by the (i+1)th audio sample of the right channel, where i = 1, 2, ..., [=num_samples_per_frame=].

# Profiles # {#profiles}

The IA Profiles define a set of capabilities that are required to parse, decode and process the corresponding IA sequence.

NOTE: In this section and subsections, the meaning of an unique OBU is that it is still unique if it only varies by reduntant flag.

## IA Simple Profile ## {#profiles-simple}

This section specifies the conformance points of the simple profile.

Restrictions on the IA sequence:

- There shall be only one unique Codec Config OBU.
- There shall be only one unique Audio Element OBU.
	- All of substreams shall have the same trimming information.
- There shall be only one unique set of Descriptor OBUs.
- There shall be only one Sync OBU placed immediately after each set of Descriptor OBUs, and no additional new Sync OBUs inserted anywhere in the sequence of data OBUs that follow.
- There shall not be any Temporal Delimiter OBUs present.
- [=version=] shall be set to 0 for this version of specification.
- [=profile_version=] shall be set to 0 for this version of specification.
	- [=num_sub_mixes=] shall be set to 1 for this profile.
- [=num_layers=] shall be set to 1 or up to 6 for Channel-based audio element (i.e. scalable channel audio).
    - In this case, [=demixing_info_parameter_data()=] and [=recon_gain_info_parameter_data()=] may be present in the IA sequence.
    - In case of simple scalable channel audio (e.g. mono for layer 1 & stereo for layer 2), demixing_info() and recon_gain_info() shall not be present in the bitstream.
    - When num_layers = 1, OBU_IA_Parameter_Block including demixing_info() may be present in the IA sequence and IA decoders may use the demixing_info() for dynamic down-mixing.
- All audio frames shall have aligned frame boundaries.
- All parameter definitons shall have the same [=param_definition_mode=].
	- When [=param_definition_mode=] = 0, duration, num_subblocks, constant_subblock_duration and subblock_duration shall be same in all parameter definitions, respectively.


Capabilities of the IA parser, decoder and processor:
- They shall be able to parse an IA sequence with the MSB four bits of [=profile_version=] = 0 and the MSB four bits of [=version=] = 0 (i.e., profile_version = 0 to 15 and version = 0 to 15).
- They shall be able to decode and process up to 16 channels.	
- They shall be able to reconstruct one audio element.
- They may use demixing_info_parameter_data() to do down-mixing.

## IA Base Profile ## {#profiles-base}

This section specifies the conformance points of the base profile.

Restrictions on IA sequence:
- There shall be only one unique Codec Config OBU.
- There shall be at most two unique Audio Element OBUs at any one time.
	- There shall be at most one Channel-based Audio Element having [=num_layers=] > 1 at any one time.
	- There shall be at most one Scene-based Audio Element at any one time.
	- In other words, following combinations of two Audio Elements are only allowed.
		- Channel-based Audio Element having [=num_layers=] = 1 + Channel-based Audio Element having [=num_layers=] = 1.
		- Channel-based Audio Element having [=num_layers=] = 1 + Channel-based Audio Element having [=num_layers=] > 1.
		- Scene-based Audio Element + Channel-based Audio Element having [=num_layers=] = 1.
		- Scene-based Audio Element + Channel-based Audio Element having [=num_layers=] > 1.
	- All of substreams shall have the same trimming information.
- There may be more than one unique set of Descriptor OBUs.
- There shall be only one Sync OBU placed immediately after each set of Descriptor OBUs, and no additional new Sync OBUs inserted anywhere in the sequence of data OBUs that follow.
- There may be Temporal Delimiter OBUs present.
- [=version=] shall be set to 0 for this version of specification.
- [=profile_version=] shall be set to 16 for this version of specification.
	- [=num_sub_mixes=] shall be set to 1 for this profile.
	- For a given Mix Presentation OBU, it shall include at most one scene-based audio element and it shall include at most one channel-based audio element with [=num_layers=] > 1 for this profile.
- [=num_layers=] shall be set to 1 or up to 6 for Channel-based audio element (i.e. scalable channel audio)
    - In this case, [=demixing_info_parameter_data()=] and [=recon_gain_info_parameter_data()=] may be present in the IA sequence.
    - In case of simple scalable channel audio (e.g. mono for layer 1 & stereo for layer 2), [=demixing_info_parameter_data()=] and [=recon_gain_info_parameter_data()=] shall not be present in the bitstream.
    - When num_layers = 1, OBU_IA_Parameter_Block including [=demixing_info_parameter_data()=] may be present in the IA sequence and IA decoders may use the [=demixing_info_parameter_data()=] for dynamic down-mixing.
- All audio frames shall have aligned frame boundaries.
- All parameter definitons shall have the same [=param_definition_mode=].
	- When [=param_definition_mode=] = 0, duration, num_subblocks, constant_subblock_duration and subblock_duration shall be same in all parameter definitions, respectively.


Capabilities of the IA parser, decoder and processor:
- They shall be able to parse an IA sequence with the MSB four bits of [=profile_version=] = 0 or 1 and the MSB four bits of [=version=] = 0 (i.e., profile_version = 0 to 31 and version = 0 to 15).
- They shall be able to support the capabilities of the Simple Profile.
- They shall be able to decode and process up to 18 channels.
	- Where, 18 channels means not the number of channels after mixing of two Audio Elements but the total sum of channels before mixing of two Audio Elements .
	- One specific example of 18 channels is 3rd-order Ambisonics (16 channels) + non-diegetic stereo (2 channels).
- They shall be able to reconstruct two audio elements.
- They shall be able to mix two audio elements.
- They shall be able to process short-lived audio elements.


# Standalone IAMF Representation # {#standalone}

This section details the order in which the OBUs are sequenced in a standalone IAMF representation. It further specifies how the Data OBUs are synchronized, with the aid of the Sync OBUs.

## OBU Sequence Order ## {#standalone-obu-sequence-order}

An IA sequence is composed of a series of OBUs in the sequence of a set of descriptor OBUs followed by their associated data OBUs, and where this pattern is repeated as many times as needed.

### Descriptor OBUs ### {#standalone-descriptor-obus}
A set of Descriptor OBUs shall be placed in the following order regardless of where they appear in the bitstream:

1. One Magic Code OBU
2. All Codec Config OBUs
3. All Audio Element OBUs
4. All Mix Presentation OBUs


### Data OBUs ### {#standalone-data-obus}

One Sync OBU shall be placed immediately after the Descriptor OBUs. This shall be followed by a sequence of Audio Frame OBUs, Parameter Block OBUs and Temporal Delimiter OBUs (if present), according to the rules below:

- Audio Frame OBUs and Parameter Block OBUs must be ordered by their implied timestamp in the timeline, and may be interleaved.
- If there are multiple Audio Frame OBUs that have the same implied start timestamp, they must be grouped by audio elements.
- Between two Sync OBUs, a sequence of audio frames or parameter blocks must be gapless.
- If an Audio Frame OBU or Parameter Block OBU has a substream or parameter ID that is not defined in the most recent Sync OBU, it must not appear in the bitstream, until a new Sync OBU is provided that specifies them.
- A Temporal Delimiter OBU may be inserted at the beginning of a temporal unit, defined as a set of all audio frames with the same start timestamp and the same duration from all substreams and all non-redundant parameter blocks with the start timestamp within the duration. A temporal unit may include redundant parameter blocks.
- If Temporal Delimiter OBUs are present, they shall be inserted at the beginning of every temporal unit.

Additionally, the following constraints apply to the Audio Frame and Parameter Block OBUs:

- Audio Frame OBUs shall be provided non-redundantly, such that for each substream, there shall not be two audio frames that are overlapping in time.
- Parameter Block OBUs may be provided redundantly, such that they contain the same data as a previously provided Parameter Block OBU for the same time region. In this case, the "obu_redundant_copy" field in the OBU header shall be set to 1.
- Redundant Parameter Block OBUs do not need to be ordered by their implied timestamp in the timeline. The implied timestamp should be inferred from the initial non-redundant version.
- Non-redundant Parameter Block OBUs must not provide data for overlapping time regions.

### Refreshing Descriptor OBUs ### {#standalone-obu-sequence-refreshes}

The above describes the full sequence of OBUs for a given set of descriptor OBUs and their associated data OBUs. If the IAMF configuration changes, a new set of descriptor OBUs is required. In that case, a new sequence of the complete set of descriptor OBUs, a Sync OBU and their corresponding data OBUs shall follow, in the same order as described above.

The descriptor OBUs may additionally be repeated redundantly and as frequently as necessary. In this case, the "obu_redundant_copy" field in the OBU header of each of the descriptor OBUs shall be set to 1.

If there is set of descriptor OBUs placed mid-stream, there may be parameter blocks that came before them which are still valid and applicable for the duration after the descriptor OBUs. In this case, these parameter blocks must be redundantly copied and placed after the first Sync OBU that follows the descriptor OBUs. This ensures that any receiver joining mid-stream and encountering a set of descriptor OBU is guaranteed to be able to receive the complete set of metadata that is applicable to all audio frames that come after.

## Synchronizing Data OBUs ## {#standalone-synchronizing-data-obus}

The audio frames and parameter data provided in the Data OBUs may be asynchronous; different audio substreams may have different audio frame sizes, parameter blocks may have different durations from the audio frames, or there may be gaps in a parameter's timeline. This section details how these Data OBUs may be synchronized, based on their duration and the information provided in the Sync OBUs.

The Sync OBU contains two pieces of information that apply to all substream and parameters that follow it: 

1) a relative offset for each of the substreams and parameters, and

2) a global offset.

The relative offsets describe how the substreams and parameters are positioned with respect to the timeline of Substreams generated from the previous Sync OBU. For example, from the previous Sync OBU, Substream 1 has a end timestamp 960 units, Substream 2 has a end timestamp 1024 units, Parameter 1 has a end timestamp 900 units and Parameter 2 has a end timestamp 1100 units. The relative offsets are calculated with respect to the maximum timeline of Substreams (i.e. 1024 units). So, Substream 1 has a relative offset that is 64 units before Substream 2, Substream 2 has  a relative offset that is 0 unit, Parameter 1 has a relative offset that is 124 units before Substream 2 and Parameter 2 has a relative offset that is 76 after Substream 2.

<table class="def">
<tr>
  <th>ID (name)</th><th>end timestamp</th><th>Relative offset</th>
</tr>
<tr>
  <td>N/A (Global offset)</td><td>0</td><td>0</td>
</td>
</tr>
  <td>1 (Substream 1)</td><td>960</td><td>-64</td>
</td>
</tr>
  <td>2 (Substream 2)</td><td>1024</td><td>+0</td>
</td>
</tr>
  <td>3 (Parameter 1)</td><td>900</td><td>-124</td>
</td>
</tr>
  <td>4 (Parameter 2)</td><td>1100</td><td>+76</td>
</tr>
</table>

The global offset defines an additional offset that is applied to all substreams and parameters, and can be used to express intentional gaps between the local frames associated with two Sync OBUs.

The local frame of reference can be positioned in a global frame of reference by using the concatenation rule provided below. This rule specify how two timelines associated with different Sync OBUs are aligned.

<dfn noexport>Concatenation Rule</dfn>

Ignoring the global offset, the new timeline after a Sync OBU is extended based on the timeline generated from the previous Sync OBU and relative offsets in the current Sync OBU. Then, the global offset is applied to additionally shift the new timeline.


The algorithm below may be used to implement the concatenation rule. But, the result shall comply with this.

```
For a given ID, end_timestamp\[ID]\[0] = 0 (i.e. initial value = 0)

Encoder operation for the Nth Sync OBU 
// Encoders know the position of an OBU on global timeline. 
// So, they know start_timestamp\[ID]\[N] and global_offset\[N].

For each ID in the Nth Sync OBU.

relative_offset\[ID]\[N] = start_timestamp\[ID]\[N] - global_offset\[N]
                           - max(end_timestamp\[ID]\[N-1] for each audio frame ID);
// i.e. relative_offset\[ID]\[1] = start_timestamp\[ID]\[1] 
//                                 - global_offset\[1] for the first Sync OBU.

// end_timestamp\[ID]\[N] for each ID is calculated as follows:

end_timestamp\[ID]\[N] = start_timestamp\[ID]\[N];

for (i = 0: i < M(N); i++) {
  end_timestamp\[ID]\[N] += frame size of ith audio frame
                            (or duration of ith parameter block) having the ID;
}
// M(N) is the number of audio frame OBUs(or parameter block OBUs) having the given ID
// between the Nth Sync OBU and the (N+1)th Sync OBU.

Decoder operation for the Nth Sync OBU 
// Decoders need to extend the timeline generated from the previous Sync OBU.
// For the first Sync OBU which decoders get after join mid-stream, N is set to 1.

For each ID in the Nth Sync OBU.

start_timestamp\[ID]\[N] = max(end_timestamp\[ID]\[N-1] for each audio frame ID)
                           + relative_offset\[ID]\[N] + global_offset\[N];

end_timestamp\[ID]\[N] = start_timestamp\[ID]\[N];

for (i = 0: i < M(N); i++) {
  end_timestamp\[ID]\[N] += frame size of ith audio frame
                            (or duration of ith parameter block) having the ID;
}
// M(N) is the number of audio frame OBUs
// (or parameter block OBUs) having the given ID
// between the Nth Sync OBU and the (N+1)th Sync OBU.
```


# ISOBMFF IAMF Encapsulation # {#isobmff}

## General Requirements & Brands ## {#brands}

A file conformant to this specification satisfies the following:
- It shall conform to the normative requirements of [[!ISOBMFF]]
- It shall have the <dfn value export for="ISOBMFF Brand">iamf</dfn> brand among the compatible brands array of the FileTypeBox
- It shall contain at least one track using an [=IASampleEntry=]
- It SHOULD indicate a structural ISOBMFF brand among the compatible brands array of the FileTypeBox, such as 'iso6'
- It MAY indicate other brands not specified in this specification provided that the associated requirements do not conflict with those given in this specification

Parsers shall support the structures required by the <code>'iso6'</code> brand and MAY support structures required by further ISOBMFF structural brands.


## ISOBMFF IAMF Encapsulation with single track ## {#isobmff-singletrack}

This section describes the basic data structures used to signal encapsulation of IA sequence in [[!ISOBMFF]] containers.

### Requirement of IA sequence ### {#isobmff-singletrack-iasequence}

IA sequence shall comply with the bitstream which is specified in [[#profiles-simple]] or [[#profiles-base]] for encapsulation of ISOBMFF with single track.

### Encapsulation Scheme ### {#isobmff-singletrack-basicencapsulationscheme}

During encapsulation process, OBUs of IA sequences are encapsulated into [[!ISOBMFF]] as follows:

- Movie Header and Edit
	- Calculate the number of temporal units in the IA sequences.
	- Take the number of trimmed samples from the IA sequence and converting it to the sample rate used by the 'elst' boxes.
	- Reflect the converted numbers to 'mvhd' to indicate the duration after trimming.
	- If there is audio samples to be trimmed at the start or at the end, then 'edts' and 'elst' boxes shall be present to reflect the the number of audio samples to be trimmed at the start of the IA sequence (i.e [=media_time=]) and [=edit_duration=].
- Sample Entry
	- The ith set of descriptor OBUs which is not a redundant copy of the previous descriptor OBUs (i.e. the first descriptor OBUs is regarded as non-redundant copy regardless of its [=obu_redundant_copy=]), specified in [[#standalone-descriptor-obus]], and the Sync OBU that immediately follows them are moved to the ith [=IASampleEntry=]. All descriptor OBUs in the IA sequences are then discarded from the IA sequence. 
- Decoding Time to IA Sample
	- The duratin of [=IA Sample=], which is reflected in 'stts' or 'trun' box, is calculated based on the number of audio frames which [=IA Sample=] includes and the [=num_samples_per_frame=] value in the Codec Config OBU, which indicates the duration of one audio frame. 
	- The duration of [=IA Sample=] is duration including samples trimmed at the beginning but excluding samples trimmed at the end. 
- Sample Group
	- The [=roll_distance=] value in the Codec Config OBU is copied to [=AudioRollRecoveryEntry=] with the [=grouping_type=] = 'roll'.
- IA Sample
	- Temporal Delimiter OBU: shall be discarded if present.	
		- Temporal Unit that has no OBUs is discarded
	- Temporal units shall be placed in consecutive IA Samples in order.
		
<center><img src="images/IAMF Encapsulation Guideline.png" style="width:100%; height:auto;"></center>
<center><figcaption>IAMF Encapsulation Scheme</figcaption></center>

### IA Sample Entry ### {#iasampleentry-section}

<pre class="def">
	Sample Entry Type: <dfn value export for="IASampleEntry">iamf</dfn>
	Container:         Sample Description Box ('stsd')
	Mandatory:         Yes
	Quantity:          One or more.
</pre>

<dfn noexport>IASampleEntry</dfn> identifies that the track contains [=IA Samples=], and contains one IA_Descriptor.

<b>Syntax</b>

```
class IASampleEntry extends AudioSampleEntry('iamf') {
  IA_Descriptor descriptor;
}
```

The [=channelcount=] and [=samplerate=] fields of AudioSampleEntry are unused.

None of AudioSampleEntry's optional boxes shall be present.

<b>Semantics</b>

<dfn noexport>descriptor</dfn> is the IA_Descriptor box in this stream.

### IA Descriptors ### {#iadescriptors-section}

<pre class="def">
	Box Type:  <dfn export>iamd</dfn>
	Container: IA Sample Entry ('iamf')
	Mandatory: Yes
	Quantity:  One.
</pre>

<dfn noexport>IA_Descriptor</dfn> contains one set of IAMF Descriptor OBUs, specified using the OBU syntax.

<b>Syntax</b>

```
class IA_Descriptor extends Box('iamd') {
  magic_code_obu();
  codec_config_obu();
  
  for (i = 0; i < num_audio_elements; i++) {
    audio_element_obu();
  }

  for (j = 0; j < num_mix_presentations; j++) {
    mix_presentation_obu();
  }
  sync_obu();
}
```

<b>Semantics</b>

<dfn value noexport for="IA_Descriptor">magic_code_obu()</dfn> is the magic_code_obu() in this set of descriptor OBUs.

<dfn value noexport for="IA_Descriptor">codec_config_obu()</dfn> is the codec_config_obu() in this set of descriptor OBUs.

<dfn value noexport for="IA_Descriptor">audio_element_obu()</dfn> is the <code>i</code>-th audio_element_obu() in this set of descriptor OBUs.

<dfn value noexport for="IA_Descriptor">mix_presentation_obu()</dfn> is the <code>j</code>-th mix_presentation_obu() in this set of descriptor OBUs.

<dfn value noexport for="IA_Descriptor">sync_obu()</dfn> is the sync_obu() that immediately follows this set of descriptor OBUs.

### IA Sample Format ### {#iasampleformat}

For tracks using the [=IASampleEntry=](s), an <dfn noexport>IA Sample</dfn> has the following constraints:
- One IA Sample data shall be one or more consecutive temporal units (after removing Temporal Delimiter OBUs if present) for every IA Sample to be sync sample.
	- In other words, every IA Sample consists of all the data OBUs that are associated with a specific, distinct time instant.
- If [=num_samples_to_trim_at_start=] < [=num_samples_per_frame=], every IA Sample except the last IA Sample shall have the same number (N > 0) of temporal units.
	- In other words, every IA Sample except the last IA Sample consists of N consecutive Audio Frame OBUs per substream and one or more Parameter Block OBUs per parameter (if present), the total duration of the one or more Parameter Block OBUs is equal to the total duration of the N consecutive Audio Frame OBUs. 
	- In every IA Sample, the relative offset of each substream or each parameter (if present) is identified by its associated [=relative_offset=] field of the sync_obu() in [=IA_Descriptor=].
		- In other words, [=relative_offset=](s) in sync_obu() is (are) applicable to every IA Sample in its associated [=IASampleEntry=].
- Otherwise, every IA Sample except the first IA Sample and the last IA Sample shall have the same number (N < 0) of temporal units. The fisrt IA Sample consists of all Audio Frame OBUs for which the entire audio frame is trimmed (i.e. No Parameter Block OBU presents in the first IA Sample).
	- In other words, every IA Sample except the fist IA Sample and the last IA Sample consists of N consecutive Audio Frame OBUs per substream and one or more Parameter Block OBUs per parameter (if present), the total duration of the one or more Parameter Block OBUs is equal to the total duration of the N consecutive Audio Frame OBUs. 
	- In every IA Sample, the relative offset of each substream or each parameter (if present) is identified by its associated [=relative_offset=] field of the sync_obu() in [=IA_Descriptor=].
		- In other words, [=relative_offset=](s) in sync_obu() is (are) applicable to every IA Sample in its associated [=IASampleEntry=].
		- In this case, MOD([=relative_offset=](P) - [=relative_offset=](A), [=num_samples_per_frame=]) is the offset to position the first audio sample in IA Sample which the first parameter value of the first Parameter Block OBU in IA Sample is applied to.

## Codecs Parameter String ## {#codecsparameter}
DASH and other applications require defined values for the 'Codecs' parameter specified in [[!RFC6381]] for ISO Media tracks. The codecs parameter string for the AOM IA codec shall be:
- For IAMF-OPUS

```
	iamf.IAMF-specific-needs.Opus
```

- For IAMF-AAC-LC

```
	iamf.IAMF-specific-needs.mp4a.40.2
```

- For IAMF-FLAC

```
	iamf.IAMF-specific-needs.fLaC
```

- For IAMF-LPCM

```
	iamf.IAMF-specific-needs.ipcm
```

<b>IAMF-specific-needs</b> shall be <b>V.PV</b> as follows:
- <dfn noexport>V</dfn> is four digits and represents the [=version=] of IA sequence.
	- The first two digits represents the major version within the range 0 to 15.
	- The second two digits represents the minor version within the range 0 to 15.
- <dfn noexport>PV</dfn> is four digits and represents the [=profile_version=] of IA sequence.
	- The first <b>P</b> is two digits and represents the profile major version within the range 0 to 15.
	- The second <b>V</b> is two digits and represents the profile minor version within the range 0 to 15.

For example, for this version of the specification
- The codecs parameter string of IAMF-OPUS for the simple profile:

```
	iamf.0000.0000.Opus
```

- The codecs parameter string of IAMF-AAC-LC for the base profile:

```
	iamf.0000.0100.mp4a.40.2
```

# ISOBMFF IAMF Decapsulation # {#isobmff-decapsulation}

## ISOBMFF IAMF Decapsulation with single track ## {#isobmff-decapsulation-singletrack}

This section provides a guideline for IAMF parser to reconstruct IA sequences from IAMF file.

When IAMF parser feeds the reconstructed IA sequences to IAMF-OBU parser, descriptor OBUs shall be placed at the first and followed by Temporal Units.

During decapsulation process, IAMF file is decapsulated into IA sequences which conform to [[#obu-syntax]] as follows:
- The ith IA sequence is reconstructed as follows:
	- Step1: Take the ith descriptor OBUs and Sync OBU from the ith IASampleEntry.
	- Step2: Take jth sample as it is and add Temporal Delimiter OBU in front of the jth sample.
		- Every Temporal Unit shall have Temporal Delimiter OBU or no Temporal Unit shall have Temporal Delimiter OBU.
	- Step3: Place the ith descriptor OBUs, followed by Sync OBU, and followed by Temporal Units in order (j = i1, i2, …, im) without gap, to reconstruct the ith IA sequence.
- Place IA sequences in order (i = 1, 2, 3, ...) to reconstruct the IA sequences.

### Recommended handling of Trimming Information ### {#isobmff-decapsulation-singletrack-trimming}

This section recommends how to handle trimming information of IAMF-ISOBMFF file.

<center><img src="images/ISOBMFF Trimming Handling.png" style="width:80%; height:auto;"></center>
<center><figcaption>Recommendation for IAMF-ISOBMFF Trimming Information Handling</figcaption></center>

As depicted in the above figure, 
- IAMF-ISOBMFF parser passes descriptor OBUs, PTS1 and Samples (or Temporal Units) to IAMF decoder.
- IAMF-ISOBMFF parser passes PTS1 and trimming information to IAMF-ISOBMFF player. 
- IAMF decoder passes PTS and audio samples after decoding to IAMF-ISOBMFF player.
	- If IAMF decoder trims the audio samples to be trimmed based on the trimming information within Audio Frame OBUs, then IAMF decoder passes PTS2 and audio samples after trimming.
	- If IAMF decoder does not trim, then IAMF decoder passes PTS1 and audio samples before trimming.
- IAMF-ISOBMFF player playbacks audio samples starting at PTS2 to Loudspeakers.

Where, PTS1 is the presentation time stamp of the first audio sample before trimming and PTS2 is the presentation time stamp of the first audio sample after trimming.

# IAMF processing # {#processing}

This section provides processes for IA decoding for a given [=IA sequence=].


IA decoding can be done by using the combination of following decoding processing.
- Decoding of a scene-based audio element (Ambisonics decoding)
- Decoding of a channel-based audio element (Scalable Channel Audio decoding)
- Rendering and mixing of each audio element before mixing of multiple audio elements.
	- It may include re-sampling of each audio element.
- Mixing of multiple audio elements with synchronization
- Post processing such as Loudness and Limiter.

<b>Ambisonics decoding</b>, it shall conform to [[!RFC8486]] except codec specific processing and shall output Ambisonics channels in ACN (Ambisonics Channel Number) order.

<b>Scalable Channel Audio decoding</b>, it shall output the channel audio (e.g. 3.1.2ch or 7.1.4ch) for the target channel layout.

IA decoder is composed of OBU parser, Codec decoder, Audio Element Renderer and Post-processor as depicted in below figure.
- OBU parser shall depacketize IA sequence to output one or more substreams with one or more Decoder_Config() but one decoder_config() per audio element, descriptors and parameters.
- Codec decoder for each substream shall output decoded channels.
- Audio Element Renderer reconstructs audio channels from decoded channels of Codec decoders according to the type of audio element which is specified audio element OBU, and renders the audio channels to the target loudspeaker layout.
	- For scene-based audio element, it shall output audio channels for the target loudspeaker layout from the reconstructed ambisonics channels.
	- For channel-based audio element, it shall output audio channels for the target loudspeaker layout from the reconstructed audio channels.
- Post-processor outputs audio channels according to the target loudspeaker layout after processing mixing and post processing such as Loudness and Limiter.
	
<center><img src="images/IA Decoder Configuration.png" style="width:100%; height:auto;"></center>
<center><figcaption>IA Decoder Configuration</figcaption></center>

## Ambisonics decoding ## {#processing-ambisonics}

This section describes the decoding of Ambisonics.

Below figure shows the decoding flowchart of Ambisonics decoding.
- OBU parser shall output the substreams for the scene-based audio element in IA sequence.
	- OBU parser shall output [=channel_mapping=] or [=demixing_matrix=] according to [=ambisonics_mode=] to Channel_Mapping/Demixing_Matrix module
- Codec decoder shall output decoded channels (PCM) in the transmission order as many as[=output_channel_count=] after decoding of each Substream.
- Channel_Mapping/Demixing_Matrix module shall apply channel_mapping or demixing_matrix according to Ambisonics_Mode to the channels (PCM) and outputs channels as many as [=output_channel_count=] in ACN order.
- Ambisonics to Channel Format module may convert the output channels to channel audio according to the target loudspeaker layout.

<center><img src="images/Ambisonics Decoding Flowchart.png" style="width:80%; height:auto;"></center>
<center><figcaption>Ambisonics Decoding Flowchart</figcaption></center>

## Scalable Channel Audio decoding ## {#processing-scalablechannelaudio}

This section describes the decoding of Scalable Channel Audio.

Below figure shows the decoding flowchart of the decoding for Scalable Channel Audio.

<center><img src="images/Channel Audio Decoding Flowchart.png" style="width:80%; height:auto;"></center>
<center><figcaption>Scalable Channel Audio Decoding Flowchart</figcaption></center>

For a given loudspeaker layout (i.e. CL #i) among the list of [=loudspeaker_layout=] in scalable channel layout config,
- OBU Parser shall get substreams for ChannelGroup #1 ~ ChannelGroup #i and pass them to Codec decoder with [=Decoder_Config()=].
- Codec decoder shall output decoded channels (PCM) in the transmission order.
	- For non-scalable audio (i.e i = 1), its order shall be converted to the loudspeaker location order for CL #1.
- Following are further processed for scalable audio (i.e. i > 1)
	- When Output_Gain_Is_Present_Flag(j) for ChannelGroup #j (j = 1, 2, …, i-1) is on, Gain module shall apply Output_Gain(j) to all audio samples of the mixed channels in the ChannelGroup #j indicated by Output_Gain_Flag(j).
	- De-Mixer shall output de-mixed channels (PCM) for CL #i generated through de-mixing of the mixed channels from Gain module by using non-mixed channels and demixing parameters for each frame.
	- Recon_Gain module shall output smoothed channels (PCM) by applying Recon_Gain to each frame of the de-mixed channels.
	- The order for Non-mixed channels and Smoothed channels shall be converted to the loudspeaker location order for CL #i after going through necessary modules such as Gain, De-Mixer, Recon_Gain etc..
- Following may be further processed
	- Loudness normalization module may output loudness normalized channels at -24 LKFS from non-mixed channels and smoothed channels (if present) by using loudness value for CL #i.
	- Limiter module may limit the true peak of input channels at -1dB.

Following sections, [[#processing-scalablechannelaudio-gain]], [[#processing-scalablechannelaudio-demixer]] and [[#processing-scalablechannelaudio-recongain]] are only needed for decoding of scalable audio with [=num_layers=] > 1.

### Gain ### {#processing-scalablechannelaudio-gain}

Gain module is the mirror process of Attenuation module. It recovers the reduced sample values using Output_Gain when its flag for ChannelGroup #j is on. When its flag is off, then this module shall be bypassed for ChannelGroup #j. Output_Gain(j) for ChannelGroup #j shall be applied to all samples of the mixed channels in the ChannelGroup #j. Where, mixed channels means the mixed channels from an input channel audio (i.e. a channel audio for CL #n).

To apply the gain, an implementation MUST use the following:

```
	Sample *= pow(10, Output_Gain(j) / (20.0*256))
```

Where, Output_Gain(j) is the raw 16-bit value for jth layer which is specified in [=channel_audio_layer_config()=].

### De-mixer ### {#processing-scalablechannelaudio-demixer}

For scalable channel audio with [=num_layers=] > 1, some channels of [=down-mixed audio=] for CL #i are delivered as is but the rest are mixed with other channels for CL #i-1.

De-mixer module reconstructs the rest of the down-mixed audio for CL #i from the mixed channels, which is passed by Gain module, and its relevant non-mixed channels using its relevant demixing parameters.

De-mixing for down-mixed audio for CL #i shall comply with the result by the combination of following surround and top de-mixers:
- Surround de-mixers
	- <dfn noexport>S1to2 de-mixer</dfn>: R2 = 2 x Mono – L2
	- <dfn noexport>S2to3 de-mixer</dfn>: L3 = L2 – 0.707 x C and R3 = R2 – 0.707 x C
	- <dfn noexport>S3to5 de-mixer</dfn>: Ls = 1/δ(k) x (L3 – L5) and Rs = 1/δ(k) x (R3 – R5)
	- <dfn noexport>S5to7 de-mixer</dfn>: Lrs = 1/β(k) x (Ls – α(k) x Lss) and Rrs = 1/β(k) x (Rs – α(k) x Rss)
- Top de-mixers
	- <dfn noexport>TF2toT2 de-mixer</dfn>: Ltf2 = Ltf3 – w(k) x (L3 – L5) and Rtf2 = Rtf3 – w(k) x (R3 – R5)
	- <dfn noexport>T2to4 de-mixer</dfn>: Ltb = 1/γ(k) x (Ltf2 – Ltf4) and Rtb = 1/γ(k) x (Rtf2 – Rtf4)
- Where, Ltf2 / Rtf2 is top channel of x.1.2ch, Ltf3 / Rtf3 is top channel of 3.1.2ch, and Ltf4 / Rtf4 is to channel of x.1.4ch (x = 5 or 7) and w(k) is determined from the value of wIdx(k).

Initially, wIdx(0) = 0 and the value of wIdx(k) shall be derived as follows:
- <dfn noexport>wIdx(k)</dfn> = Clip3(0, 10, wIdx(k-1) + w_idx_offset(k))

Mapping of wIdx(k) to w(k) should be as follows:
<pre class = "def">
 wIdx(k) :   w(k)
    0    :    0
    1    :  0.0179
    2    :  0.0391
    3    :  0.0658
    4    :  0.1038
    5    :  0.25
    6    :  0.3962
    7    :  0.4342
    8    :  0.4609
    9    :  0.4821
    10    : 0.5
</pre>

When D_set = { x | S1 < x ≤ Si and x is an integer},
- If 2 is an element of D_set, the combination shall include [=S1to2 de-mixer=].
- If 3 is an element of D_set, the combination shall include [=S2to3 de-mixer=].
- If 5 is an element of D_set, the combination shall include [=S3to5 de-mixer=].
- If 7 is an element of D_set, the combination shall include [=S5to7 de-mixer=].

When Ti = 2,
- If Sj = 3 (j=1,2,…, i-1), the combination shall include [=TF2toT2 de-mixer=].

When Ti = 4,
- If Sj = 3 (j=1,2,…, i-1), the combination shall include [=TF2toT2 de-mixer=] and [=T2to4 de-mixer=].
- Elseif Tj = 2 (j=1,2,…, i-1), the combination shall include [=T2to4 de-mixer=].

For example, when CL #1 = 2ch, CL #2 = 3.1.2ch, CL #3 = 5.1.2ch and CL #4 = 7.1.4ch. To reconstruct the rest (i.e. Ls5/Rs5/Ltf/Rtf) of the down-mixed 5.1.2ch,
- The combination includes [=S2to3 de-mixer=], [=S3to5 de-mixer=] and [=TF2toF2 de-mixer].
- Ls5 and Rs5 are recovered by S2to3 de-mixer and S3to5 de-mixer.
- Ltf and Rtf are recovered by S2to3 de-mixer and TF2toT2 de-mixer.

```
	Ls5 = 1/δ(k) × (L2 - 0.707 × C - L5) and Rs5 = 1/δ(k) × (R2 - 0.707 × C - R5).
	Ltf = Ltf3 - w(k) x (L2 - 0.707 x C - L5) and Rtf = Rtf3 - w(k) x (R2 - 0.707 x C - R5).
```

### Recon Gain ### {#processing-scalablechannelaudio-recongain}

[=recon_gain=] shall be only applied to all of audio samples of the de-mixed channels from De-mixer module.
- [=recon_gain_info_parameter_data()=] indicates each channel of CL #i which Recon_Gain needs to be applied to and provides Recon_Gain value for each frame of the channel.
	- Sample (k,i) *= Smoothed_Recon_Gain (k,i), where k is the frame index and i is the sample index of the frame.
	- Smoothed_Recon_Gain (k) = MA_gain (k-1) x e_window + MA_gain (k) x s_window
	- MA_gain (k) = 2 / (N+1) x Recon_Gain (k) / 255 + (1 – 2/(N+1)) x MA_gain (k-1), where MA_gain (0) = 1.
	- e_window[:ps – olen] = 1, e_window[ps – olen: ps] = hanning[olen:], e_window[ps:flen] = 0.
	- s_window[:ps – olen] = 0, s_window[ps – olen: ps] = hanning[:olen], s_window[ps:flen] = 1.
	- Where, hanning = np.hanning (2*olen), ps is the pre-skip value, flen is the frame size and olen is the overlap size.
	- Recommend values: N = 7

Below figure shows the smoothing scheme of [=recon_gain=].

<center><img src="images/Smoothing Scheme of Recon Gain.png" style="width:100%; height:auto;"></center>
<center><figcaption>Smoothing Scheme of Recon Gain</figcaption></center>

Recommend values for specific codecs are as follows
- IAMF-OPUS: olen = 60, the pre-skip (ps) value is indicated in Codec_Specific_Info for IAMF-OPUS.
- IAMF-AAC-LC: olen = 64, ps = 720.

## Mix Presentation ## {#processing-mixpresentation}

An IA sequence may contain more than one mix presentation. [[#processing-mixpresentation-selection]] details how a mix presentation should be selected from multiple of them.

A mix presentation specifies how to render, process and mix one or more audio elements. Each audio element should first be individually rendered and processed before mixing. Then, any additional processing specified by [=output_mix_config()=] should be applied to the mixed audio signal in order to generate the final output audio for playback. [[#processing-mixpresentation-rendering]] details how each audio element should be rendered, while [[#processing-mixpresentation-mixing]] details how the audio elements should be processed and mixed.

### Selecting a Mix Presentation ### {#processing-mixpresentation-selection}

An IA sequence may contain more than one mix presentations. The IA parser should select the appropriate mix presentation in the following order.

1. If there are any user-selectable mixes, the IA parser should select the mix, or mixes, that match the user's preferences. An example might be a mix with a specific language. Mix presentations may use [=mix_presentation_friendly_label=] to describe such mixes.
2. If there are more than one valid mixes remaining, the IA parser should select an appropriate mix for rendering, in the following order.
	1. If the playback layout is binaural, i.e. headphones:
		1. Select the mix with [=audio_element_id=] whose [=loudspeaker_layout=] is BINAURAL.
		2. If there is no such mix, select the mix with the highest available [=loudness_layout=].
	2. If the playback layout is loudspeakers:
		1. If there is a mix with an [=loudness_layout=] that matches the playback loudspeaker layout, it should be selected. If there are more than one matching mixes, the first one should be selected.
		2. If there is no such mix, select the mix presentation with the highest available [=loudness_layout=].

### Rendering an Audio Element ### {#processing-mixpresentation-rendering}

This specification supports the rendering of either a multichannel or ambisonics audio element to either a target loudspeaker layout or a binaural output.

In this section, for a given x.y.z layout, the next highest layout x'.y'.z' means that x', y' and z' are greater than or equal to x, y and z, respectively.

<table class="def">
<tr>
  <th><code>audio_element_type</code></th><th>Playback layout</th><th>Section</th>
</tr>
<tr>
  <td>CHANNEL_BASED</td><td>Loudspeakers</td><td>[[#processing-mixpresentation-rendering-m2l]]</td>
</tr>
<tr>
  <td>SCENE_BASED</td><td>Loudspeakers</td><td>[[#processing-mixpresentation-rendering-a2l]]</td>
</tr>
<tr>
  <td>CHANNEL_BASED</td><td>Binaural output</td><td>[[#processing-mixpresentation-rendering-m2b]]</td>
</tr>
<tr>
  <td>SCENE_BASED</td><td>Binaural output</td><td>[[#processing-mixpresentation-rendering-a2b]]</td>
</tr>
</table>

#### Rendering a channel-based audio element to loudspeakers #### {#processing-mixpresentation-rendering-m2l}

This section defines the renderer to use, given a channel-based audio element and a loudspeaker playback layout.

- The input layout of the IA renderer is set as follows:
	- If [=num_layers=] = 1, use the [=loudspeaker_layout=] of the audio element.
	- Else, if there is a [=loudness_layout=] that matches the playback layout, use it.
	- Else, use the next highest available layout from all available [=loudspeaker_layout=] and [=loudness_layout=].
- The output layout of the IA renderer is set to the playback layout.
- The IA renderer used is selected according to the following rules:
	- If the playback layout matches a [=loudspeaker_layout=] which can be generated from the highest loudspeaker layout of the audio element according to [[#iamfgeneration-scalablechannelaudio-channellayoutgenerationrule]], use demixing_info_parameter_data().
		- If demixing_info_parameter_data() is not delivered,
			- If the playback layout complies with loudspeaker layouts supported by [[!ITU2051-3]], use EAR Direct Speakers renderer ([[!ITU2127-0]]).
			- Else if the playback layout is 3.1.2ch, use the static down-mix matrices specified in [[#processing-downmixmatrix-static]].
			- Else, use implementation-specific renderer
	- Else if the playback layout complies with loudspeaker layouts supported by [[!ITU2051-3]], use EAR Direct Speakers renderer ([[!ITU2127-0]]).
	- Else if the playback layout is 3.1.2ch, use the static down-mix matrices specified in [[#processing-downmixmatrix-static]].
	- Else, use implementation-specific renderer.

If the EAR Direct Speakers renderer is used, the following should be provided for each audio channel of the audio element:

- speaker label: the label of the speaker position, using the same convention as "SP Label" in [[!ITU2051-3]]. This is defined for each audio channel of the audio element based on the information from [=loudspeaker_layouts=].

In [[!ITU2051-3]], an LFE audio channel may be identified either by an explicit label or its frequency content. In this specification, the LFE channel is identified based on the explicit label only, given by [=loudspeaker_layout=].

#### Rendering a scene-based audio element to loudspeakers #### {#processing-mixpresentation-rendering-a2l}

This section defines the renderer to use, given a scene-based audio element and a loudspeaker playback layout.

- The input layout of the IA renderer is set to Ambisonics.
- The output layout of the IA renderer is set to the playback layout.
- The IA renderer used is selected according to the following rules:
	- If the playback layout complies with loudspeaker layouts supported by [[!ITU2051-3]], use EAR HOA renderer ([[!ITU2127-0]]).
	- Else, use implementation-specific renderer.
		- If there is no implementation-specific Ambisonics renderer, use the EAR HOA renderer to render to the next highest [[!ITU2051-3]] layout compared to the playback layout, and then downmix using implementation-specific renderer.

If the EAR HOA renderer is used, the following metadata should be provided to the renderer for each audio channel:

1. Ambisonics order
2. Ambisonics degree
3. Ambisonics normalization method

In this specification, the [[!AmbiX]] format is adopted, which uses SN3D normalization and ACN channel ordering. Accordingly, the Ambisonics order and degree can be computed from the channel index <code>k</code> as follows:

```
order   n = floor(sqrt(k)),
degree  m = k - n * (n + 1).
```

#### Rendering a channel-based audio element to a binaural output #### {#processing-mixpresentation-rendering-m2b}

Given a channel-based audio element and a binaural playback layout, the Binaural EBU ADM Direct Speaker renderer [[!BEAR]] should be used. The highest layout provided in [=scalable_channel_layout_config()=] should be used as the input to the renderer.

#### Rendering a scene-based audio element to a binaural output #### {#processing-mixpresentation-rendering-a2b}

Given a scene-based audio element and a binaural playback system, the Resonance Audio renderer [[!Resonance-Audio]] should be used.


### Mixing Audio Elements ### {#processing-mixpresentation-mixing}

Each audio element is processed individually before mixing as follows:
1. Render to the playback layout.
2. If all audio elements do not have a common sample rate, re-sample to 48 kHz.
3. If all audio elements do not have a common bit-depth, convert to a common bit-depth. This specification recommends using 16 bits.
4. If [=loudness_layout=] matches with the playback layout, apply any per-element processing according to [=element_mix_config()=].

The rendered and processed audio elements are then summed, and then apply [=output_mix_config()=] to generate one sub-mixed audio signal. If there are more than one sub-mixes, the output of each sub-mix is further summed to generate the final mixed audio signal.


## Animated Parameters ## {#processing-animated-params}

This section describes how a set of parameters is animated over a subblock in a parameter block and applied to the corresponding audio samples, using the information provided in [=AnimatedParameterData()=].

If [=animation_type=] is equal to STEP, the parameter value provided by [=start_point_value=] should be applied to all time steps in the subblock.

If [=animation_type=] is equal to LINEAR or BEZIER, the information provided in [=AnimatedParameterData()=] describes how the parameter is animated as a Bezier curve. Let <code>T</code> be the subblock duration defined in the parameter_block_obu() and <code>P0</code>, <code>P1</code> and <code>P2</code> be 2D coordinates defined as

```
P0 = (t0, start_point_value),
P1 = (t1, control_point_value),
P2 = (t2, end_point_value),
```

where <code>t0 = 0</code> is the subblock start time, <code>t2 = D</code> is the subblock end time and <code>t1</code> is the control point time given by

```
t1 = round(D * control_point_relative_time).
```

The values of <code>t0</code>, <code>t1</code> and <code>t2</code> are expressed as ticks at the [=parameter_rate=] given in the associated parameter definition.

If [=animation_type=] is equal to LINEAR, the parameter value is linearly interpolated between [=start_point_value=] and [=end_point_value=] at a given point in time as:

```
B_linear(a) = (1 - a) * P0 + a * P2,
0 <= a <= 1,
```

where <code>B_linear(a) = (t, y)</code> is a 2D coordinate with the parameter value <code>y</code> at time <code>t</code>.

If [=animation_type=] is equal to BEZIER, the parameter value is interpolated following a quadratic Bezier curve between [=start_point_value=] and [=end_point_value=] at a given point in time as:

```
B_quad(a) = (1 - a)^2 * P0 + 2 * (1 - a) * a * P1 + a^2 * P2,
0 <= a <= 1.
```

where <code>B_quad(a) = (t, y)</code> is a 2D coordinate with parameter value <code>y</code> at time <code>t</code>.

To apply the parameter values to the audio samples in the subblock without interpolation, the [=parameter_rate=] is first resampled to the audio sample rate to give:

```
n0 = t0 * audio_sample_rate / parameter_rate,
n1 = t1 * audio_sample_rate / parameter_rate,
n2 = t2 * audio_sample_rate / parameter_rate.
```

Then, <code>P0</code>, <code>P1</code>, <code>P2</code> can be rewritten as:

```
P0 = (n0, start_point_value),
P1 = (n1, control_point_value),
P2 = (n2, end_point_value).
```

Next, the parameter value <code>y</code> is computed for each time <code>t</code> that corresponds to an integer audio sample index, <code>t = n = [0, 1, 2, ..., n2]</code>. This is done by computing the equivalent value of <code>a</code> for every <code>n</code>, and then applying the Bezier equations <code>B_linear(a)</code> and <code>B_quad(a)</code> to find the parameter value <code>y</code>.

In the case of <code>B_linear(a)</code>, the mapping between <code>n</code> and <code>a</code> is given by:

```
a = n ÷ n2.
```

In the case of <code>B_quad(a)</code>, the mapping between <code>n</code> and <code>a</code> is given by:

```
a = (-beta + sqrt(beta^2 - 4 * alpha * gamma)) ÷ (2 * alpha),
```

where

```
alpha = n0 - 2 * n1 + n2,
beta = 2 * (n1 - n0),
gamma = n0 - n.
```


## Post Processing ## {#processing-post}

### Loudness Normalization ### {#processing-post-loudness}

Loudness normalization should be done by adjusting the loudness level to a target output level using information provided in [[#obu-mixpresentation-loudness]].  A control may be provided to set unique target output levels for each anchored loudness and/or the integrated loudness.  If loudness normalization increases the output level, a peak limiter to prevent saturation and/or clipping may be necessary; [=true_peak=] or [=digital_peak=] may be used to determine if peak limiting is needed.  Alternately, the total amount of normalization may be limited.

The rendered layouts that were used to measure the loudness information of a sub-mix are provided by [=loudness_layout=]s. 

If one of them matches the playback layout, the loudness information should be used directly for normalization. If there is a mismatch between [=loudness_layout=] and the playback layout, the implementation may choose to use the provided loudness information of the highest [=loudness_layout=] as-is. 

If there is more than one selected loudness_info() specified in the mix presentation (i.e. in case of multiple sub-mixes), the implementation should normalize the loudness of each sub-mix independently before summing them.

### Limiter ### {#processing-post-limiter}

The limiter should limit the true peak of audio signal at -1 dBTP, where true peak is defined in [[!ITU1770-4]]. The limiter should apply to multichannel signals in a linked manner and further support auto-release.


## Down-mix Matrix ## {#processing-downmixmatrix}


### Dynamic Down-mix Matrix ### {#processing-downmixmatrix-dynamic}

This section recommends dynamic down-mixing matrices.

The dynamic down-mixing matrics complies with the down-mixing mechanism which is specified in [[#iamfgeneration-scalablechannelaudio-downmixmechanism]].

### Static Down-mix Matrix ### {#processing-downmixmatrix-static}

This section specifies static down-mix matrices to render to 3.1.2ch from each of 5.1.2ch, 5.1.4ch, 7.1.2ch and 7.1.4ch.

The figures below show static down-mix matrices to 3.1.2ch.

<center><img src="images/3.1.2ch Down-mix Matrix for 5.1.2ch.png" style="width:80%; height:auto;"></center>
<center><figcaption>3.1.2ch Down-mix matrix for 5.1.2ch</figcaption></center>

<center><img src="images/3.1.2ch Down-mix Matrix for 5.1.4ch.png" style="width:80%; height:auto;"></center>
<center><figcaption>3.1.2ch Down-mix matrix for 5.1.4ch</figcaption></center>

<center><img src="images/3.1.2ch Down-mix Matrix for 7.1.2ch.png" style="width:100%; height:auto;"></center>
<center><figcaption>3.1.2ch Down-mix matrix for 7.1.2ch</figcaption></center>

<center><img src="images/3.1.2ch Down-mix Matrix for 7.1.4ch.png" style="width:100%; height:auto;"></center>
<center><figcaption>3.1.2ch Down-mix matrix for 7.1.4ch</figcaption></center>

Where, p1 = 0.707. Implementations may use limiter defined in [[#processing-post-limiter]] to preserve energy of audio signals instead of normalization factors.


# IAMF Generation Process # {#iamfgeneration}

This section provides processes for IA encoding for a given input audio format.

Recommended input audio format for IA encoding is as follows:
- Ambisonics format: It shall conform to [=ChannelMappingFamily=] = 2 or 3 of [[RFC8486]].
- Channel Audio format: It shall conform to [=loudspeaker_layout=] specified in channel_audio_layer_config().
- Input Sampling Rate: 48000Hz
- Bitdepth: 16 bits or 24 bits
	- 16 bits are recommended for IAMF-OPUS.
- Input file format: .wav file (Linear PCM, simply called as PCM)

For a given input audio and user inputs, IA encoder shall output [=IA sequence=] which conforms to [[#obu-syntax]].

Input audio shall be one of followings:
- Ambisonics format
- Channel Audio format

User inputs are:
- Ambisonics mode to indicate if [=ChannelMappingFamily=] = 2 or 3 of [[RFC8486]].
- List of channel layouts to be supported for scalable channel audio: it conforms to [=loudspeaker_layout=].
	- For a given input audio with Channel Audio format, if the input audio has height channels (e.g 7.1.4ch), each of the list of channel layouts should have height channels (i.e it should be higher than or equal to 3.1.2ch).
		- Examples for recommended list of channel layouts: 3.1.2ch/5.1.2ch, 3.1.2ch/5.1.2ch/7.1.4ch, 5.1.2ch/7.1.4ch etc..
		- Examples for not-recommended list of channel layouts: 2ch/3.1.2ch/5.1.2ch, 2ch/3.1.2ch/5.1.2ch/7.1.4ch, 2ch/5.1.2ch/7.1.4ch, 2ch/7.1.4ch etc..
		
NOTE: Contents providers may be satisfied with the down-mixed audio having no height channels even though the down-mix mechanism, specified in [[#iamfgeneration-scalablechannelaudio-downmixmechanism]], drops height channels when it does down-mix from input channel audio with height channels to surround channels for example from 7.14ch to Mono, Stereo, 5.1ch or 7.1ch. In that case, encoder may generate a scalable audio with the down-mixed audio without having height channels from the input channel audio with height channels. In other words, this specification does not disallow for scalable audios to have a down-mixed audio without having height channels from input channel audio having height channels.

IA encoding can be done by using the combination of following generation processing.
- Encoding of an audio element (Ambisonics encoding or Scalable Channel Audio encoding)
- Encoding of mix presentation

The below figure shows IA encoder configuration for one single audio element.

The IA encoder is composed of Pre-processor, Codec encoder and OBU packetizer.
- Pre-processor outputs one or more ChannelGroups, descriptors and optional parameter blocks based on the input audios and user inputs.
	- It outputs one single ChannelGroup for scene-based audio element.
	- It outputs one or more ChannelGroups for channel-based audio element.
	- It outputs descriptors which are composed of one Magic Code, one Codec Config, one Audio Element config, one or more Mix Presentation config. 
	- It may output parameter blocks
		- For channel-based audio element with [=num_layers=] = 1, it may output parameter blocks for demixing info.
		- For channel-based audio element with [=num_layers=] > 1, it outputs parameter blocks for demixing_info_parameter_data and recon_gain_info_parameter_data.
		- It may further output parameter blocks for mixing gain.
- Codec encoder generates one or more substreams from each ChannelGroup based on Codec Config.
- OBU packetizer packetize descriptors, sync information, parameter blocks and audio frames by OBU, and outputs IA sequence.
	- Temporal unit generator generates temporal unit for each frame from audio frame OBUs and parameter block OBUs (if present).

<center><img src="images/IA Encoder Configuration.png" style="width:100%; height:auto;"></center>
<center><figcaption>IA Encoder Configuration</figcaption></center>

## Ambisonics Encoding ## {#iamfgeneration-ambisonics}

For Ambisonics encoding:
- Pre-processor outputs one ChannelGroup and descriptors and it is only composed of Meta Generator.
	- Meta generator generates descriptors based on Ambisonics mode and the number of channels for Ambisonics.
		- [=ambisonics_mode=] shall be set to 0 for [=ChannelMappingFamily=] = 2 of [[RFC8486]] or 1 for [=ChannelMappingFamily=] = 3 of [[RFC8486]].
		- ambisonics_config is set to as follows:
			- [=output_channel_count=], [=substream_count=] and [=coupled_substream_count=] shall be set to the number of channels for Ambisonics.
			- [=channel_mapping=] for [=ambisonics_mode=] = 0 is assigned to according to the order of substreams in ChannelGroup.
			- [=demixing_matrix=] for [=ambisonics_mode=] = 1 is assigned to according to the order of substreams in ChannelGroup.
- Codec Enc. outputs substreams as many as the number of channels which is indicated in [=substream_count=].
- Temporal unit shall be composed of audio frame OBUs for substreams.
	- It may have the immediately preceding temporal delimiter OBU.
	- The order of substreams in ChannelGroup shall be aligned with [=channel_mapping=] for Ambisonics_Mode = 0 or [=demixing_matrix=] for Ambisonics_Mode = 1.

## Scalable Channel Audio Encoding ## {#iamfgeneration-scalablechannelaudio}

For Scalable Channel Audio encoding:
- Pre-processor outputs one or more ChannelGroups, descriptors and parameter blocks. It is composed of Down-mix parameter generator, Down-mixer, Loudness, ChannelGroup generator, Attenuation and Meta generator.
	- For non-scalable channel audio (i.e. [=num_layers=] = 1):
		- Parameter blocks for recon_gain_info_parameter_data is not be generated. 
		- Parameter blocks for demixing_info_parameter_data may be generated by implementers who assume it to be recommended for dynamic downmixing in a decoder side.
		- Down-mixer, ChannelGroup generator and Attenuation modules do not needed.
	- Down-mix parameter generator shall generate 5 down-mix parameters (α(k), β(k), γ(k), δ(k) and w(k)) by analyzing input channel audio.
	- Down-mixer shall generate down-mixed audios according to the list of channel layouts and the down-mix parameters.
	- Loudness module should output the loudness level ([=LKFS=]) of each down-mixed audio based on [[ITU1770-4]].
	- ChannelGroup generator shall transform the input channel audio to ChannelGroups for scalable channel audio with [=num_layers=] > 1 scalability by using the down-mix parameters and the list of channel layouts.
	- Attenuation module shall apply a gain to the transformed ChannelGroups to prevent clipping.
	- Meta generator generates descriptors and parameter block(s) for each frame.
		- descriptors shall be set to as follows:
			- [=num_layers=] shall be set to the number of channel layouts.
			- [=channel_audio_layer_config()=] shall be set to as follows:
				- [=loudspeaker_layout=] shall be set to the ith list of channel layouts for the ith ChannelGroup.
				- [=output_gain_is_present_flag=] shall set to 1 for the ith ChannelGroup if attenuation is applied to the mixed channels of the ith ChannelGroup. Otherwise it shall be set to 0 for the ith ChannelGroup.
				- [=recon_gain_is_present_flag=] shall be set to 1 for the ith ChannelGroup if the preceding ChannelGroups has one or more mixed channels from the down-mixed audio for the ith channel layout. Otherwise, it shall be set to 0 for the ith ChannelGroup. Especially, when [=num_layers=] = 1, this flag shall be set to 0.
					- This flag shall be set to 0 for lossless codecs including IAMF-LPCM.
				- [=substream_count=] shall be set to the number of substreams composing of the ith ChannelGroup.
				- [=coupled_substream_count=] shall be set to the number of coupled substreams among the substreams composing of the ith ChannelGroup.
				- [=loudness=] shall be set to the loudness ([=LKFS=]) of the down-mixed audio for the ith channel layout for the ith ChannelGroup.
				- Each bit of [=output_gain_flags=] shall be set to 1 for the ith ChannelGroup if attenuation is applied to the relevant channel of the ith ChannelGroup. Otherwise it shall be set to 0 for the ith ChannelGroup.
				- [=output_gain=] shall be set to the inverse number of the gain which is applied to the channels which are indicated by output_gain_flags.
		- Parameter blocks can be composed of [=demixing_info_parameter_data()=] and [=recon_gain_info_parameter_data()=]. When [=recon_gain_is_present_flag=] = 0 for all ChannelGroup, recon_gain_info shall not present in IA sequence.
			- [=dmixp_mode=] of demixing_info_parameter_data for the kth frame shall be set to indicate (α(k), β(k), γ(k), δ(k)) and w_idx_offset(k). Where w_idx_offset(k) = 1 or -1.
			- [=recon_gain_flags=] of recon_gain_info_parameter_data shall be set to indicate the de-mixed channels, which need to apply [=recon_gain=] among the output channels after demixing for ith channel layout.
			- [=recon_gain=] shall be set to the gain value to be applied to the channel which is indicated by recon_gain_flags for the ith ChannelGroup.
- Temporal unit for kth frame shall be composed of audio frame OBUs for the kth frames of the substreams and followed by OBUs for zero or more parameter block OBUs.
	- It may have the immediately preceding temporal delimiter OBU,
	- ChannelGroups in temporal unit shall be placed in order. In other words, ChannelGroup for the first channel layout shall come first, followed by ChannelGroup for the second channel layout, followed by ChannelGroup for the third channel layout and so on.

Below figure shows IA encoding flowchart for Scalable Channel Audio.
- For a given Channel Audio and a given list of channel layouts for scalability, PCMs for Channel Audio are passed to CG Generation module.
- CG Generation module generates the transformed audio according to CG generation rule based on the list of CLs and the down-mix parameters.
	- The transformed audio is structured as ChannelGroups.
- Non-mixed channels of the transformed audio (i.e., the original channels of the input channel audio) are directly input to Codec encoder, but the mixed channels may be input first to Attenuation module and then to Codec encoder.
- The Attenuation module reduces all sample values of the mixed channels in the same CG at a uniform rate (Output_Gain).
	- A range of 0dB to -6dB is recommended for the attenuation. (i.e. a range of 0dB to 6dB for Output_Gain)
- Codec Enc. generates the coded substreams from PCMs and passes substreams and one single decoder_config to OBU Packetizer.
- OBU packetizer generates descriptor OBUs which consists of one Magic Code OBU, one Codec Config OBU, one Audio Element OBU and zero or more Mix Presentation OBU.
		- Codec Config OBU is generated based on [=decoder_config()=].
- OBU packetizer generates zero or more parameter block OBUs for each frame which contains demixing_info_parameter_data and recon_gain_info_parameter_data.
- OBU packetizer generates audio frame OBUs for each frame of the substreams.
- OBU packetizer generates temporal unit for each frame.
	- Temporal unit consists of audio frame OBUs and followed by zero or more parameter block OBUs.
		- It may have the immediately preceding temporal delimiter OBU, 
- OBU Packetizer outputs IA sequence which is composed of OBUs for descriptor OBUs, followed by sync OBU and followed by OBUs for temporal units.

<center><img src="images/IA Encoding Flowchart for Channel Audio Format.png" style="width:80%; height:auto;"></center>
<center><figcaption>IA Encoding Flowchart for Scalable Channel Audio</figcaption></center>

Following sections, [[#iamfgeneration-scalablechannelaudio-downmixparameter]], [[#iamfgeneration-scalablechannelaudio-downmixmechanism]], [[#iamfgeneration-scalablechannelaudio-channellayoutgenerationrule]], [[#iamfgeneration-scalablechannelaudio-recongaingeneration]] and [[#iamfgeneration-scalablechannelaudio-channelgroupgenerationrule]] do not needed for non-scalable channel audio (i.e., when [=num_layers=] specified in [=scalable_channel_layout_config()=] is set to 1).

### Down-mix parameter and Loudness ### {#iamfgeneration-scalablechannelaudio-downmixparameter}

This section describes how to generate down-mix parameters and loudness level for a given channel audio and a given list of channel layouts for scalability.

Below figure shows a block diagram for down-mix parameter and loudness module including down-mixer.

<center><img src="images/Down-mix Parameter and Loudness.png" style="width:100%; height:auto;"></center>
<center><figcaption>IA Down-mix Parameter and Loudness</figcaption></center>

For a given Channel Audio (e.g. 7.1.4ch) and a given list of channel layouts based on the Channel Audio,
- Down-mix parameter generator shall generate 5 down-mix parameters (α(k), β(k), γ(k), δ(k) and w(k)) by analyzing input Channel Audio, by referring [[AI-CAD-Mixing]]. Where, k is a frame index.
	- It is composed of Audio Scene Classification module and Height Energy Quantification module as depicted in Figure 11-2.
	- Audio Scene Classification module generates 4 parameters (α(k), β(k), γ(k), δ(k)) by classifying audio scenes of input channel audio in three modes.
		- Default scene: Neither Dialog nor Effect
		- Dialog scene: Center-channel oriented and clear dialog/voice sounds
		- Effect scene: Directional and spatially moving sounds.
	- Height Energy Quantification module generates a surround to height mixing parameter (w(k)) which is decided according to the relative energy difference between the top and surround channels of input channel audio.
		- If the energy of top channels is bigger than that of surround ones, then w_idx_offset(k) is set to 1. Otherwise, it is set to -1. And, w(k) is calculated based on w_idx_offset(k) and conforms to [[#processing-scalablechannelaudio]].
- Down-mixer generates down-mixed audios from input Channel Audio according to the list of channel layouts and the down-mix parameters, and outputs down-mixed audio for each channel layout to Loudness module.
	- It is not depicted in the figure but Down-mixer further generates [=Dmixp_Mode=] and [=Recon_Gains=] for each frame to be passed to OBU packetizer.
- Loudness module measures the loudness level ([=LKFS=]) of each down-mixed audio based on [[ITU1770-4]], and passes them to OBU packetizer.

### Down-mix Mechanism ### {#iamfgeneration-scalablechannelaudio-downmixmechanism}

This section specifies the down-mixing mechanism to generate <dfn noexport>down-mixed audio</dfn> for scalable channel audio.

For a given Channel Audio which conforms to [=loudspeaker_layout=], the surround and top channels (if any) are separately down-mixed and especially step by step until to get a target channels.

Implementers may use another method to get the down-mixed audio from the given channel audio, but the down-mixed audio shall comply with that by this section.

Therefore, a down-mixer based on the down-mix mechanism is a combination of following surround down-mixer(s) and top down-mixer(s) as depicted in below figure.
- Surround Down-mixers: S7to5 enc., S5to3 enc., S3to2 enc., S2to1 enc.

```
	S7to5 enc.: Ls5 = α(k) x Lss7 + β(k) x Lrs7 and Rs5 = α(k) x Rss7 + β(k) x Rrs7.
	S5to3 enc.: L3 = L5 + δ(k) x Ls5 and R3 = R5 + δ(k) x Rs5
	S3to2 enc.: L2 = L3 + 0.707 x C and R2 = R3 + 0.707 x C
	S2to1 enc.: Mono = 0.5 x (L2 + R2)
```

- Top Down-mixers: T4to2 enc., T2toTF2 enc.

```
	T4to2 enc.: Ltf2 = Ltf4 + γ(k) x Ltb4  and Rtf2 = Rtf4 + γ(k) x Rtb4.
	T2toTF2 enc.: Ltf3 = Ltf2 + w(k) x δ(k) x Ls5 and Rtf3 = Rtf2 + w(k) x δ(k) x Rs5.
```

<center><img src="images/Down-mix Mechanism.png" style="width:100%; height:auto;"></center>
<center><figcaption>IA Down-mix Mechanism</figcaption></center>

```
For example, to get down-mixed 3.1.2ch from 7.1.4ch:
- S3 of 3.1.2ch is generated by using S7to5 and S5to3 encs.
- TF2 of 3.1.2ch is generated by using T4to2 and T2toTF2 encs.
```

### Channel Layout Generation Rule ### {#iamfgeneration-scalablechannelaudio-channellayoutgenerationrule}

This section describes the generation rule for channel layouts for scalable channel audio.

For a given channel layout (CL #n) of input Channel Audio, any list of CLs ({CL #i: i = 1, 2, ..., n}) for a scalable channel audio shall conform with following rules:
- Si ≤ Si+1 and Wi ≤ Wi+1 and Ti ≤ Ti+1 except Si = Si+1 and Wi = Wi+1 and Ti = Ti+1 for i = n-1, n-2, …, 1. Where ith Channel Layout CL #i = Si.Wi.Ti.
- CL #i is one of [=loudspeaker_layouts=] supported in this specification.

Down-mix paths, which conform to the above rule, shall be only allowed for scalable channel audio with [=num_layers=] > 1 as depicted in below figure.

<center><img src="images/Down-mix Path.png" style="width:90%; height:auto;"></center>
<center><figcaption>IA Down-mix Path</figcaption></center>

### Recon Gain Generation ### {#iamfgeneration-scalablechannelaudio-recongaingeneration}

This section describes how to generate [=recon_gain=].

Recon_Gain needs to be applied to de-mixed channels. For this, IA encoder needs to deliver it to IA decoders.

Let's define followings:
- Level Ok is the signal power for the frame #k of a channel of the down-mixed audio for CL #i.
- Level Mk is the signal power for the frame #k of the relevant mixed channel of the down-mixed audio for CL #i-1.
- Level Dk is the signal power for the frame #k of the de-mixed channel for CL #i (after demixing).

If 10*log10(level Ok / maxL^2) is less than the first threshold value (e.g. -80dB), Recon_Gain (k, i)  = 0. Where, maxL = 32767 for 16bits.

If 10*log10(level Ok / level Mk ) is less than the second threshold value (e.g. -6dB), Recon_Gain (k, i) is set to the value which makes level Ok = Recon_Gain (k, i)^2 x level Dk. Otherwise, Recon_Gain (k, i) = 1. Actual value to be delivered is floor(255*Recon_Gain).

```
For example, if we assume CL #i = 7.1.4ch and CL #i-1 = 5.1.2ch, then de-mixed channels are D_Lrs7, D_Rrs7, D_Ltb4 and D_Rtb4.
- D_Lrs7 and D_Rrs7 are de-mixed from Ls5 and Rs5 in the (i-1)th ChannelGroup by using Lss7 and Rss7 in the ith ChannelGroup and its relevant demixing parameters (i.e., α(k) and β(k)) , respectively.
- D_Ltb4 and D_Rtb4 are de-mixed from Ltf2 and Rtf2 in the (i-1)th ChannelGroup by using Ltf4 and Rtf4 in the ith ChannelGroup and its relevant demixing parameter (i.e., γ(k)), respectively.

Recon_Gain for D_Lrs7:
- Level Ok is the signal power for the frame #k of Lrs7 in the ith ChannelGroup.
- Level Mk is the signal power for the frame #k of Ls5 in the (i-1)th ChannelGroup.
- Level Dk is the signal power for the frame #k of D_Lrs7.
Recon_Gain for D_Rrs7:
- Level Ok is the signal power for the frame #k of Rrs7 in the ith ChannelGroup.
- Level Mk is the signal power for the frame #k of Rs5 in the (i-1)th ChannelGroup.
- Level Dk is the signal power for the frame #k of D_Rrs7.
Recon_Gain for D_Ltb4:
- Level Ok is the signal power for the frame #k of Ltf4 in the ith ChannelGroup.
- Level Mk is the signal power for the frame #k of Ltf2 in the (i-1)th ChannelGroup.
- Level Dk is the signal power for the frame #k of D_Ltb4.
Recon_Gain for D_Rtb4:
- Level Ok is the signal power for the frame #k of Rtf4 in the ith ChannelGroup.
- Level Mk is the signal power for the frame #k of Rtf2 in the (i-1)th ChannelGroup.
- Level Dk is the signal power for the frame #k of D_Rtb4.
```

### ChannelGroup Generation Rule ### {#iamfgeneration-scalablechannelaudio-channelgroupgenerationrule}

This section describes the generation rule for ChannelGroup.

For a given Channel Audio and the list of CLs ({CL #i: i = 1, 2, ..., n}), CG Generation module outputs the transformed audio (i.e. ChannelGroups) which shall conform to following rules:
- It consists of C number of channels and is structured to n number of CGs, where C is the number of channels for the Channel Audio.
- CG #1 (as called BCG): This CG is the down-mixed audio itself for CL #1 generated from the Channel Audio. It contains C1 number of channels.
- CG #i (as called DCG, i = 2, 3, …, n): This CG contains (Ci – Ci-1) number of channels. (Ci – Ci-1) channel(s) consists of as follows:
	- (Si – Si-1) surround channel(s) if Si > Si-1 . When S_set = { x | Si-1 < x ≤ Si and x is an integer},
		- If 2 is an element of S_set, the L2 channel is contained in this CG #i.
		- If 3 is an element of S_set, the Center channel is contained in this CG #i.
		- If 5 is an element of S_set, the L5 and R5 channels are contained in this CG #i.
		- If 7 is an element of S_set, the Lss7 and Rss7 channels are contained in this CG #i.
	- The LFE channel if Wi > Wi-1 .
	- (Ti – Ti-1) top channels if Ti > Ti-1 .
		- If Ti-1 = 0, the top channels of the down-mixed audio for CL #i are contained in this CG #i.
		- If Ti-1 = 2, the Ltf and Rtf channels of the down-mixed audio for CL #i are contained in this CG #i.

Below figure shows one example of transformation matrix with 4 CGs (2ch/3.1.2ch/5.1.2ch/7.1.4ch).

<center><img src="images/Example of Transformation Matrix with 4 CGs.png" style="width:100%; height:auto;"></center>
<center><figcaption>Example of Transformation Matrix with 4 CGs</figcaption></center>

## Mix Presentation Encoding ## {#iamfgeneration-mixpresentation}

For Mix Presentation OBU for one single channel-based audio element, Mix Presentation OBU shall follow following restrictions:
- [=num_sub_mixes=]: set to 1
- [=num_audio_elements=]: set to 1
- [=element_mix_config()=]: No parameter block for element_mix and default_mix_gain = 0dB
- [=output_mix_config()=]: No parameter block for output_mix and default_mix_gain = 0dB
- [=num_layouts=]: set to [=num_layers=]
- [=loudness_layout=]: set to L(1), L(2), ..., L([=num_layers=]).
- loudness_info() on L(1), loudness_info on L(2), ..., loudness_info on L([=num_layers=]): loudness information of the rendered audio to the measured layout L(i).
- Where L(i) is the measured layout for the ith layer and i = 1, 2, ..., [=num_layers=]

For Mix Presentation for one single scene-based audio element, Mix Presentation OBU shall follow following restrictions:
- [=num_sub_mixes=]: set to 1
- [=num_audio_elements=]: set to 1
- [=element_mix_config()=]: set to [=mix_gain=]
- [=output_mix_config()=]: set to [=output_mix_gain=]
- [=num_layouts=]: set to M1, the number of loudness informations which are provided.
- [=loudness_layout=]: set to L(1), L(2), ..., L(M1).
- loudness_info() on L(1), loudness_info on L(2), ..., loudness_info on L(M1): loudness information of the rendered audio to the measured layout L(i).
- Where L(i) is the measured layout for the ith loudness information and i = 1, 2, ..., M1.
- This Mix Presentation is authored by using the highest [=loudness_layout=].
 
For Mix Presentation for N (>1) audio elements (when num_sub-mixes = 1), Mix Presentation OBU shall follow following restrictions:
- [=num_sub_mixes=]: set to 1
- [=num_audio_elements=]: set to N
- [=element_mix_config()=] for each audio element: set to [=mix_gain=]
- [=output_mix_config()=]: set to [=output_mix_gain=]
- [=num_layouts=]: set to M2, the number of loudness informations which are provided.
- [=loudness_layout=]: set to L(1), L(2), ..., L(M2).
- loudness_info() on L(1), loudness_info on L(2), ..., loudness_info on L(M2): loudness information of the rendered audio to the measured layout L(i).
- Where L(i) is the measured layout for the ith loudness information and i = 1, 2, ..., M2.
- This Mix Presentation is authored by using the highest [=loudness_layout=].

### Element Mix Config (Informative) ###  {#iamfgeneration-mixpresentation-mix}

This section provide a guideline to generate element_mix_config().

An IA multiplexer may merge two or more IA sequences. In this case, it should adjust the gain values for [=element_mix_config()=]s as necessary to describe the desired relative gains between the IA sequences when they are summed to generate the final mix. It should also ensure that the gains selected do not result in clipping when the final mix is generated.

## Multiple Audio Elements Encoding ## {#iamfgeneration-multipleaudioelements}

This section provide a way to generate IA sequence having multiple audio elements from two IA simple or base profiles.

### Multiple Audio Elements with One Codec Config (Informative) ### {#iamfgeneration-multipleaudioelements-onecodec}

This section provides a way how to generate IA sequence having multiple audio elements from two IA simple profiles with the same codec config OBU. However, the result shall comply with the base profile of IA sequence.

Step1: Descriptor OBUs are generated as follows:
- Magic Code OBU: get the larger version field and the larger profile version field, respectively.
- Codec Config OBU
	- take just one codec_id and codec_config()
- Audio Element OBUs: just take all of them except followings:
	- codec_config_id in each Audio Element OBU is updated to indicate [=codec_config_id=] specified in the taken Codec Config OBU.
	- [=audio_element_id=]s are updated to be unique in all of Audio Element OBUs.
	- [=audio_substream_id=]s are updated to be unique in all of Audio Element OBUs. 
	- parameter_ids in [=ParamDefinition()=]s carried in each Audio Element OBU are updated to refer its associated parameters correctly.
- Mix Presentation OBUs: just take all of them and generate new ones which are used for mixing of multiple audio elements if needed except following:
	- audio_element_ids in each Mix Presentation OBU are updated to indicate the [=audio_element_id=]s specified in Audio Element OBUs.
	- parameter_ids in [=ParamDefinition()=]s carried in each Mix Presentation OBU are updated to refer its associated parameters correctly.

Step2: ith temporal unit is generated as follows:
- Just take all of temporal units for ith frames from each audio element and keep the order of temporal units as the order of audio element OBUs in descriptor OBUs except following:
	- [=obu_type=]s are updated to be aligned according to [=audio_substream_id=]s specified in Audio Element OBUs.
	- [=parameter_id=]s in Parameter Block OBUs are updated to uniquely indentify the parameter in IA sequence and based on the parameter_ids in [=ParamDefinition()=]s carried in Descriptor OBUs.
- It may have the immediately preceding temporal delimiter OBU for each temporal unit.

Step3: Update Sync OBU.
	- Sync OBU is updated based on Sync OBUs of each IA sequence and updated [=audio_substream_id=]s and [=parameter_id=]s.

Step4: Generate IA sequence which starts descriptor OBUs, followed by Sync OBU and followed by temporal units in order.

## Post Processing ## {#iamfgeneration-postprocessing}

This section provides a way to generate algorithms for post processing.

### Loudness Information ###  {#iamfgeneration-postprocessing-loudness}

This section provides a way to generate loudness_info().
		
For a given Mix Presentation OBU and a given [=loudness_layout=] of a sub-mix of the given Mix Presentation OBU, the followings are processed in order to produce loudness_info().
- Each of the Audio Elements specified in the sub-mix of the given Mix Presentation OBU is rendered to the given [=loudness_layout=] according to [=rendering_config()=] for the Audio Element.
- Each of the Audio Elements specified in the sub-mix of the given Mix Presentation OBU applies [=mix_gain=] according to [=element_mix_config()=] for the Audio Element.
- All of the Audio Elements specified in the sub-mix of the given Mix Presentation OBU are summed, and then applies [=mix_gain=] according to [=output_mix_config()=] for the sub-mix.
- Generate loudness_info() of the mixed audio according to [[#obu-mixpresentation-loudness]].

# Consumption of IAMF bitstream # {#iamfconsumption}

ISSUE: TODO. Fill in example workflows.

# Annex

## Annex A: ID Linking Scheme (Informative)

The below figure shows the linking scheme among IDs in obu_header or obu payload.

<center><img src="images/ID Linking Example.png" style="width:100%; height:auto;"></center>
<center><figcaption>ID Linking Scheme</figcaption></center>

In the above figure, 
- Codec Config OBU with codec_config_id  = 0 is providing codec_id and its decoder_config().
- Mix Presentation OBU with mix_presentation_id  = 21 is saying:
	- There are two Audio Elements(audio_element_id = 11 and 12) which need to be mixed. The audio_element_id = 11 and the audio_element_id = 12 are linked to the Audio Element OBUs with audio_element_id = 11 and audio_element_id = 12, respectively.
		- There is one or more Parameter Block OBUs with parameter_id = 32 to be used for mixing of the Audio Element with audio_element_id = 11. 
		- There is one or more Parameter Block OBUs with parameter_id = 33 to be used for mixing of the Audio Element with audio_element_id = 12.
	- There is one or more Parameter Block OBUs with parameter_id = 34 to be used for mixing of the two Audio Elements.
- Audio Element OBU with audio_element_id = 11 is saying:
	- This audio element has been coded using Codec Config OBU with codec_config_id = 0. 
	- There are two Substreams (audio_substream_id = 0 and 1) in this audio element. The audio_substream_id = 0 and the audio_substream_id = 1 are linked to the Audio Frame OBUs with audio_substream_id = 0 and audio_substream_id = 1(i.e. obu_type = OBU_IA_Audio_Frame_ID0 and obu_type = OBU_IA_Audio_Frame_ID1), respectively.
	- There is one or more Parameter Block OBUs with parameter_id = 31 to be used for demixing of this audio element.
- Audio Element OBU with audio_element_id = 12 is saying:
	- This audio element has been coded by using Codec Config OBU with codec_config_id = 0.
	- There is one Substream (audio_substream_id = 2) in this audio element. The audio_substream_id = 2 is linked to the Audio Frame OBUs with audio_substream_id = 2 (i.e. obu_type = OBU_IA_Audio_Frame_ID2).
- Audio Frame OBU with ID = 0 (i.e. obu_type = OBU_IA_Audio_Frame_ID0) is providing the coded data which has been coded by using Codec Config OBU with codec_config_id = 0 of Substream with audio_substream_id = 0.
- Audio Frame OBU with ID = 1 (i.e. obu_type = OBU_IA_Audio_Frame_ID1) is providing the coded data which has been coded by using Codec Config OBU with codec_config_id = 0 of Substream with audio_substream_id = 1.
- Audio Frame OBU with ID = 2 (i.e. obu_type = OBU_IA_Audio_Frame_ID2) is providing the coded data which has been coded by using Codec Config OBU with codec_config_id = 0 of Substream with audio_substream_id = 2.
- Parameter Block OBU with parameter_id = 31 is providing demixing_info_parameter_data() to be applied for demixing of the Audio Element with audio_element_id = 11.
- Parameter Block OBU with parameter_id = 32 is providing mix_gain_parameter_data() to be applied to the rendered audio element after rendering according to render_config() of the Audio Element with audio_element_id = 11.
- Parameter Block OBU with parameter_id = 33 is providing mix_gain_parameter_data() to be applied to the rendered audio element after rendering according to render_config() of the Audio Element with audio_element_id = 12.
- Parameter Block OBU with parameter_id = 34 is providing mix_gain_parameter_data() to be applied to the mixed audio of the two rendered audios.

## Annex B: Short-lived Audio (Normative)

An IA sequence may contain audio elements which are short-lived, where the audio element may not exist for the entire timeline of the IA sequence. There is a method for signalling this. Consider the example with two audio elements, A and B, present at the start of the IA sequence, where B is a short-lived audio element with a length shorter than A.

1. The method uses a new set of Descriptor OBUs. The first set of Descriptor OBUs includes an Audio Element OBU for each of A and B, and a Mix Presentation OBU that references both A and B. When the audio element B has ended, a second set of Descriptor OBUs is placed in the IA stream, which includes an Audio Element for only A, and a Mix Presentation OBU that references only A.

In the case, relevant parameter blocks must be updated in a way to match the timing of the short-lived audio elements if necessary to ensure that the processed audio output is correct.
