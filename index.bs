<pre class='metadata'>
Group: AOM
Status: WGD
Title: Immersive Audio Container
Editor: SungHee Hwang, Samsung, hshee@samsung.com
Editor: Felicia Lim, Google, flim@google.com
Repository: AOMediaCodec/iac
Shortname: iac
URL: https://aomediacodec.github.io/iac/
Date: 2022-08-22
Abstract: This document specifies the immersive audio (IA) bitstream format and the storage format for the IA bitstream in one single [[!ISOBMFF]] track.
</pre>

<pre class="anchors">
url: https://www.iso.org/standard/68960.html#; spec: ISOBMFF; type: dfn;
	text: AudioSampleEntry
	text: boxtype
	text: grouping_type
	text: SampleGroupDescriptionEntry
	text: channelcount
	text: samplerate

url: https://www.iso.org/standard/68960.html#; spec: ISOBMFF; type: property;
	text: iso6
	text: sgpd
	text: stsd
	text: sbgp

url: https://www.iso.org/standard/43345.html#; spec: AAC; type: dfn;
	text: raw_data_block()
	text: ADTS
	text: Low Complexity Profile

url: https://opus-codec.org/docs/opus_in_isobmff.html#; spec: OPUS-IN-ISOBMFF; type: dfn;
	text: OpusSpecificBox
	text: OutputChannelCount
	text: OutputGain
	text: ChannelMappingFamily
	text: PreSkip
	text: InputSampleRate


url: https://opus-codec.org/docs/opus_in_isobmff.html#; spec: OPUS-IN-ISOBMFF; type: property;
	text: opus
	text: dOps

url: https://www.iso.org/standard/55688.html#; spec: MP4-Systems; type: dfn;
	text: objectTypeIndication
	text: streamType
	text: upstream
	text: decSpecificInfo()
	text: DecoderConfigDescriptor()

url: https://www.iso.org/standard/76383.html#; spec: MP4-Audio; type: dfn;
	text: AudioSpecificConfig()
	text: audioObjectType
	text: channelConfiguration
	text: GASpecificConfig()
	text: frameLengthFlag
	text: dependsOnCoreCoder
	text: extensionFlag

url: https://www.iso.org/standard/79110.html#; spec: MP4; type: dfn;
	text: ESDBox

url: https://www.iso.org/standard/79110.html#; spec: MP4; type: property;
	text: mp4a
	text: esds

url: https://tools.ietf.org/html/rfc6381#; spec: RFC6381; type: property;
	text: codecs

url: https://tools.ietf.org/html/rfc8486#; spec: RFC8486; type: dfn;
	text: channel count

url: https://tools.ietf.org/html/rfc7845#; spec: RFC7845; type: dfn;
	text: ID Header
	text: Output Gain

url: https://tools.ietf.org/html/rfc6716#; spec: RFC6716; type: dfn;
	text: opus packet

url: https://www.itu.int/dms_pubrec/itu-r/rec/bs/R-REC-BS.1770-4-201510-I!!PDF-E.pdf#; spec: ITU1770-4; type: dfn;
	text: LKFS

url: https://www.itu.int/dms_pubrec/itu-r/rec/bs/R-REC-BS.2051-3-202205-I!!PDF-E.pdf#; spec: ITU2051-3; type: dfn;
	text: Loudspeaker configuration for Sound System A (0+2+0)
	text: Loudspeaker configuration for Sound System B (0+5+0)
	text: Loudspeaker configuration for Sound System C (2+5+0)
	text: Loudspeaker configuration for Sound System D (4+5+0)
	text: Loudspeaker configuration for Sound System I (0+7+0)
	text: Loudspeaker configuration for Sound System J (4+7+0)

url: https://en.wikipedia.org/wiki/Q_(number_format); spec: Q-Format; type: dfn;
	text:

</pre>

<pre class='biblio'>
{
	"AI-CAD-Mixing": {
		"title": "AI 3D immersive audio codec based on content-adaptive dynamic down-mixing and up-mixing framework",
		"status": "Paper",
		"publisher": "AES",
		"href": "https://www.aes.org/e-lib/browse.cfm?elib=21489"
	},
	"AAC": {
		"title": "Information technology — Generic coding of moving pictures and associated audio information — Part 7: Advanced Audio Coding (AAC)",
		"status": "Standard",
		"publisher": "ISO/IEC",
		"href": "https://www.iso.org/standard/43345.html"
	},
	"MP4-Audio": {
		"title": "Information technology — Coding of audio-visual objects — Part 3: Audio",
		"status": "Standard",
		"publisher": "ISO/IEC",
		"href": "https://www.iso.org/standard/76383.html"
	},
	"MP4-Systems": {
		"title": "Information technology — Coding of audio-visual objects — Part 1: Systems",
		"status": "Standard",
		"publisher": "ISO/IEC",
		"href": "https://www.iso.org/standard/55688.html"
	},
	"OPUS-IN-ISOBMFF": {
		"title": "Encapsulation of Opus in ISO Base Media File Format",
		"status": "Best Practice",
		"publisher": "IETF",
		"href": "https://opus-codec.org/docs/opus_in_isobmff.html"
	},
	"ITU1770-4": {
		"title": "Algorithms to measure audio programme loudness and true-peak audio level",
		"status": "Standard",
		"publisher": "ITU",
		"href": "https://www.itu.int/dms_pubrec/itu-r/rec/bs/R-REC-BS.1770-4-201510-I!!PDF-E.pdf"
	},
	"ITU2051-3": {
		"title": "Advance sound system for programme production",
		"status": "Standard",
		"publisher": "ITU",
		"href": "https://www.itu.int/dms_pubrec/itu-r/rec/bs/R-REC-BS.2051-3-202205-I!!PDF-E.pdf"
	},
	"Q-Format": {
		"title": "Q (number format)",
		"status": "Best Practice",
		"publisher": "Wikepedia",
		"href": "https://en.wikipedia.org/wiki/Q_(number_format)"
	}
}
</pre>


# Introduction # {#introduction}

The <dfn noexport>IA bitstream</dfn> is designed to represent immersive audio for presentation on a wide range of devices in both dynamic streaming and offline applications. These applications include internet audio streaming, multicasting/broadcasting services, file download, gaming, communication, virtual and augmented reality, and others. In these applications, audio may be played back on a wide range of devices, e.g. headsets, mobile phones, tablets, TVs, sound bars, home theater systems and big screen. 

The bitstream comprises a number of coded audio substreams and the metadata that describes how to decode, render and mix the substreams to generate an audio signal for playback. The bitstream format itself is codec-agnostic; any supported audio codec may be used to code the audio substreams.

The immersive audio container (<dfn noexport>IAC</dfn>) is the storage format for immersive audio (IA) bitstream in one single [[!ISOBMFF]] track.

The figure below shows the conceptual IAC architecture.

<center><img src="images/Conceptual IAC Architecture.png"></center>
<center><figcaption>Conceptual IAC Architecture</figcaption></center>

For a given input 3D audio,
- Pre-Processor generates Pre-Processed Audio and Codec Agnostic Metadata for immersive audio (IA).
- Audio Codec Enc generates Codec-Dependent Bitstream, which consists of the coded streams, coded from Pre-Processed Audio.
- File Packager generates IAC File by encapsulating IA bitstream, which consists of Codec-Dependent Bitstream and Codec Agnostic Metadata, into [[!ISOBMFF]] tracks.
- File Parser reconstructs IA bitstream by decapsulating IAC File.
- Audio Codec Dec outputs a decoded Pre-Processed Audio after decoding of Codec-Dependent Bitstream.
- Post-Processor outputs Immersive 3D Audio by using the decoded Pre-Processed Audio and Codec Agnostic Metadata.


This specification is formulated as follows:
- [[#introduction]] describes a conceptual IAC architecture.
- [[#iabitstream-definition]] specifies the definition of IA bitstream.
- [[#basic-encapsulation]] specifies the way to encapsulate IA bitstream into [[!ISOBMFF]] tracks.
- [[#iacdecapsulation]] provides a way to decapsulate IAC file back into IA bitstream.
- [[#iaencoding]] provides a guideline for Pre-Processor to generate Pre-Processed Audio and Codec Agnostic Metadata and IAC encoding model based on the conventional more or stereo encoding model.
- [[#iadecoding]] provides IAC decoding model based on the conventional more or stereo decoding model and a guideline for Post-Processor to generate Immersive 3D Audio.
- [[#iaprofiles]] provides profiles for IA bitstreams and IA decoders.


# Architecture # {#architecture}

## IA Bitstream Components ## {#iab-components}

The IA bitstream format consists of audio substreams, audio elements, mix presentations and parameters.

- <dfn noexport>Audio substreams</dfn> are the actual audio signals, which may be encoded with any compatible audio codec. In the video-on-demand (VOD) use-case, e.g. encapsulation within an ISOBMFF container, all audio substreams within the same IA bitstream must use the same audio codec. In the live linear use-case, different audio codecs may be used for different audio substreams.
- <dfn noexport>Audio elements</dfn> are the 3D representations of the audio signals, and are constructed from one or more audio substreams and the metadata describing them. The audio substreams associated with one audio element must use the same audio_substream_config().
- <dfn noexport>Mix presentations</dfn> contain metadata that describe how the audio elements should be rendered and mixed together for playback through physical loudspeakers or headphones. At any given time, only one mix presentation should be used for playback. However, multiple mix presentations may be defined as alternatives to each other within the same IA bitstream. Furthermore, the choice of which mix presentation to use at playback may be left to the user. For example, multi-language support may be implemented by defining different mix presentations, where the first mix might describe the use of the audio element with English dialogue, and the second mix might describe the use of the audio element with French dialogue.
- <dfn noexport>Parameters</dfn> are the values that are associated with the algorithms used for decoding, reconstructing, rendering and mixing. Parameters may change their values over time and may further be animated; for example, any changes in values may be smoothed over some time interval. Their rate of change is specific to its respective algorithm, and is independent of other algorithms and the frame rates associated with the audio substreams. As such, they may be viewed as a 1D signal that have different metadata specified for different time intervals.

The figure below shows the relationship between the audio substreams, audio elements and mix presentations and the processing flow to obtain the immersive audio playback.

<center><img src="images/decoding_flow_cropped.svg" style="width:100%; height:auto;"></center>
<center><figcaption>Processing flow to decode, reconstruct, render and mix the audio signals for immersive audio playback.</figcaption></center>


## <dfn noexport>Metadata Update Rates</dfn> ## {#metadata-updaterates}

The IA bitstream supports the description of multiple audio substreams and algorithms, which may have different metadata update rates to each other. The update rate for the audio substreams and audio elements is governed by the frame rates of the audio codec used. Since a single bitstream may support multiple codecs, this may lead to multiple different frame rates.  The algorithms for rendering and mixing may have parameters that update at different rates to each other and to the audio frame rates. Therefore, each metadata in the IA bitstream contains timing information to indicate the start time and duration for which it is valid.

# Immersive Audio Bitstream Definition # {#iabitstream-definition}

An immersive audio (IA) sequence is composed of a sequence of IA bitstreams.

Each IA bitstream is self-decodable and composed of [=global metadata=], [=update metadata=] and [=audio substreams=]. 

There can be two types of IA bitstreams. The first is an IA bitstream with one single frame size and the second is an IA bitstream with two or more different frame sizes. The conceptual diagrams are shown in the two figures below.

<center><img src="images/Immersive Audio Bitstream with one single frame size (before OBU packing).png" style="width:100%; height:auto;"></center>
<center><figcaption>Immersive Audio Bitstream with one single frame size (before OBU packing).</figcaption></center>

In the first type of IA bitstream with one single frame size, all [=audio substreams=] in the same IA bitstream have the same audio_substream_config().

In this case, Audio Frames depicted in the diagram above is a set of audio substream frames with the same start timestamp.
- Audio Frames #i is composed of Ni number of frames, each of them is frame #i of each substream. Where, i = 1, 2, ..., k.

<center><img src="images/Immersive Audio Bitstream with two frame sizes (before OBU packing).png" style="width:100%; height:auto;"></center>
<center><figcaption>Immersive Audio Bitstream with two frame sizes (before OBU packing).</figcaption></center>

In the second type of IA bitstream with two or more frame sizes, the audio substreams in the same IA bitstream may have different audio_substream_config() with different [=num_samples_per_frame=].

The diagram above depicts an example case where there are two frame sizes in the same IA bitstream. In this case, Audio Frames is a set of audio substream frames with the same start timestamp and the same frame size.
- Audio Frames #i1 for frame size 1 is composed of Ni1 number of frames, each of them is frame #i1 of each substream. Where, i1 = 1, 2, ..., k1.
- Audio Frames #i2 for frame size 2 is composed of Ni2 number of frames, each of them is frame #i2 of each substream. Where, i2 = 1, 2, ..., k2.


## <dfn noexport>Global Metadata</dfn> ## {#metadata-global}
The global metadata contains all the information that is required to setup and configure the decoders, reconstruction algorithms, renderers and mixers. As such, they can be considered to be valid random access points.

It may also contain a description of list of parameters for the entire timeline, or a section of it.

In the VOD use-case, the global metadata must be placed at the beginning of the IA bitstream.

In the live linear use-case, the global metadata is placed at the beginning of the bitstream, and again periodically to provide setup configuration information to receivers that are joining mid-stream.

If there are any mid-stream changes in the configuration, there are two ways to signal this in the IA bitstream.

1. The global metadata may contain a list of all configurations for the entire timeline, alongside a description of the start time and duration for each of the configurations.

2. Additional global metadata may be placed anywhere mid-stream as needed to signal the new configuration. These must be also contain a complete description of all configuration, including repeating unchanged configuration from the previous global metadata. This option may lead to redundant data, which may be possible to refactor out if the transport container provides a mechanism to do so.

## Update Metadata ## {#metadata-update}

The <dfn noexport>update metadata</dfn> signals any parameter updates in the bitstream. This may be included anywhere in the bitstream, and as often as needed.

By itself, the update metadata does not contain sufficient information to decode, reconstruct, render and mix the following audio substream frames. As such, it must be used in conjunction with the latest global metadata.

## Audio Substreams ## {#substreams}

The audio substreams contains one or more substreams, each of which contains one or more audio frames.

The total length of the sequence of audio frames between global or update metadata can be variable. In other words, there does not need to be a periodic inclusion of update metadata in between the audio substreams.

## Bitstream Packing ## {#bitstream-packing}

All metadata within an IA bitstream contains timing information that includes the start time and the duration for which it is valid. This is used when determining the order in which the metadata is packed in the bitstream.

- The global and update metadata, and audio substreams, should be packed chronologically according to their start time.
- If there are multiple metadata and audio substreams with the same start time, they should be packed in the following order:
    1. Global metadata
    2. Update metadata
    3. Audio substreams
- Within a sequence of metadata or audio substreams with the same start time, ordering does not matter if they have associated IDs.

As an illustrative example, consider a bitstream that contains the following:

1. Two substreams, one coded with Codec A and the second coded with Codec B.
		- Codec A has a frame size of 20 ms.
		- Codec B has a frame size of 30 ms.
2. Three parameters with different update rates.
		- Parameter A has an update rate of 10 ms.
		- Parameter B has an update rate of 40 ms.
		- Parameter C has a variable update rate.

The belwo figure shows the metadata and substreams, and the bitstream packing for this example.

<center><img src="images/bitstream_packing.svg" style = "width: 100%; height: 100%;"></center>
<center><figcaption>Example of how substreams and parameter metadata with different update rates should be packed in the bitstream.</figcaption></center>


## Open Bitstream Unit (OBU) Syntax and Semantics ## {#obu-section}

The IA bitstream uses the OBU syntax.

This section specifies the OBU syntax elements and the meaning of the syntax elements. 

<!--<center><img src="images/Hypothetical IAC Decoder Model.png" style="width:100%; height:auto;"></center>-->
<!--<center><figcaption>Hypothetical IAC Decoder Model</figcaption></center>-->


### General OBU Syntax and Semantics ### {#obu-general}

<b>Syntax</b>

```
class audio_open_bitstream_unit(sz) {
  if (SeenIABitstream) {
    obu_header();

    if (obu_has_size_field)
      unsigned int (leb128()) obu_size;
    else
      obu_size = sz - 1;

    if (obu_type == OBU_IA_Global_Metadata)
      global_metadata_obu();
    else if (obu_type == OBU_IA_Update_Metadata)
      update_metadata_obu();
    else if (obu_type == OBU_IA_Audio_Frame)
      audio_frame_obu(obu_size);
    else 
      reserved_obu()

    byte_alignment():
  }
  else {
    obu_header();
    if (obu_type != OBU_IA_Stream_Indicator)
      drop_obu();
    else
      ia_stream_indicator_obu();
  }
}
```

<b>Semantics</b>

The variable SeenIABitstream shall initially be set to 0. If the syntax element obu_type is equal to OBU_IA_Stream_Indicator, the variable SeenIABitstream shall be set to 1. When SeenIABitstream is set to 1, an ordered series of OBUs is presented to the decoding process. Each OBU is given to the decoding process as a string of bytes along with a variable sz that identifies the total number of bytes in the OBU.

<dfn noexport>obu_has_size_field</dfn> equal to 1 indicates that the obu_size syntax element will be present. In this case, the variable sz is unused and does not need to be provided. obu_has_size_field equal to 0 indicates that the obu_size syntax element will not be present.

<dfn noexport>obu_size</dfn> shall indicate the size in bytes of the OBU not including the bytes within obu_header or the obu_size syntax element.

OBU data starts on the first (most significant) bit and ends on the last bit of the given bytes. The payload of an OBU lies between the first bit of the given bytes and the last bit before the first zero bit of the byte_alignment() function call.

<dfn noexport>drop_obu( )</dfn> is a function call that indicates when the IAC decoder should ignore an OBU because it is not defined to be an IA bitstream.




### OBU Header Syntax and Semantics ### {#obu-header}

<b>Syntax</b>

```
class obu_header() {
  unsigned int (1) obu_forbidden_bit;
  unsigned int (4) obu_type;
  unsigned int (1) obu_reserved_1bit;
  unsigned int (1) obu_has_size_field;
  unsigned int (1) obu_reserved_1bit;
}
```

<b>Semantics</b>

OBUs are structured with a header and a payload. The header identifies the type of the payload using the obu_type header parameter.

<dfn noexport>obu_forbidden_bit</dfn> shall be set to 0.

<dfn noexport>obu_type</dfn> shall specify the type of data structure contained in the OBU payload.

[=obu_has_size_field=] shall indicate the presence of [=obu_size=] field.

<pre class = "def">
obu_type: Name of obu_type
   0    : OBU_IA_Stream_Indicator
   1    : OBU_IA_Global_Metadata
   2    : OBU_IA_Update_Metadata
   3    : OBU_IA_Audio_Frame
  4~15  : Reserved
</pre>

Reserved units are for future use and shall be ignored by an IAC-OBU parser.

<dfn noexport>obu_reserved_1bit</dfn> shall be set to 0. The value is ignored by an IAC-OBU parser.()

### Byte Alignment Syntax and Semantics ### {#obu-bytealignment}

<b>Syntax</b>

```
class byte_alignment() {
  while (get_position() & 7)
    unsigned int (1) zero_bit;
}
```

<b>Semantics</b>

<dfn noexport>zero_bit</dfn> shall be equal to 0 and is inserted into the bitstream to align the bit position to a multiple of 8 bits.


### Reserved OBU Syntax and Semantics ### {#obu-reserved}

The reserved OBU allows the extension of this specification with additional OBU types in a way that allows older IAC-OBU parsers to ignore them.


### IA Stream Indicator OBU Syntax and Semantics ### {#obu-iastreamindicator}

<b>Syntax</b>

```
class ia_stream_indicator_obu() {
  SeenIABitstream = 1;
}
```

NOTE: The IA Stream Indicator OBU has an empty payload.

<b>Semantics</b>

<dfn noexport>SeenIABitstream</dfn> indicates whether a series of OBUs for the IA bitstream will follow. It is initialized to zero.

### Audio Frame OBU Syntax and Semantics ### {#obu-audio-frame}

<b>Syntax</b>

```
class audio_frame_obu(obu_size) {
  unsigned int (leb128()) audio_stream_id_ref;
  unsigned int (leb128()) start_timestamp;

  unsigned int (obu_size - N) substream();
}
```

<dfn noexport>audio_substream_id_ref</dfn> identifies the substream that the coded audio data in this frame corresponds to.

<dfn value noexport for="audio_frame_obu">start_timestamp</dfn> indicates the starting timestamp in the overall bitstream for this frame of coded audio data.

ISSUE: what unit shall be used for the timestamps throughout IAC?

<dfn noexport>substream()</dfn> is a function call that contains the raw coded audio data.

<dfn noexport>N</dfn> is the number of bytes used to represent the variables audio_substream_id_ref and start_timestamp. If obu_size is equal to N, this indicates that there is no data present in substream(). This may be used to indicate the presence of an audio substream that contains no audio for a particular time duration.


### Global Metadata OBU Syntax and Semantics ### {#obu-global-metadata}

<b>Syntax</b>

```
class global_metadata_obu() {
  unsigned int (8) version;
  unsigned int (leb128()) num_functions;
  for (i = 0; i < num_functions; i++) {
    unsigned int (leb128()) function_id_ref;
    function_call(function_id_ref);
  }
}
```

<dfn noexport>version</dfn> shall indicate the version of IA bitstream. It shall be set to 0 for this version of the specification. Implementations should treat IA bitstream where the MSB four bits of the version number match that of a recognized specification as backwards compatible with that specification. That is, the version number can be split into "major" and "minor" version sub-fields, with changes to the minor sub-field (in the LSB four bits) signaling compatible changes. For example, an implementation of this specification should accept any stream with a version number of ’15’ or less, and should assume any stream with a version number ’16’ or
greater is incompatible.

<dfn noexport>num_functions</dfn> shall indicate the number of functions to be called in this OBU.

<dfn noexport>function_id_ref</dfn> shall indicate function_id of the function to be called.


```
class function_call(function_id_ref) {
  if (function_id_ref == AUDIO_SUBSTREAMS) {
    audio_substreams();
  }
  else if (function_id_ref == AUDIO_ELEMENTS) {
    audio_elements();
  }
  else if (function_id_ref == MIX_PRESENTATIONS) {
    mix_presentations();
  }
}
```

#### Audio Substreams Syntax and Semantics #### {#syntax-audio-substreams}

<b>Syntax</b>

```
class audio_substreams() {
  f(1) substream_id_mode;

  if (substream_id_mode == ALL) {
    audio_substream_config();
  } else if (substream_id_mode == MANY) {
    unsigned int (leb128()) num_substreams;
    for (i = 0; i < num_substreams; i++) {
      unsigned int (leb128()) audio_substream_id;
      audio_substream_config();
    }
  }
}
```

<b>Semantics</b>

<dfn noexport>substream_id_mode</dfn> specifies the method used for signalling the metadata for the audio substreams.

<pre class = "def">
substream_id_mode: Method for signalling the metadata for the audio substreams.
   0    : ALL
   1    : MANY
</pre>

If substream_id_mode is equal to ALL, this indicates that all substreams are configured identically. Only one set of configuration needs to be specified, provided by audio_substream_config().

If substream_id_mode is equal to MANY, this indicates that all substreams are configured differently. Each substream requires a corresponding set of configuration to be specified, provided by audio_substream_config().

<dfn noexport>audio_substream_id</dfn> is a unique ID that can be used by other function calls in the IA bitstream to reference this audio substream.

##### Audio Substream Config Syntax and Semantics ##### {#syntax-audio-substreams-config}

<b>Syntax</b>

```
class audio_substream_config() {
  unsigned int (32) codec_id;
  decoder_config(codec_id);
  unsigned int (leb128()) num_samples_per_frame;
  unsigned int (leb128()) num_samples_to_trim_at_start;
  unsigned int (leb128()) num_samples_to_trim_at_end;
}
```

<b>Semantics</b>

<dfn noexport>codec_id</dfn> is a ‘four-character code’ (4CC) to identify the codec used to generate the audio substreams. It shall be the same as the [=boxtype=] of its AduioSampleEntry if exist. It shall be 'opus' for IAC-OPUS and 'mp4a' for IAC-AAC-LC.

<dfn noexport>decoder_config</dfn> is a set of decoding parameters required to decode an audio substream for a given codec_id. The decoder_config for IAC-OPUS shall conform to Codec_Specific_Info of [[#iac-opus-specific]] and decoder_config for IAC-AAC-LC shall conform to Codec_Specific_Info of [[#iac-aac-lc-specific]].

<dfn noexport>num_samples_per_frame</dfn> indicates the frame length, in samples, of the raw coded audio provided by in audio_frame_obu().

<dfn noexport>num_samples_to_trim_at_start</dfn> indicates the number of samples that needs to be trimmed from the start of the audio substream for gapless playback.

<dfn noexport>num_samples_to_trim_at_end</dfn> indicates the number of samples that needs to be trimmed from the end of the audio substream for gapless playback.

#### Audio Elements Syntax and Semantics #### {#syntax-audio-elements}

<b>Syntax</b>

```
class audio_elements() {
  leb128 num_audio_elements;
  for(i = 0; i < num_audio_elements; i++) {
    audio_element();
  } 
}

class audio_element() {
  unsigned int (leb128()) audio_element_id;
  f(3) audio_element_type;

  unsigned int (leb128()) num_substreams;
  for (i = 0; i < num_substreams; i++) {
    unsigned int (leb128()) audio_substream_id_ref;
  }

  unsigned int (leb128()) num_timestamp_intervals;
  for (i = 0; i < num_timestamp_intervals; i++) {
    unsigned int (leb128()) start_timestamp;
    unsigned int (leb128()) duration;
  }

  if (audio_element_type == CHANNEL_BASED) {
    scalable_channel_layout_config();
  } else if (audio_element_type == AMBISONIC) {
    ambisonics_config();   
  }
}
```

<b>Semantics</b>

<dfn value noexport for="audio_elements">num_audio_elements</dfn> specifies the number of audio elements present in the IA bitstream.

<dfn noexport>audio_element()</dfn> is the function call that provides the configuration for an audio element.

<dfn noexport>audio_element_id</dfn> is a unique ID that can be used by other function calls in the IA bitstream to reference this audio element.

<dfn noexport>audio_element_type</dfn> indicates the audio representation which is constructed from one or more audio substreams.

<pre class = "def">
audio_element_type: The type of audio representation.
   0    : CHANNEL_BASED
   1    : SCENE_BASED
  2~7   : Reserved
</pre>

<dfn noexport>num_substreams</dfn> specifies the number of audio substreams that are used to reconstruct this audio element.

<dfn value noexport for="audio_element">audio_substream_id_ref</dfn> specifies the unique ID of the audio substream that is used to reconstruct this audio element.

<dfn value noexport for="audio_element">num_timestamp_intervals</dfn> specifies the number of time intervals where the audio element configuration given here is valid and applicable in the overall timeline.

<dfn value noexport for="audio_element">start_timestamp</dfn> specifies, for each timestamp interval, the starting time when the audio element configuration given here is valid and applicable. For the IA bistream with one single frame size, the starting time should be aligned with one of frame boundaries of the other audio elements.

<dfn value noexport for="audio_element">duration</dfn> specifies, for each timestamp interval, the duration after the corresponding start_timestamp when the audio element configuration given here is valid and applicable.

<dfn noexport>scalable_channel_layout_config()</dfn> is a function call that provides the metadata required for combining the substreams identified here in order to reconstruct a scalable channel layout.

<dfn noexport>ambisonics_config()</dfn> is a function call that provides the metadata required for combining the substreams identified here in order to reconstruct an Ambisonics layout.


##### Scalable Channel Layout Config Syntax and Semantics ##### {#syntax-scalable-channel-layout-config}

[=scalable_channel_layout_config()=] contains information regarding the configuration of scalable channel audio.

<b>Syntax</b>

```
class scalable_channel_layout_config() {
  unsigned int (3) num_layers;
  unsigned int (5) reserved;
  for (i = 1; i <= num_layers; i++) {
    channel_audio_layer_config(i);
  }
}

class channel_audio_layer_config(i) {
  unsigned int (4) loudspeaker_layout(i);
  unsigned int (1) output_gain_is_present_flag(i);
  unsigned int (1) recon_gain_is_present_flag(i);
  unsigned int (2) reserved;
  unsigned int (8) substream_count(i);
  unsigned int (8) coupled_substream_count(i);
  signed int (16) loudness(i);
  if (output_gain_is_present_flag(i) == 1) {
    unsigned int (6) output_gain_flag(i);
    unsigned int (2) reserved;
    signed int (16) output_gain(i);
  }
}
```

When an audio element is composed of G(r) number of substreams, scalable channel audio for the audio element is layered into [=num_layers=] = r number of ChannelGroups.
- <dfn noexport>ChannelGroup</dfn> is a set of substreams which is able to provide a spatial resolution of audio contents by itself or which is able to provide an enhanced spatial resolution of audio contents by combining with the preceding ChannelGroups within the [=audio frames=].
- ChannelGroup #q consists of G(q)-G(q-1) number of substreams. Where, q = 1, 2, ..., r and G(0) = 0.
- <dfn noexport for = "Scalable Channel Audio">Audio Frames</dfn> is a set of frames with the same start timestamps of the single audio element for scalable channel audio. Each of them comes from each substream.
- Every [=Audio Frames=] have the same number of frames, each of them comes from each substream. 
- When r > 1, update_metadata_obu may present in front of every [=Audio Frames=]. 

<center><img src="images/Immersive Audio Bitstream with scalable channel audio (before OBU packing).png" style="width:100%; height:auto;"></center>
<center><figcaption>Immersive Audio Bitstream with scalable channel audio (before OBU packing)</figcaption></center>

<b>Semantics</b>

<dfn noexport>num_layers</dfn> shall indicate the number of ChannelGroups for scalable channel audio. It shall not be set to zero and its maximum number shall be limited to 6.

<dfn noexport>channel_audio_layer_config()</dfn> is a function call that provides the information regarding the configuration of ChannelGroup for scalable channel audio.

<dfn noexport>loudspeaker_layout</dfn> shall indicate the channel layout for the channels to be reconstructed from the precedent ChannelGroups and the current ChannelGroup among ChannelGroups for scalable channel audio.

In the current version of the specification, [=loudspeaker_layout=] shall indicate one of 9 channel layouts including Mono, Stereo, 5.1ch, 5.1.2ch, 5.1.4ch, 7.1ch, 7.1.2ch, 7.1.4ch and 3.1.2ch. Where,
- <dfn noexport>Stereo</dfn> is the loudspeaker configuration as depicted in [=Loudspeaker configuration for Sound System A (0+2+0)=] of [[!ITU2051-3]].
- <dfn noexport>5.1ch</dfn> is the loudspeaker configuration as depicted in [=Loudspeaker configuration for Sound System B (0+5+0)=] of [[!ITU2051-3]].
- <dfn noexport>5.1.2ch</dfn> is the loudspeaker configuration as depicted in [=Loudspeaker configuration for Sound System C (2+5+0)=] of [[!ITU2051-3]].
- <dfn noexport>5.1.4ch</dfn> is the loudspeaker configuration as depicted in [=Loudspeaker configuration for Sound System D (4+5+0)=] of [[!ITU2051-3]].
- <dfn noexport>7.1ch</dfn> is the loudspeaker configuration as depicted in [=Loudspeaker configuration for Sound System I (0+7+0)=] of [[!ITU2051-3]].
- <dfn noexport>7.1.2ch</dfn> is the combination of the loudspeaker configuration as depicted in [=Loudspeaker configuration for Sound System I (0+7+0)=] of [[!ITU2051-3]] and the left and right top front pair of the loudspeaker configuration as depicted in [=Loudspeaker configuration for Sound System J (4+7+0)=] of [[!ITU2051-3]].
- <dfn noexport>7.1.4ch</dfn> is the loudspeaker configuration as depicted in [=Loudspeaker configuration for Sound System J (4+7+0)=] of [[!ITU2051-3]].
- <dfn noexport>3.1.2ch</dfn> is the front subset (L/C/R/Ltf/Rtf/LFE) of [=7.1.4ch=].

<pre class = "def">
Loudspekaer Layout (4 bits) :  Channel Layout  : Loudspeaker Location Ordering
             0000           :       Mono       : C
             0001           :      Stereo      : L/R
             0010           :      5.1ch       : L/C/R/Ls/Rs/LFE
             0011           :     5.1.2ch      : L/C/R/Ls/Rs/Ltf/Rtf/LFE
             0100           :     5.1.4ch      : L/C/R/Ls/Rs/Ltf/Rtf/Ltr/Rtr/LFE
             0101           :      7.1ch       : L/C/R/Lss/Rss/Lrs/Rrs/LFE
             0110           :     7.1.2ch      : L/C/R/Lss/Rss/Lrs/Rrs/Ltf/Rtf/LFE
             0111           :     7.1.4ch      : L/C/R/Lss/Rss/Lrs/Rrs/Ltf/Rtf/Ltb/Rtb/LFE
             1000           :     3.1.2ch      : L/C/R//Ltf/Rtf/LFE
            others          :     reserved     :
</pre>

```
Where, C: Center, L: Left, R: Right, Ls: Left Surround, Lss: Left Side Surround, Rs: Right Surround, Rss: Right Side Surround, Ltf: Left Top Front, Rtf: Right Top Front, Ltr: Left Top Rear, Rtr: Right Top Rear, Ltb: Left Top Back, Rtb: Right Top Back, LFE: Low-Frequency Effects
```

<dfn noexport>output_gain_is_present_flag</dfn> shall indicate if output_gain information fields for the ChannelGroup presents .
- 0: No output_gain information fields for the ChannelGroup present.
- 1: output_gain information fields for the ChannelGroup present. In this case, output_gain_flags and output_gain fields present.

<dfn noexport>recon_gain_is_present_flag</dfn> shall indicate if recon_gain information fields for the ChannelGroup presents in Recon_Gain_Info().
- 0: No recon_gain information fields for the ChannelGroup present in Recon_Gain_Info_OBU.
- 1: recon_gain information fields for the ChannelGroup present in Recon_Gain_Info_OBU. In this case, recon_gain_flags and recon_gain fields present.


<dfn noexport>loudness</dfn> shall indicate the loudness value of the downmixed channels, for the channel layout which is indicated by loudspeaker_layout, from the original channel audio. It shall be stored in fixed-point value with 8 fractional bits (i.e. Q7.8 in [[!Q-Format]]) and shall be [=LKFS=] based on [[!ITU1770-4]], so it shall be to represent zero or negative value.

<dfn noexport>output_gain_flags</dfn> shall indicate the channels which output_gian is applied to. If a bit set to 1, output_gain shall be applied to the channel. Otherwise, output_gain shall not be applied to the channel.


<pre class = "def">
Bit position : Channel Name
    b5(MSB)  : Left channel (L1, L2, L3)
      b4     : Right channel (R2, R3)
      b3     : Left Surround channel (Ls5)
      b2     : Right Surround channel (Rs5)
      b1     : Left Top Front channel (Ltf)
      b0     : Rigth Top Front channel (Rtf)

</pre>

<dfn noexport>output_gain</dfn> shall indicate the gain value to be applied to the mixed channels which are indicated by output_gain_flags. It is 20*log10 of the factor by which to scale the mixed channels. It is stored in a 16-bit, signed, two’s complement fixed-point value with 8 fractional bits (i.e. Q7.8 in [[!Q-Format]]). Where, each mixed channel is generated by downmixing two or more input channels.


##### Ambisonics Config Syntax and Semantics ##### {#syntax-ambisonics-config}

[=ambisonics_config()=] contains information regarding the configuration of Ambisonics.

<b>Syntax</b>

```
class ambisonics_config() {
  unsigned int (leb128()) ambisonics_mode;
  if (ambisonics_mode == MONO) {
    ambisonics_mono_config();
  } else if (ambisonics_mode == PROJECTION) {
    ambisonics_projection_config();
  }
}

class ambisonics_mono_config() {
  unsigned int(8) output_channel_count (C);
  unsigned int(8) substream_count (N);
  unsigned int(8 * C) channel_mapping;
}

class ambisonics_projection_config() {
  unsigned int(8) output_channel_count (C);
  unsigned int(8) substream_count (N);
  unsigned int(8) coupled_substream_count (M);
  unsigned int(16 * (N + M) * C) demixing_matrix;
}
```

<b>Semantics</b>

<dfn noexport>ambisonics_mode</dfn> shall indicate the method of coding Ambisonics.
- 0: MONO. Ambisonics channels are coded as individual mono substreams. 
- 1: PROJECTION. Ambisonics channels are linearly projected onto another subspace before coding as a mix of coupled stereo and mono substreams.

<dfn noexport>output_channel_count</dfn> shall be the same as [=channel count=] in [[!RFC8486].

<dfn noexport>substream_count</dfn> shall indicate the number of audio substreams. It must be the same as [=num_substreams=] in its corresponding audio_element().

<dfn noexport>channel_mapping</dfn> shall be the same as the one for [=ChannelMappingFamily=] = 2 in [[!RFC8486]].

<dfn noexport>coupled_substream_count</dfn> shall indicate the number of referenced substreams that are that are coded as coupled stereo channels, where M <= N.

<dfn noexport>demixing_matrix</dfn> shall be the same as the one for [=ChannelMappingFamily=] = 3 in [[!RFC8486]].


#### Mix Presentations Syntax and Semantics #### {#syntax-mix-presentations}

<b>Syntax</b>

```
class mix_presentations() {
  unsigned int (leb128()) num_mixes;
  for(i = 0; i < num_mixes; i++) {
    mix_presentation();
  } 
}
```

<b>Semantics</b>

<dfn noexport>num_mixes</dfn> specifies the number of mix presentations present in the IA bitstream.

<dfn noexport>mix_presentation()</dfn> is the function call that provides the configuration for a mix presentation.

##### Mix Presentation Syntax and Semantics ##### {#syntax-mix-presentation}

<b>Syntax</b>
```
class mix_presentation() {
  unsigned int (leb128()) mix_presentation_id;
  string mix_presentation_friendly_label;

  unsigned int (leb128()) num_timestamp_intervals;
  for (i = 0; i < num_timestamp_intervals; i++) {
    unsigned int (leb128()) start_timestamp;
    unsigned int (leb128()) duration;
  }

  unsigned int (leb128()) num_audio_elements;
  for (i = 0; i < num_audio_elements; i++) {
    string audio_element_friendly_label;
    unsigned int (leb128()) audio_element_id_ref; 
    rendering_config();
    element_mix_config();
  }

  master_mix_config();
  mix_loudness_info();
  drc_config();
  // etc...
}
```

<b>Semantics</b>

<dfn noexport>mix_presentation_id</dfn> is a unique ID that can be used by other function calls in the IA bitstream to reference this mix presentation.

<dfn noexport>mix_presentation_friendly_label</dfn> may be used to provide a human-friendly label to describe this mix presentation.

<dfn value noexport for="mix_presentation">num_timestamp_intervals</dfn> specifies the number of time intervals where the mix presentation given here is valid and applicable in the overall timeline.

<dfn value noexport for="mix_presentation">start_timestamp</dfn> specifies, for each timestamp interval, the starting time when the mix presentation given here is valid and applicable.

<dfn value noexport for = "mix_presentation">duration</dfn> specifies, for each timestamp interval, the duration after the corresponding start_timestamp when the mix presentation given here is valid and applicable.

<dfn value noexport for="audio_mix_presentation">num_audio_elements</dfn> specifies the number of audio elements that are used in this mix presentation to generate the final output audio signal for playback.

<dfn noexport>audio_element_id_ref</dfn> specifies the unique ID of the audio element that is used in this mix presentation.

<dfn noexport>rendering_config()</dfn> is the function call that provides the metadata required for rendering the referenced audio element.

<dfn noexport>element_mix_config()</dfn> is the function call that provides the metadata required for applying any processing to the referenced audio element before mixing with other audio elements. 

<dfn noexport>master_mix_config()</dfn> is the function call that provides the metadata required for mixing all the referenced audio elements into a single audio signal.

<dfn noexport>mix_loudness_info()</dfn> is the function call that provides the metadata required for adjusting the loudness of the final output audio signal for playback.

<dfn noexport>drc_config()</dfn> is the function call that provides the metadata required for applying dynamic range control (DRC) to generate the final output audio signal for playback.

### Update Metadata OBU Syntax and Semantics ### {#obu-update-metadata}

This section defines <dfn noexport>update_metadata_obu</dfn> to carry [=update metadata=].

<b>Syntax</b>

```
class update_metadata_obu() {
  unsigned int (leb128()) metadata_type;
  if (metadata_type == 0) {
    unsigned int (leb128()) num_functions;
    for (i = 0; i < num_functions; i++) {
      unsigned int (leb128()) function_id_ref;
      function_call(function_id_ref);
    }
  }
}
```

<b>Semantics</b>

<dfn noexport>metadata_type</dfn> shall indicate the type of update metadata. It shall be set to 0 for this version of specification.


```
class function_call(function_id_ref) {
  if (function_id_ref == demixing_info) {
    demixing_info();
  }
  else if (function_id_ref == recon_gain_info) {
    recon_gain_info();
  }
}
```

ISSUE: We may need to update this function_call to be generalized to support any function to be added and move to a separated section. 


#### Demixing Info Syntax and Semantics #### {#demixinginfo}

<dfn noexport>demixing_info</dfn> specifies demixing parameter mode to be used to reconstruct demixed channels and its associated audio element and frames.

<b>Syntax</b>

```
class demixing_info() {
  unsigned int (leb128()) audio_element_id_ref;
  unsigned int (leb128()) num_entries;
  for (i = 0; i < num_entries; i++) {
    unsigned int (leb128()) frame_count;
    unsigned int (3) dmixp_mode;
    unsigned int (5) reserved;
  }
}
```

<b>Semantics</b>

<dfn value noexport for = "demixing_info()">audio_element_id_ref</dfn> shall indicate the [=audio_element_id=] of the audio element to be associated with this [=demixing_info=].

<dfn noexport>num_entries</dfn> is an integer that gives the number of entries in the following table.

<dfn noexport>frame_count</dfn> is an integer that gives the number of consecutive frames of the audio element which is specified by the [=audio_element_id=] with the same [=dmixp_mode=]. Where, the count starts from 1 at the first frame(s) of the audio element coming right after update_metadata_obu.

<dfn noexport>dmixp_mode</dfn> shall indicate a mode of pre-defined combinations of five demix parameters.
- 0: mode1, (alpha, beta, gamma, delta, w_idx_offset) = (1, 1, 0.707, 0.707, -1)
- 1: mode2, (alpha, beta, gamma, delta, w_idx_offset) = (0.707, 0.707, 0.707, 0.707, -1)
- 2: mode3, (alpha, beta, gamma, delta, w_idx_offset) = (1, 0.866, 0.866, 0.866, -1)
- 3: reserved
- 4: mode1, (alpha, beta, gamma, delta, w_idx_offset) = (1, 1, 0.707, 0.707, 1)
- 5: mode2, (alpha, beta, gamma, delta, w_idx_offset) = (0.707, 0.707, 0.707, 0.707, 1)
- 6: mode3, (alpha, beta, gamma, delta, w_idx_offset) = (1, 0.866, 0.866, 0.866, 1)
- 7: reserved

<dfn noexport>alpha</dfn> and <dfn noexport>beta</dfn> are gain values used for S7to5 down-mixer, <dfn noexport>gamma</dfn> for T4to2 down-mixer, <dfn noexport>delta</dfn> for S5to3 down-mixer and <dfn noexport>w_idx_offset</dfn> is the offset to generate a gain value <dfn noexport>w</dfn> used for T2toTF2 down-mixer.

<center><img src="images/Down-mix Mechanism.png" style="width:100%; height:auto;"></center>
<center><figcaption></b>IA Downmix Mechanism</figcaption></center>

#### Recon Gain Info Syntax and Semantics #### {#recongaininfo}

<dfn noexport>recon_gain_info</dfn> contains recon gain values for demixed channels.

<b>Syntax</b>

```
class recon_gain_info() {
  unsigned int (leb128()) audio_element_id_ref;
  for (i=0; i< channel_audio_layer; i++) {
    if (recon_gain_is_present_flag(i) == 1) {
      unsigned int(leb128()) recon_gain_flags(i);
      for (j=0; j< n(i); j++) {
        if (recon_gain_flag(i)(j) == 1)
          unsigned int (8) recon_gain;
      }
    }
  }
}
```

<b>Semantics</b>

<dfn value noexport for = "recon_gain_info()">audio_element_id_ref</dfn> shall indicate the [=audio_element_id=] of the audio element to be associated with this [=recon_gain_info=].

<dfn noexport>recon_gain_flags</dfn> shall indicates the channels which recon_gain is applied to.

<left><img src="images/Recon_Gain_Flags.png" style="width:100%; height:auto;"></left>

<dfn noexport>recon_gain</dfn> shall indicates the gain value to be applied to the channel, which is indicated by [=recon_gain_flags=], after decoding of the following associated frames.
  

## Codec Specific ## {#codec-specific}

This section defines codec specific information for Codec_Specific_Info and Substream.

- <dfn noexport>Codec_Specific_Info</dfn> is composed of [=Codec_ID=] and [=Decoder_Config=]. Codec_ID shall indicate the codec which has been used to generate Substreams within IA bitstream and Decder_Config shall indicate the decoding parameters which are applied to all of Substreams within IA bitstream.

For legacy codecs, Decder_Config shall be exactly the same information as the conventional file parser feeds to the codec decoders for decoding of mono or stereo bitstream. For future codecs, Decder_Config shall include all of decoding parameters which are required to decode Substreams.

- Substream is a raw coded stream for mono or stereo channels. Substream format shall be exactly the same as the sample format (before packing OBU) for mono or stereo audio file which consists of only one single coded stream by the Codec_ID.


### IAC-OPUS Specific ### {#iac-opus-specific}

Codec_Specific_Info for IAC-OPUS shall conform to [=ID Header=] with [=ChannelMappingFamily=] = 0 of [[!RFC7845]] with following constraints:
- [=Channel Count=] should be set to 2.
- [=Output Gain=] shall not be used. In other words, it shall be set to 0dB.

Substream format shall be [=opus packet=] of [[!RFC6716]] which contains only one single frame of mono or stereo channels.


### IAC-AAC-LC Specific ### {#iac-aac-lc-specific}

[=Codec_ID=] shall be 'mp4a'.

[=Decoder_Config=] for IAC-AAC-LC shall be [=DecoderConfigDescriptor()=] of [[!MP4-Systems]], which is a subset of [=ESDBox=] for [[!MP4-Audio]], with following constraints:
- [=objectTypeIndication=] = 0x40
- [=streamType=] = 0x05 (Audio Stream)
- [=upstream=] = 0
- [=decSpecificInfo()=]: The syntax and values shall conform to [=AudioSpecificConfig()=] of [[!MP4-Audio]] with following constraints:
	- [=audioObjectType=] = 2
	- [=channelConfiguration=] should be set to 2.
	- [=GASpecificConfig()=]: The syntax and values shall conform to [=GASpecificConfig()=] of [[!MP4-Audio]] with following constraints:
		- [=frameLengthFlag=] = 0 (1024 lines IMDCT)
		- [=dependsOnCoreCoder=] = 0
		- [=extensionFlag=] = 0

Substream format shall be [=raw_data_block()=] of [[!AAC]] which contains only one single frame of mono or stereo channels.

ISSUE: Add PCM and Flac

ISSUE: 19 Aug 2022: Modifications made up to here. To be continued...

# Basic Encapsulation Scheme # {#basic-encapsulation}

This section describes the basic data structures used to signal encapsulation of IA bitstreams in [[!ISOBMFF]] containers.

## General Requirements & Brands ## {#brands}

A file conformant to this specification satisfies the following:
- It shall conform to the normative requirements of [[!ISOBMFF]]
- It shall have the <dfn value export for="ISOBMFF Brand">aiac</dfn> brand among the compatible brands array of the FileTypeBox
- It shall contain at least one track using an [=IASampleEntry=]
- It SHOULD indicate a structural ISOBMFF brand among the compatible brands array of the FileTypeBox, such as 'iso6'
- It MAY indicate other brands not specified in this specification provided that the associated requirements do not conflict with those given in this specification

Parsers shall support the structures required by the <code>'iso6'</code> brand and MAY support structures required by further ISOBMFF structural brands.

During encapsulation process, OBUs of IA bistream are encapsulated into [[!ISOBMFF]] as follows:
- CodecSpecificBox, which is defined from Codec_Specific_Info in IA bitstream, shall be stored in sample entry.
- IA_Static_Meta (with OBU syntax) shall be stored as a new sample group having [=grouping_type=], [=iasm=].
- Some fields of IA_Static_Meta, related to MIME codecs parameter, shall be copied in sample entry.
- Temporal_Delimiter_OBUs shall be discarded from Temporal Units.
- Demixing_Info_OBUs (with OBU syntax) may be stored as a new sample group having [=grouping_type=], [=admi=].
- Remainded OBUs of Temporal Units shall be stored as sample data without gap among OBUs.

## IA Sample Entry ## {#iasampleentry-section}

NOTE: As discussed, we have an agreement to specify that only codec specific info is stored (no loop, no override). We might reconsider if new use cases are brought forward.
NOTE: We agree that all Opus (or AAC-LC) substreams must be encoded in a way that produces the same codec specific info.
NOTE: We agree that ChannelMappingFamily is always 0, and that OutputChannelCount is always 2. OutputChannelCount can be ignored because the real value can be determined from the IAC static metadata and from the Opus Packet headers.

### Definition ### {#iasampleentry-definition}

<pre class="def">
	Sample Entry Type: <dfn value export for="IASampleEntry">aiac</dfn>
	Container:         Sample Description Box ('stsd')
	Mandatory:         Yes
	Quantity:          One or more.
</pre>

### Description ### {#iasampleentry-description}

The <dfn noexport>IASampleEntry</dfn> sample entry identifies that the track contains [=IA Samples=], and uses one single [=codec specific box=].

### Syntax ### {#iasampleentry-syntax}

```
class IASampleEntry extends AudioSampleEntry('aiac') {
  unsigned int (8) version;
  unsigned int (2) ambisonics_mode;
  unsigned int (3) channel_audio_layer;
  unsigned int (3) reserved;
  unsigned int (8) ambisonics_channel_count;
  for (i=0; i<channel_audio_layer; i++)
    unsigned int (4) loudspeaker_layout;
  byte_alignment();
  CodecSpecificBox config;
}
```

No optional boxes of AudioSampleEntry shall present.

### Semantics ### {#iasampleentry-semantics}

Both [=channelcount=] and [=samplerate=] fields of AudioSampleEntry shall be ignored.

version and channel_audio_layer shall be the same as the ones in IA_Static_Meta_OBU.

ambisonics_mode and channel_audio_layer shall be the same as the ones in IA_Static_Meta_OBU.

<dfn noexport>ambisonics_channel_count</dfn> shall be the same as [=output_channel_count=] in IA_Static_Meta_OBU. When ambisonics_mode set to 0, this field shall be ignored.

loudspeaker_layout shall be the same as the one in IA_Static_Meta_OBU.

## Codec Specific Box ## {#codecspecificbox-section}

This section describes a <dfn noexport>codec specific box</dfn> for the decoding parameters, which is defined by codec_id of Codec_Specific_Info_OBU, to decode one single Substream of IA bitstream. <code>aiac</code> shall contain only one single codec specific box regardless of the number of Substreams in IA_Coded_Data. So, the codec specific box is applied to allo of Substreams in sample data.

### OPUS Specific Box ### {#codecspecificbox-opus}

This shal be [=OpusSpecificBox=] ('dOps') for 'opus' audiosampleentry which is specified in [[!OPUS-IN-ISOBMFF]].

#### Definition #### {#codecspecificbox-opus-definition}

<pre class="def">
	Box Type:  <dfn export>dOps</dfn>
	Container: IA Sample Entry ('aiac')
	Mandatory: Yes
	Quantity:  One
</pre>

#### Description #### {#codecspecificbox-opus-description}

This box is for one single Substream.

#### Syntax #### {#codecspecificbox-opus-syntax}

It shall be the same as 'dOps' box for 'opus' with that [=ChannelMappingFamily=] shall be set to 0.

#### Semantics #### {#codecspecificbox-opus-semantics}

It shall be the same as the semantics except followings:
- [=OutputChannelCount=] should be set to 2. [=OutputChannelCount=] can be ignored because the real value can be determined from the IA_Static_Meta_OBU and from the [=opus packet=] header.
- In case of channel_audio_layer > 0, [=OutputGain=] shall be set to 0.
- [=ChannelMappingFamily=] shall be set to 0.

### MP4A Specific Box ### {#codecspecificbox-mp4a}
This is [=ESDBox=] ('esds') for 'mp4a' which is specified in [[!MP4]].

#### Definition #### {#codecspecificbox-mp4a-definition}
<pre class="def">
	Box Type:  <dfn export>esds</dfn>
	Container: IA Sample Entry ('aiac')
	Mandatory: Yes
	Quantity:  One of more
</pre>

#### Description #### {#codecspecificbox-mp4a-description}

This box is for one single Substream.

#### Syntax #### {#codecspecificbox-mp4a-syntax}

It shall be the same as 'esds' box for [=Low Complexity Profile=] of [[!AAC]] (AAC-LC).

#### Semantics #### {#codecspecificbox-mp4a-semantics}

It shall be the same as the semantics except followings:
- [=channelConfiguration=] field should be set to 2. The real value can be implied from the IA_Static_Meta_OBU.

## IA Sample Format ## {#iasampleformat}

For tracks using the [=IASampleEntry=], an <dfn noexport>IA Sample</dfn> has the following constraints:
- The sample data shall be a sequence of OBUs forming a Temporal Unit.
- Temporal_Delimiter_OBU shall not be present. It shall be discarded when Temporal Unit is stored as sample data.
- OBUs for Timed Metadata (if present) come first and followed by OBU(s) for IA_Coded_Data.
- Each OBU shall follow OBU syntax as specified in this specificaiton.

## IA Sample Group ## {#iasamplegroup}

NOTE: We agree to create a generic sample group where the payload is exactly the OBU content (with header and length). This is to be used for demixing OBU and possibly others in the future. We still need to discuss if sample groups shall or should or can be used, possibly based on the OBU type.

### Demixing Info Sample Group ## {#iasamplegroup-demixing}

During encapsulation process, Demixing_Info_OBUs shall or should or can be discarded from IA bistream. A new sample group for Demixing_Info_OBUs is defined by using 'sgpd'' and 'sbgp' boxes with following requirements:
- [=grouping_type=] shall be set to <dfn noexport>admi</dfn>.
- Each [=SampleGroupDescriptionEntry=] shall be Demixing_Info_OBU with OBU syntax.

### IA Static Meta Sample Group ## {#iasamplegroup-iastaticmeta}

During encapsulation process, IA_Static_Meta_OBUs are discarded from IA bistream. A new sample group for IA_Static_Meta_OBUs is defined by using 'sgpd' and 'sbgp' boxes with following requirements:
- [=grouping_type=] shall be set to <dfn noexport>iasm</dfn>.
- [=SampleGroupDescriptionEntry=] shall be IA_Static_Meta_OBU with OBU syntax.


## Common Encryption ## {#CommonEncryption}
TBA

## Codecs Parameter String ## {#codecsparameter}
DASH and other applications require defined values for the 'Codecs' parameter specified in [[!RFC6381]] for ISO Media tracks. The codecs parameter string for the AOM IA codec shall be:
- For IAC-OPUS

```
	aiac.IAC-specific-needs.Opus
```

- For IAC-AAC-LC

```
	aiac.IAC-specific-needs.mp4a.40.2
```

<b>IAC-specific-needs</b> shall be <b>V.AA.L(CC)*</b> as follows:
- <dfn noexport>V</dfn> shall be four digits and shall represent version of IA_Static_Meta.
	- The first two digits shall represent the major version within the range 0 to 15.
	- The second two digits shall represent the minor version within the range 0 to 15.
- <dfn noexport>AA</dfn> shall be two or three digits.
	- The first <b>A</b> shall be one digit and shall represent the mode of Ambisonics.
	- The second <b>A</b> shall be one or two digits and shall represent the order of Ambisonics.
- <dfn noexport>L(CC)*</dfn> means that <b>CC</b> commes L times.
	- <dfn noexport>L</dfn> shall be one digit and shall represent channel_audio_layer of the channel audio.
	- <dfn noexport>CC</dfn> shall be two digits and shall represent the number of surround and top channels.
		- The first <b>C</b> shall be one digit and shall represent the number of surround channels.
		- The second <b>C</b> shall be one digit and shall represent the number of top channels.
	- The ith [=CC=] shall represent for the ith layer of the channel audio, where i = 1, 2, ..., L.

For example, for this version of the specification
- The codecs parameter string of IAC-AAC-LC for the second order of Ambiosnics (SOA) with channel mapping:

```
	aiac.0000.12.mp4a.40.2
```

- The codecs parameter string of IAC-OPUS for channel audio with 3 layers (2ch/3.1.2ch/7.1.4ch):

```
	aiac.0000.00.203274.Opus
```

# IAC Decapsulation Process # {#iacdecapsulation}

This section provides a guideline for IAC parser to reconstruct IA bitstreams (i.e., IA sequence) from IAC file.

When IAC parser feeds the reconstructed IA bitstreams to IAC-OBU parser, IA_Stream_Indicator_OBU is placed at the front of the first IA bistream to let IAC-OBU parser know OBUs for IA bistreams are coming.

Figure 9 shows the mirroring process of the encapsulation scheme of IA bitstream specified in [[#basic-encapsulation]].

<center><img src="images/IAC Decapsulation Guideline.png"></center>
<center><b>Figure 9. </b>IAC Decapsulation Guideline</center>

During decapsulation process, IAC file is decapsulated into IA bitstreams which conform to [[#iabitstream-definition]] as follows:
- Step1: Reconstruction of Non-timed Metadata (Codec_Specific_OBU and followed by IA_Static_Meta_OBU) for the ith IA bitstream
	- [Step1-1] Codec_Specific_Info_OBU: generate Codec_Specific_Info from CodecSpecificBox of <code>aiac</code> sample entry, and packetize it by OBU with obu_type = OBU_Codec_Sepcific_info.
	- [Step1-2] IA_Static_Meta_OBU: take the ith SampleGroupDescriptionEntry as it is in SampleGroup with grouping_type, [=iasm=].
	- [Step1-3] Place Codec_Specific_Info_OBU at the front of IA_Static_Meta_OBU without gap to reconstruct Non-timed Metadata.
	- [Step1-4] Figure out the offset (i1) and number (im) of Samples, which the ith SampleGroupDescriptionEntry is applied to, from the SampleGroup.
- Step2: Reconstructing of the jth Temporal Unit of the ith IA Bitstream (j = i1, i2, …, im)
	- [Step2-1] Prepare Temporal_Delimiter_OBU with obu_type = OBU_Temporal_Delimiter.
	- [Step2-2] If there is the SampleGroup with grouping_type, [=admi=], then place the Demixing_Info_OBU at the front of jth Sample without gap. Otherwise, take jth Sample as it is.
		- Demixing_Info_OBU: take the SampleGroupDescriptionEntry as it is, from SampleGrouop with grouping_type, [=admi=], mapped to jth Sample.
	- [Step2-3] Place Temporal_Delimiter_OBU at the front of the result of Step2-2 without gap to reconstruct the jth Temporal Unit.
- Step3: Place Non-Timed Metadata and followed by Temporal Units in order (j = i1, i2, …, im) without gap to reconstruct the ith IA bitstream.

Codec_Specific_Info_OBU for IAC-OPUS is generated as follows:
- The syntax and values conform to [=ID Header=] of [[!RFC7845]] with following constraints.
	- [=OutputChannelCount=], [=PreSkip=], [=InputSampleRate=], [=OutputGain=] and [=ChannelMappingFamily=] are copied from [=dOps=] box.

Codec_Specific_Info_OBU for IAC-AAC-LC is generated as follows:
- [=Codec_ID=]: 'mp4a'
- [=Decoder_Config=] is copied from [=DecoderConfigDescriptor()=] of [=esds=] box.


# IA Encoding Process # {#iaencoding}

This section provides a guideline for IA encoding for a given input audio format.

## Input Audio Format ## {#iaencoding-inputaudioformat}

Recommended input audo format for IA encoding is as follows:
- Ambiosnics format: It conforms to [=ChannelMappingFamily=] = 2 or 3 of [[RFC8486]].
- Channel Audio format: It conforms to[=loudspeaker_layout=] specified in channel_audio_layer_config().
- Ambisonics + Channel Audio format: In this case, Channel Audio is regarded as Non-diegetic.
- Input Smapling Rate: 48000hz
- Bitdepth: 16 bits or 24 bits
	- 16 bits are recommended for IAC-OPUS.
- Input file format: .wav file (Linear PCM, simply called as PCM)

## IA Encoder ## {#iaencoding-iaencoder}

For a given input audio and user inputs, IA encoder outputs [=IA bitstream=] which conforms to [[#iabitstream-definition]].

Input audio is one of followings:
- Ambisonics format
- Channel Audio format
- Ambisonics + Channel Audio format

User inputs are:
- Ambisonics mode to indicate if [=ChannelMappingFamily=] = 2 or 3 of [[RFC8486]].
- List of channel layouts to be supported for scalable channel audio: it conforms to [=loudspeaker_layout=].

IA encoder is composed of Pre-processor, Codec encoder and OBU packetizer as depicted in Figure 10.
- Pre-processor outputs one or more ChannelGroups, IA_Static_Meta and Timed Metadata if needed based on the input audio and user inputs.
	- It outputs one single ChannelGroup for Ambisonics.
	- It outputs one or more ChannelGroups for Channel audio.
- Codec encoder generates one or more Substreams from each ChannelGroup and outputs the Substream(s) with one single Decoder_Config.
	- Mono or stereo coding is only allowed.
		- Ambisonics format: each channel is coded as mono mode
		- Channel Audio format: each pair of coupled channels in the same ChannelGroup is coded as stereo mode to generate one single Substream and each of non-coupled channels in the same ChannelGroup is coded as mono mode to generate one single Substream.
			- <dfn noexport>Coupled channels</dfn>: L/R, Ls/Rs, Lss/Rss, Lrs/Rrs, Ltf/Rtf, Ltb/Rtb
			- <dnf noexport>Non-coupled channels</dfn>: C, LFE, L
- OBU packetizer generates Non-timed Metadata and Temporal Unit for each frame, and outputs IA bitstream.
	- Non-timed Metadata generator generates OBUs for [=Codec_Specific_Info=] and IA_Static_Meta.
	- Temporal Unit generator generates Temporal Unit for each frame from Timed Metadata if present and Substreams.

<center><img src="images/IA Encoder Configuration.png"></center>
<center><b>Figure 10. </b>IA Encoder Configuration</center>

The order of Substreams in each ChannelGroup is as follows:
- In ChannelGroup for Ambisonics: The order conforms to [[RFC8486]].
- In ChannelGroup for Channel audio: The order conforms to following rules:
	- Coupled Substreams comes first and followed by non-coupled Substreams.
	- Coupled Substreams for surround channels comes first and followed by one(s) for top channels.
	- Coupled Substreams for front channels comes first and followed by one(s) for side, rear and back channels.
	- Coupled Substreams for side channels comes first and followed by one(s) for rear channels.
	- Center channel comes first and followed by LFE and followed by the other one.

Where, <dfn noexport>non-coupled Substream</dfn> is a coded Substream from one of non-coupled channels.

### IA Encoder for Ambisonics format ### {#iaencoding-iaencoder-ambisonics}

For Ambisonics format:
- Pre-processor outputs one ChannelGroup and IA_Static_Meta and it is only composed of Meta Generator.
	- Meta generator generates IA_Static_Meta based on Ambisonics mode and the number of channels for Ambisonics.
		- [=Ambisonics_Mode=] is set to 1 for [=ChannelMappingFamily=] = 2 of [[RFC8486]] or 2 for [=ChannelMappingFamily=] = 3 of [[RFC8486]].
		- Channel_Audio_Layer is set to 0.
		- Ambisonics Layer Config() is set to as follows:
			- [=output_channel_count=], [=substream_count=] and [=coupled_substream_count=] are set to the number of channels for Ambisonics.
			- [=channel_mapping=] for [=Ambisonics_Mode=] = 1 or [=demixing_matrix=] for [=Ambisonics_Mode=] = 2 is assigned to according to the order of Substreams in ChannelGroup.
- Codec Enc. outputs Substreams as many as the number of channels for Ambisoncis by coding each channel in a mono mode.
- Temporal Unit is composed of Temporal_Delimiter_OBU and followded by OBUs for Substreams.
	- The order of Substreams in ChanngelGroup is aligned with [=channel_mapping=] for [=Ambisonics_Mode=] = 1 or [=demixing_matrix=] for [=Ambisonics_Mode=] = 2.

### IA Encoder for Channel Audio format ### {#iaencoding-iaencoder-channelaudio}

For Channel Audio format:
- Pre-processor outputs one or more ChannelGroups, IA_Static_Meta and Timed Metadata. It is composed of Down-mix parameter generator, Down-mixer, Loudness, ChannelGroup generator, Attenation and Meta generator.
	- For non-scalable channel audio (i.e. Channel_Audio_Layer = 1):
		- Timed Metadata may not need to be generated. But Demixing_Info of Timed Metadata may be generated by implementers who assume it to be used for dynamic downmixing in a decoder side.
		- Down-mix parameter generator, Down-mixer, ChannelGroup generator and Attenuation modules are not needed.
	- Down-mix parameter generator generates 5 down-mix parameters (α(k), β(k), γ(k), δ(k) and w(k)) by analyzing input Channel Audio
	- Down-mixer generates down-mixed audios according to the list of channel layouts and the down-mix parameters.
	- Loudness module outputs the loudness level ([=LKFS=]) of each down-mixed audio based on [[ITU1770-4]].
	- ChannelGroup generator transforms the input Channel Audio to ChannelGroups for audio scalability by using transformation matrix.
		- Transformation matrix is generated based on down-mix parameters and the list of channel layouts.
	- Attenuation module applies a gain to prevent clipping of mixed channels.
	- Meta generator generates IA_Static_Meta, and Timed Metadata for each frame.
		- IA_Static_Meta is set to as follows:
			- [=Ambisonics_Mode=] is set to 0.
			- Channel_Audio_Layer is set to the number of channel layouts.
			- Channel_Audio Layer Config() is set to as follows:
				- [=loudspeaker_layout=] is set to the ith list of channel layouts for the ith ChannelGroup.
				- [=output_gain_is_present_flag=] is set to 1 for the ith ChannelGroup if attenuation is applied to the mixed channels of the ith ChannelGroup. Otherwise it is set to 0 for the ith ChannelGroup.
				- [=recon_gain_is_present_flag=] is set to 1 for the ith ChannelGroup if the preceding ChannelGroups has one or more mixed channels from the down-mixed audio for the ith channel layout. Otherwise, it is set to 0 for the ith ChannelGroup.
				- [=substream_count=] is set to the nubmer of Substreams composing of the ith ChannelGroup.
				- [=coupled_substream_count=] is set to the nubmer of coupled Substreams among the Substreams composing of the ith ChannelGroup.
				- [=loudness=] is set to the loudness ([=LKFS=]) of the down-mixed audio for the ith channel layout for the ith ChannelGroup.
				- Each bit of [=output_gain_flags=] is set to 1 for the ith ChannelGroup if attenuation is applied to the relevant channel of the ith ChannelGroup. Otherwies it is set to 0 for the ith ChannelGroup.
				- [=output_gain=] is set to the inverse number of the gain which is applied to the channels which are indicated by output_gain_flags.
		- Timed Metadata is composed of [=Demixing_Info=] and [=Recon_Gain_Info=].
			- [=dmixp_mode=] of Demixing_Info for the kth frame is set to indicate (α(k), β(k), γ(k), δ(k)) and w_idx_offset(k). Where w_idx_offset(k) = 1 or -1.
			- [=recon_gain_flags=] of Recon_Gain_Info are set to indicate the de-mixed channels, which need to apply [=recon_gain=] among the output channels after demixing for ith channel layout.
			- [=recon_gain=] is set to the gain value to be applied to the channel which is indicated by recon_gain_flags for the ith ChannelGroup.
- Temporal Unit is composed of Temporal_Delimiter_OBU, followed by OBUs for Timed Metadata and followed by OBUs for Substreams.
	- ChannelGroups in Temporal Unit are placed in order. In other words, ChannelGroup for the first channel layout comes first, followed by ChannelGroup for the second channel layout, followed by ChannelGroup for the third channel layout and so on.

Figure 11-1 shows IA encoding flowchart for Channel Audio Format.
- For a given Channel Audio and a given list of channel layouts for scalability, PCMs for Channel Audio are passed to CG Generation moddule.
- CG Generation module generates the transformed audio according to CG generation rule based on the list of CLs and the down-mix parameters.
	- The transformed audio is structured as ChannelGroups.
- Non-mixed channels of the transformed audio (i.e., the original channels of the input channel audio) are directly input to Codec encoder, but the mixed channels may be input first to Attenuation module and then to Codec encoder.
- The Attenuation module reduces all sample values of the mixed channels in the same CG at a uniform rate (Output_Gain).
	- A range of 0dB to -6dB is recommended for the attenuation. (i.e. a range of 0dB to 6dB for Output_Gain)
- Codec Enc. generates the coded Substreams from PCMs and passes Substreams and one single Decoder_Config to OBU Packetizer.
- OBU packetizer generates Non-timed Metadata which consists of OBU for Codec_Specific_Info and OBU for IA_Static_Meta.
	- Codec_Specific_Info_OBU is generated based on [=Decoder_Config=].
	- IA_Static_Meta_OBU is generated based on Ambix_Layer_Config and Channel_Audio_Layer_Config.
- OBU packetizer generates Temporal Unit for each frame.
	- OBU Packetizer generates Timed Metadata, which consists of OBU for Demixing_Info and OBU for Recon_Gain_Info, for each frame.
	- OBU Packetizer generates OBUs for Substreams for each frame.
- OBU Packetizer outputs IA Bitstream which is composed of OBUs for Non-timed Metadata and followed by OBUs for Temporal Units.

<center><img src="images/IA Encoding Flowchart for Channel Audio Format.png"></center>
<center><b>Figure 11-1. </b>IA Encoding Flowchart for Channel Audio Format</center>

Following sections, [[#iaencoding-iaencoder-channelaudio-downmixparameter]], [[#iaencoding-iaencoder-channelaudio-downmixmechanism]], [[#iaencoding-iaencoder-channelaudio-channellayoutgenerationrule]], [[#iaencoding-iaencoder-channelaudio-recongaingeneration]] and [[#iaencoding-iaencoder-channelaudio-channelgroupgenerationrule]] are not needed for non-scalable channel audio (i.e., when Channel_Audio_Layer of IA_Static_Meta is set to 1).

#### Down-mix parameter and Loudness #### {#iaencoding-iaencoder-channelaudio-downmixparameter}

This section describes how to generate down-mix parameters and loudness level for a given channel audio and a given list of channel layouts for scalability.

Figure 11-2 shows a block diagram for down-mix parameter and loudness module including down-mixer.

<center><img src="images/Down-mix Parameter and Loudness.png"></center>
<center><b>Figure 11-2. </b>IA Down-mix Parameter and Loudness</center>

For a given Channel Audio (e.g. 7.1.4ch) and a given list of channel layouts based on the Channel Audio,
- Down-mix parameter generator generates 5 down-mix parameters (α(k), β(k), γ(k), δ(k) and w(k)) by analyzing input Channel Audio, by refering [[AI-CAD-Mixing]]. Where, k is a frame index.
	- It is composed of Audio Scene Classification module and Height Energy Quantification module as depicted in Figure 11-2.
	- Audio Scene Classification module generates 4 parameters (α(k), β(k), γ(k), δ(k)) by classifying audio scenes of input channel audio in three modes.
		- Default scene: Neither Dialog nor Effect
		- Dialog scene: Center-channel oriented and clear dialog/voice sounds
		- Effect scene: Directional and spatially moving sounds.
	- Height Energy Quantification module generates a surround to height mixing parameter (w(k)) which is decided according to the relative energy difference between the top and surround channels of input channel audio.
		- If the energy of top channels is bigger than that of surround ones, then w_idx_offset(k) is set to 1. Otherwise, it is set to -1. And, w(k) is calculated based on w_idx_offset(k) and conforms to [[#iadecoding]].
- Down-mixer generates down-mixed audios from input Channel Audio according to the list of channel layouts and the down-mix parameters, and outputs down-mixed audio for each channel layout to Loudness module.
	- It is not depicted in Figure 11-2 but Down-mixer further generates [=Dmixp_Mode=] and [=Recon_Gains=] for each frame to be passed to OBU packetizer.
- Loudness module measures the loudness level ([=LKFS=]) of each down-mixed audio based on [[ITU1770-4]], and passes them to OBU packetizer.

#### Down-mix Mechanism #### {#iaencoding-iaencoder-channelaudio-downmixmechanism}

This section describes the down-mixing mechanism to generate <dfn noexport>down-mixed audio</dfn> for IA.

For a given Channel Audio which conforms to [[=loudspeaker_layout]], teh surround and top channels (if any) are separately down-mixed and especially step by step until to get a target channels.

Therefore, a down-mixer based on the down-mix mechanisam for IA is a combination of following surround down-mixer(s) and top down-mixer(s) as depicted in Figure 11-3
- Surround Down-mixers: S7to5 enc., S5to3 enc., S3to2 enc., S2to1 enc.

```
	S7to5 enc.: Ls5 = α(k) x Lss7 + β(k) x Lrs7 and Rs5 = α(k) x Rss7 + β(k) x Rrs7.
	S5to3 enc.: L3 = L5 + δ(k) x Ls5 and R3 = R5 + δ(k) x Rs5
	S3to2 enc.: L2 = L3 + 0.707 x C and R2 = R3 + 0.707 x C
	S2to1 enc.: Mono = 0.5 x (L2 + R2)
```

- Top Down-mixers: T4to2 enc., T2toTF2 enc.

```
	T4to2 enc.: Ltf2 = Ltf4 + γ(k) x Ltb4  and Rtf2 = Rtf4 + γ(k) x Rtb4.
	T2toTF2 enc.: Ltf3 = Ltf2 + w(k) x δ(k) x Ls5 and Rtf3 = Rtf2 + w(k) x δ(k) x Rs5.
```

Figure 11-3 shows the down-mix mechanism.

<center><img src="images/Down-mix Mechanism.png"></center>
<center><b>Figure 11-3. </b>IA Down-mix Mechanism</center>

```
For example, to get down-mixed 3.1.2ch from 7.1.4ch:
- S3 of 3.1.2ch is generated by using S7to5 and S5to3 encs.
- TF2 of 3.1.2ch is generated by using T4to2 and T2toTF2 encs.
```

#### Channel Layout Generation Rule #### {#iaencoding-iaencoder-channelaudio-channellayoutgenerationrule}

This section describes the generation rule for channel layouts.

For a given channel layout (CL #n) of input Channel Audio, any list of CLs ({CL #i: i = 1, 2, ..., n}) for a scalable channel audio comforms with following rules:
- Si ≤ Si+1 and Wi ≤ Wi+1 and Ti ≤ Ti+1 except Si = Si+1 and Wi = Wi+1 and Ti = Ti+1 for i = n-1, n-2, …, 1. Where ith Channel Layout CL #i = Si.Wi.Ti.
- CL #i is one of [=loudspeaker_layouts=] supported in this specification.

Down-mix paths, which conform to the above rule, are only allowed as depicted in Figure 11-4.

<center><img src="images/Down-mix Path.png"></center>
<center><b>Figure 11-4. </b>IA Down-mix Path</center>

#### Recon Gain Generation #### {#iaencoding-iaencoder-channelaudio-recongaingeneration}

This section describes how to generate [=Recon_Gain=].

Recon_Gain needs to be applied to de-mixed channels. For this, IA encoder needs to deliver it to IA decoders.

Let's define followings:
- Level Ok is the signal power for the frame #k of a channel of the down-mixed audio for CL #i.
- Level Mk is the signal power for the frame #k of the relevant mixed channel of the down-mixed audio for CL #i-1.
- Level Dk is the signal power for the frame #k of the de-mixed channel for CL #i (after demixing).

If 10*log10(level Ok / maxL^2) is less than the first threshold value (e.g. -80dB), Recon_Gain (k, i)  = 0. Where, maxL = 32767 for 16bits.

If 10*log10(level Ok / level Mk ) is less than the second threshold value (e.g. -6dB), Recon_Gain (k, i) is set to the value which makes level Ok = Recon_Gain (k, i)^2 x level Dk. Otherwise, Recon_Gain (k, i) = 1. Actual value to be delivered is floor(255*Recon_Gain).

```
For example, if we assume CL #i = 7.1.4ch and CL #i-1 = 5.1.2ch, then de-mixed channels are D_Lrs7, D_Rrs7, D_Ltb4 and D_Rtb4.
- D_Lrs7 and D_Rrs7 are de-mixed from Ls5 and Rs5 in the (i-1)th ChanngelGroup by using Lss7 and Rss7 in the ith ChannelGroup and its relevant demixing parameters (i.e., α(k) and β(k)) , respectively.
- D_Ltb4 and D_Rtb4 are de-mixed from Ltf2 and Rtf2 in the (i-1)th ChanngelGroup by using Ltf4 and Rtf4 in the ith ChannelGroup and its relevant demixing parameter (i.e., γ(k)), respectively.

Recon_Gain for D_Lrs7:
- Level Ok is the signal power for the frame #k of Lrs7 in the ith ChanngGroup.
- Level Mk is the signal power for the frame #k of Ls5 in the (i-1)th ChannelGroup.
- Level Dk is the signal power for the frame #k of D_Lrs7.
Recon_Gain for D_Rrs7:
- Level Ok is the signal power for the frame #k of Rrs7 in the ith ChanngGroup.
- Level Mk is the signal power for the frame #k of Rs5 in the (i-1)th ChannelGroup.
- Level Dk is the signal power for the frame #k of D_Rrs7.
Recon_Gain for D_Ltb4:
- Level Ok is the signal power for the frame #k of Ltf4 in the ith ChanngGroup.
- Level Mk is the signal power for the frame #k of Ltf2 in the (i-1)th ChannelGroup.
- Level Dk is the signal power for the frame #k of D_Ltb4.
Recon_Gain for D_Rtb4:
- Level Ok is the signal power for the frame #k of Rtf4 in the ith ChanngGroup.
- Level Mk is the signal power for the frame #k of Rtf2 in the (i-1)th ChannelGroup.
- Level Dk is the signal power for the frame #k of D_Rtb4.
```

#### ChannelGroup Generation Rule #### {#iaencoding-iaencoder-channelaudio-channelgroupgenerationrule}

This section describes the generation rule for ChannelGroup.

For a given Channel Audio and the list of CLs ({CL #i: i = 1, 2, ..., n}), CG Generation module outputs the transformed audio (i.e. ChannelGroups) which conforms to following rules:
- It consists of C number of channels and is structured to n number of CGs, where C is the number of channels for the Channel Audio.
- CG #1 (as called BCG): This CG is the down-mixed audio itself for CL #1 generated from the Channel Audio. It contains C1 number of channels.
- CG #i (as called DCG, i = 2, 3, …, n): This CG contains (Ci – Ci-1) number of channels. (Ci – Ci-1) channel(s) consists of as follows:
	- (Si – Si-1) surround channel(s) if Si > Si-1 . When S_set = { x | Si-1 < x ≤ Si and x is an integer},
		- If 2 is an element of S_set, the L2 channel is contained in this CG #i.
		- If 3 is an element of S_set, the Center channel is contained in this CG #i.
		- If 5 is an element of S_set, the L5 and R5 channels are contained in this CG #i.
		- If 7 is an element of S_set, the Lss7 and Rss7 channels are contained in this CG #i.
	- The LFE channel if Wi > Wi-1 .
	- (Ti – Ti-1) top channels if Ti > Ti-1 .
		- If Ti-1 = 0, the top channels of the down-mixed audio for CL #i are contained in this CG #i.
		- If Ti-1 = 2, the Ltf and Rtf channels of the down-mixed audio for CL #i are contained in this CG #i.

Figure 15 shows one example of transformation matrix with 4 CGs (2ch/3.1.2ch/5.1.2ch/7.1.4ch).

<center><img src="images/Example of Transformation Matrix with 4 CGs.png"></center>
<center><b>Figure 11-5. </b>Example of Transformation Matrix with 4 CGs</center>

### IA Encoder for Ambisonics and Channel Audio format ### {#iaencoding-iaencoder-ambisoncis-channelaudio}

For Ambisonics and Channel Audio format:
- One single ChannelGroup for Ambisonics is generated in the same way with [[#iaencoding-iaencoder-ambisonics]].
- One or more ChannelGroups and Timed Metadata for Channel Audio are generated in the same way with [[#iaencoding-iaencoder-ambisonics]].
- IA_Static_Meta is set to as follows:
	- Ambisonics_Mode is set to according to Ambisonics mode in the same way with [[#iaencoding-iaencoder-ambisonics]].
	- Channel_Audio_Layer is set in the same way with [[#iaencoding-iaencoder-channelaudio]].
	- ambix_layer_config is set in the same way with [[#iaencoding-iaencoder-ambisonics]].
	- channel_audio_layer_config is set in the same way with [[#iaencoding-iaencoder-channelaudio]].
- Temporal Unit is composed of Temporal_Delimiter_OBU, followed by OBUs for Timed Metadata and followed by OBUs for Substreams.
	- OBUs for Substreams composing of ChannelGroup for Ambisonics comes first and followed by OBUs for Substreams composing of ChannelGroups for Channel Audio.

Figure 12 shows IA encoding flowchart for Ambisonics and Channel Audio format with non-scalable channel audio.

<center><img src="images/IA Encoding Flowchart for Ambisonics and Channel Audio Format.png"></center>
<center><b>Figure 12. </b>IA Encoding Flowchart for Ambisonics and Channel Audio Format</center>

# IA Decoding Process #  {#iadecoding}

This section provides a guideline for IA decoding for a given [=IA bitstream=].

## IA Decoder ## {#iadecoding-iadecoder}

IA decoder can selects one of three decoding modes based on Ambisonics_Mode and Channel_Audio_Layer in IA_Static_Meta.
- Ambisonics decoding in case of Ambisonics_Mode !=0 and Channel_Audio_Layer = 0.
- Channel Audio decoding in case of Ambisonics_Mode = 0 and Channel_Audio_Layer > 0.
- Ambisonics + Channel Audio decoding in case of Ambisonics_Mode != 0 and Channel_Audio_Layer > 0.

<b>Abmisonics decoding</b>, it conforms to [[!RFC8486]] except codec specific processing and outputs Ambisonics channels in ACN (Ambisonics Channel Number) order.

<b>Channel Audio decoding</b>, it outputs the channel audio (e.g. 3.1.2ch or 7.1.4ch) for the target channel layout.

<b>Ambisonics + Channel Audio decoding</b>, it outputs both of Ambisonics channels and the channel audio for the target channel layout.
- In this case, implementors may have additional processing converting Ambisonics to Channel Audio (including Binaural) but it is not specified in this specification.

IA decoder is composed of OBU parser, Codec decoder and Post-processor as depicted in Figure 13.
- OBU parser depacketizes IA bitstream to output one or more Substreams with one single Decoder_Config, IA_Static_Meta and Timed Metadata.
	- OBU parser is composed of Non-timed Metadata parser and Temporal Unit parser.
		- Non-timed Metadata parser depacketizes OBUs for Codec_Specific_Info and IA_Static_Meta, and figures out the configuration of IA bitstream including the codec to decoder Substreams.
		- Temporal Unit parser depacketizes OBUs for each Temporal Unit and outputs Timed Metadata and Substreams for each frame.
	- One or more Substreams with one single Decoder_Config are passed to Codec decoder.
	- IA_Static_Meta and Timed Metadata for each frame are passed to Post-processor.
	- For IAC-OPUS, Substream is one single [=opus packet=] of [[!RFC6716]] which has non-delimiting frame structure and for IAC-AAC-LC, Substreams is one single [=raw_data_block()=] of [[!AAC]].
- Codec decoder prepares the Mono/Stereo decoders as many as the number of Substreams. Each Mono/Stereo decoder is initialized with Decoder_Config and decodes Substream.
	- Each Mono/Stereo decoder outputs one or two channels to Post-processor.
- Post-processor outputs Ambisonics and/or Channel Audio based on the decoding mode.
	- Post-processor is composed of Ambiosonics processor and Channel Audio processor.
	- Post-processor figures out the configuration of ChannelGroups based on IA_Static_Meta.
	- Ambisonics processor outputs Ambisonics channels in ACN order by applying [=Channel_Mapping=] or [=Demixing_Matrix=] to the first ChannelGroup.
	- Channel Audio processor outputs channel audio for the target channel layout after some processing of the relevant ChannelGroups by using Timed Metadata if needed.

<center><img src="images/IA Decoder Configuration.png"></center>
<center><b>Figure 13. </b>IA Decoder Configuration</center>

### IA Decoder for Ambisonics decoding ### {#iadecoding-iadecoder-ambisonics}

This section describes IA decoding operation for Ambisonics.

Figure 14 shows the decoding flowchart of Ambisonics decoding.
- OBU parser outputs the first Substreams, among Substream in IA bitstream, as many as [=substream_count=] specified in ambix_layer_config of IA_Static_Meta, with Decoder_Config.
	- OBU parser outputs [=channel_mapping=] or [=demixing_matrix=] according to [=Ambisonics_Mode=] to Channel_Mapping/Demixing_Matrix module
- Codec decoder outputs channels as many as the nubmer of Substreams after decoding of each Substream.
- Channel_Mapping/Demixing_Matrix module applies channel_mapping or demixing_matrix according to Ambisonics_Mode to the channels (PCM) and outputs channels as many as [=output_channel_count=] in ACN order.

<center><img src="images/Ambisonics Decoding Flowchart.png"></center>
<center><b>Figure 14. </b>Ambisonics Decoding Flowchart</center>

### IA Decoder for Channel Audio decoding ### {#iadecoding-iadecoder-channelaudio}

This section describes IA decoding operation for Channe Audio.

Figure 15 shows the decoding flowchart of Channel Audio decoding.

<center><img src="images/Channel Audio Decoding Flowchart.png"></center>
<center><b>Figure 15. </b>Channel Audio Decoding Flowchart</center>

For a given target channel layout (i.e. CL #i) among the list of [=loudspeaker_layout=] in IA_Static_Meta,
- OBU Parser gets Substreams for ChannelGroup #1 ~ ChannelGroup #i and pass them to Codec decoder with [=Decoder_Config=].
- Codec decoder outputs decoded channels (PCM) in the transmission order.
	- For non-scalable audio (i.e i = 1), its order is converted to the loudspeaker location order for CL #1.
	- For scalable audio, its order is converted to the loudspeaker location order for CL #i after going through necessary modules such as Gain, De-Mixer, Recon_Gain etc..
- When Output_Gain_Is_Present_Flag(j) for ChanneGroup #j (j = 1, 2, …, i-1) is on, Gain module applies Output_Gain(j) to all audio samples of the mixed channels in the ChannelGroup #j indicated by Output_Gain_Flag(j).
- De-Mixer outputs de-mixed channels (PCM) for CL #i generated through de-mixing of the mixed channels from Gain module by using non-mixed channels and demixing parameters for each frame.
- Recon_Gain module outputs smoothed channels (PCM) by appling Recon_Gain to each frame of the de-mixed channels.
- Loudness normalization module outputs loudness normalized channels at -24 LKFS from non-mixed channels and smoothed channels (if present) by using loudness value for CL #i.
- DRC control module applies the pre-defined DRC compression to the loudness normalized channels, after that it outputs loudness normalized channels at -16 LKFS.
- Limiter module limits the true peak of input channels at -1dB.

Following sections, [[#iadecoding-iadecoder-channelaudio-gain]], [[#iadecoding-iadecoder-channelaudio-demixer]] and [[#iadecoding-iadecoder-channelaudio-recongain]] are only needed for decoding of scalable audio.
[[#iadecoding-iadecoder-channelaudio-loudness]] and [[#iadecoding-iadecoder-channelaudio-drc]] may not be recommended according to application.

#### Gain #### {#iadecoding-iadecoder-channelaudio-gain}

Gain module is the mirror process of Attenuation module. It recovers the reduced sample values using Output_Gain when its flag for ChannelGroup #j is on. When its flag is off, then this module is bypassed for ChannelGroup #j. Output_Gain(j) for ChannelGroup #j is applied to all samples of the mixed channels in the ChannelGroup #j. Where, mixed channels means the mixed channels from an input channel audio (i.e. a channel audio for CL #n).

To apply the gain, an implementation MUST use the following:

```
	Sample *= pow(10, Output_Gain(j) / (20.0*256))
```

Where, Output_Gain(j) is the raw 16-bit value from IA_Static_Meta.

#### De-mixer #### {#iadecoding-iadecoder-channelaudio-demixer}

For scalable audio, some channels of [=down-mixed audio=] for CL #i are delivered as is but the rest are mixed with other channels for CL #i-1.

De-mixer module reconstructs the rest of the down-mixed audio for CL #i from the mixed channels, which is passed by Gain module, and its relevant non-mixed channels using its relevant demixing parameters.

De-mixing for down-mixed audio for CL #i is a combination of following surround and top de-mixers:
- Surround de-mixers
	- <dfn noexport>S1to2 de-mixer</dfn>: R2 = 2 x Mono – L2
	- <dfn noexport>S2to3 de-mixer</dfn>: L3 = L2 – 0.707 x C and R3 = R2 – 0.707 x C
	- <dfn noexport>S3to5 de-mixer</dfn>: Ls = 1/δ(k) x (L3 – L5) and Rs = 1/δ(k) x (R3 – R5)
	- <dfn noexport>S5to7 de-mixer</dfn>: Lrs = 1/β(k) x (Ls – α(k) x Lss) and Rrs = 1/β(k) x (Rs – α(k) x Rss)
- Top de-mixers
	- <dfn noexport>TF2toT2 de-mixer</dfn>: Ltf2 = Ltf3 – w(k) x (L3 – L5) and Rtf2 = Rtf3 – w(k) x (R3 – R5)
	- <dfn noexport>T2to4 de-mixer</dfn>: Ltb = 1/γ(k) x (Ltf2 – Ltf4) and Rtb = 1/γ(k) x (Rtf2 – Rtf4)
- Where, Ltf2 / Rtf2 is top channel of x.1.2ch, Ltf3 / Rtf3 is top channel of 3.1.2ch, and Ltf4 / Rtf4 is to channel of x.1.4ch (x = 5 or 7) and w(k) is determined from the value of wIdx(k).

Initially, wIdx(0) = 0 and the value of wIdx(k) is derived as follows:
- <dfn noexport>wIdx(k)</dfn> = Clip3 (wIdx(k-1) + w_idx_offset(k), 0, 10)
- Where, Clip3 (x, min, max) = max if x > max, min if x < min, x otherwise.

Mapping of wIdx(k) to w(k) is as follows:
<pre class = "def">
 wIdx(k) :   w(k)
    0    :    0
    1    :  0.0179
    2    :  0.0391
    3    :  0.0658
    4    :  0.1038
    5    :  0.25
    6    :  0.3962
    7    :  0.4342
    8    :  0.4609
    9    :  0.4821
    10    : 0.5
</pre>

When D_set = { x | S1 < x ≤ Si and x is an integer},
- If 2 is an element of D_set, the combination includes [=S1to2 de-mixer=].
- If 3 is an element of D_set, the combination includes [=S2to3 de-mixer=].
- If 5 is an element of D_set, the combination includes [=S3to5 de-mixer=].
- If 7 is an element of D_set, the combination includes [=S5to7 de-mixer=].

When Ti = 2,
- If Sj = 3 (j=1,2,…, i-1), the combination includes [=TF2toT2 de-mixer=].

When Ti = 4,
- If Sj = 3 (j=1,2,…, i-1), the combination includes [=TF2toT2 de-mixer=] and [=T2to4 de-mixer=].
- Elseif Tj = 2 (j=1,2,…, i-1), the combination includes [=T2to4 de-mixer=].

For example, when CL #1 = 2ch, CL #2 = 3.1.2ch, CL #3 = 5.1.2ch and CL #4 = 7.1.4ch. To reconstruct the rest (i.e. Ls5/Rs5/Ltf/Rtf) of th down-mixed 5.1.2ch,
- The combination includes [=S2to3 de-mixer=], [=S3to5 de-mixer=] and [=TF2toF2 de-mixer].
- Ls5 and Rs5 are recovered by S2to3 de-mixer and S3to5 de-mixer.
- Ltf and Rtf are recovered by S2to3 de-mixer and TF2toT2 de-mixer.

```
	Ls5 = 1/δ(k) × (L2 - 0.707 × C - L5) and Rs5 = 1/δ(k) × (R2 - 0.707 × C - R5).
	Ltf = Ltf3 - w(k) x (L2 - 0.707 x C - L5) and Rtf = Rtf3 - w(k) x (R2 - 0.707 x C - R5).
```

#### Recon Gain #### {#iadecoding-iadecoder-channelaudio-recongain}

[=Recon_Gain=] is only applied to all of audio samples of the de-mixed channels from De-mixer module.
- [=Recon_Gain_Info=] indicates each channel of CL #i which Recon_Gain needs to be applied to and provides Recon_Gain value for each frame of the channel.
	- Sample (k,i) *= Smoothed_Recon_Gain (k,i), where k is the frame index and i is the sample index of the frame.
	- Smoothed_Recon_Gain (k) = MA_gain (k-1) x e_window + MA_gain (k) x s_window
	- MA_gain (k) = 2 / (N+1) x Recon_Gain (k) / 255 + (1 – 2/(N+1)) x MA_gain (k-1), where MA_gain (0) = 1.
	- e_window[:ps – olen] = 1, e_window[ps – olen: ps] = hanning[olen:], e_window[ps:flen] = 0.
	- s_window[:ps – olen] = 0, s_window[ps – olen: ps] = hanning[:olen], s_window[ps:flen] = 1.
	- Where, hanning = np.hanning (2*olen), ps is the pre-skip value, flen is the frame size and olen is the overlab size.
	- Recommend values: N = 7

Figure 16 shows the smoothing scheme of [=Recon_Gain=].

<center><img src="images/Smoothing Scheme of Recon Gain.png"></center>
<center><b>Figure 16. </b>Smoothing Scheme of Recon Gain</center>

Recommend values for specific codecs are as follows
- IAC-OPUS: olen = 60, the pre-skip (ps) value is indicated in Codec_Specific_Info for IAC-OPUS.
- IAC-AAC-LC: olen = 64, ps = 720.

#### Loudness Normalization #### {#iadecoding-iadecoder-channelaudio-loudness}

Loudness normalization is done by adjusting a loudness level to -24 LKFS based on the loudness value of the target channel layout (i.e. CL #i) which is signaled in [=Channel_Audio_Layer_Config()=].

Real implementations for [[#iadecoding-iadecoder-channelaudio-loudness]], [[#iadecoding-iadecoder-channelaudio-drc]] and [[#iadecoding-iadecoder-channelaudio-limiter]] are soly dependent on implementers (i.e., out of scope of this specification). This specification only recommends the principles for them.

#### DRC Control #### {#iadecoding-iadecoder-channelaudio-drc}

In this specification, DRC Control assumes an input loudness of -24 LKFS and targets an output loudness of -16 LKFS.

DRC Control module applies the pre-defined DRC compression by assuming a target loudness is adjusted to -16 LKFS as follows:
- DRC Segment 0
	- Threshold: not applicable
	- Ratio: 1:1
	- Type: Neutral
- DRC Segment 1
	- Threshold: -16.5 dBFS
	- Ratio: 1.5:1
	- Type: Compressor
- DRC Segment 2
	- Threshold: -9 dBFS
	- Ratio: 2:1
	- Type: Compressor
- DRC Segment 3
	- Threshold: -6 dBFS
	- Ratio: 3:1
	- Type: Compressor

Figure 17 shows the schematic diagram of the pre-defined DRC compression.

<center><img src="images/Pre-defined DRC Compression Scheme.png"></center>
<center><b>Figure 17. </b>Pre-defined DRC Compression Scheme</center>

The below is the equation that represents the compressor scheme of Figure 17.

```
	Y = D_T(i) + (X - T(i)) / R(i). Where,
	X ∈ Seg(i) and D_T (i) = T(0) + ∑ ((T(k+1) - T(k)) / R(k)) (k = 0 to i-1).
	Seg(i): ith Segment
	 T(i) : Threshold vlaue in dBFS for Seg(i), where T(0) = -96.33
	 R(i) : Ratio value for Seg(i)
	D_T(i): Threshold value in dBFS for Seg(i) after DRC compression, where D_T(0) = T(0)
	  X   : Input sample value in dBFS
	  Y   : Output sample value in dBFS
```

#### Limiter #### {#iadecoding-iadecoder-channelaudio-limiter}

This module limits the true peak of input signal at -1dB. The definition of thr true peak is base on [[!ITU1770-4]].

Below is a recommended loudness normalization and DRC control principle according to application.
- For AV application, it only applies Limiter at -1dBTP.
- For TV application, it only applies Loudness normalization at -24LKFS and Limiter at -1dBTP.
- For Mobile application, it applies Loudness normalization at -24LKFS, the pre-defined DRC control and adjusting of target loudness at -16 LKFS, and Limiter at -1dBTP.

NOTE: The definitions of AV, TV and Mobile applications are as follows:
.AV application: Sound devices with external speakers such as Soundbar, AV receiver, HiFi speaker etc..
.TV application: Television with built-in speakers such as LCD/OLED slim TV.
.Mobile application: Handheld devices with built-in speakers such as smartphone, tablet etc..

### IA Decoder for Ambisonics and Channel Audio decoding ### {#iadecoding-iadecoder-ambisonics-channelaudio}

Ambisonics and Channel Audio decoding is a simple parallel processing of both Ambisoncis decoding and Channel Audio decoding which are described in [[#iadecoding-iadecoder-ambisonics]] and [[#iadecoding-iadecoder-channelaudio]], respectively.

## Down-mix Matrix (Static) ## {#iadecoding-downmixmatrix}

This section provides static down-mix matrices to stereo and 3.1.2ch.

IAC players need to support any valid channel layout, even if the number of channels does not match the physically connected audio hardware. Players needs to perform channel mixing to increase or reduce the number of channels as needed.

Implementations can use the matrices in Figure 18 to Figure 24 to implement down-mixing from output channel audio, which are known to give acceptable results for stereo and 3.1.2ch.

For down-mixing to stereo, both sub-woofer and top channels are discarded during down-mixing. Therefore surround channels are only down-mixed and it only defines three down-mixing matrices, 3.x.x to stereo, 5.x.x to stereo and 7.x.x to stereo. Matrix for 3 channels is normalized so each coefficient row sums to 1 to avoid clipping. For 5 or more channels, they are normalized to 2 as a compromise between clipping and dynamic range reduction.

<center><img src="images/Stereo Down-mix Matrix for 3.x.x ch.png"></center>
<center><b>Figure 18. </b>Stereo Down-mix matrix for 3.x.x ch</center>

<center><img src="images/Stereo Down-mix Matrix for 5.x.x ch.png"></center>
<center><b>Figure 19. </b>Stereo Down-mix matrix for 5.x.x ch</center>

<center><img src="images/Stereo Down-mix Matrix for 7.x.x ch.png"></center>
<center><b>Figure 20. </b>Stereo Down-mix matrix for 7.x.x ch</center>

Figure 21 to Figure 24 show static down-mix matrices to 3.1.2ch.

<center><img src="images/3.1.2ch Down-mix Matrix for 5.1.2ch.png"></center>
<center><b>Figure 21. </b>3.1.2ch Down-mix matrix for 5.1.2ch</center>

<center><img src="images/3.1.2ch Down-mix Matrix for 5.1.4ch.png"></center>
<center><b>Figure 22. </b>3.1.2ch Down-mix matrix for 5.1.4ch</center>

<center><img src="images/3.1.2ch Down-mix Matrix for 7.1.2ch.png"></center>
<center><b>Figure 23. </b>3.1.2ch Down-mix matrix for 7.1.2ch</center>

<center><img src="images/3.1.2ch Down-mix Matrix for 7.1.4ch.png"></center>
<center><b>Figure 24. </b>3.1.2ch Down-mix matrix for 7.1.4ch</center>

Where, p1 = 0.707 and p2 = 0.3535


# IA Profiles # {#iaprofiles}

The IA Profiles define a set of capabilities that are required to decode the coresponding IA bitstreams.

ISSUE: Define the profiles and their capabilities/constraints.

## IA Simple Profile ## {#iaprofiles-simple}

This section defines the simple profile for IA bitstream and IA decoder and specifies the conformance points of this profile.

## IA Base Profile ## {#iaprofiles-base}

This section defines the base profile for IA bitstream and IA decoder and specifies the conformance points of this profile.

## IA Enhanced Profile ## {#iaprofiles-Enhanced}

This section defines the enhanced profile for IA bitstream and IA decoder and specifies the conformance points of this profile.
